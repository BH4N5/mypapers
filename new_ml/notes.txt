Przejdźmy teraz do matematycznego opisu architektury MLP. Załóżmy, iż sieć składa się z \(H + 2\)
warstw (\(H\) warstw ukrytych) o liczbach neuronów \(N_{in} = N_0\) (warstwa wejściowa), \(N_1,
\ldots, N_H\) (warstwy ukryte), \(N_{out} = N_{H+1}\) (warstwa wyjściowa). 

Jeśli \(\mathbf{x} \in \mathbb{R}^{N_{h-1}}\) jest wejściem \(h\)--tej warstwy ukrytej to jej
wyjście \(\mathbf{y}_h \in \mathbb{R}^{N_h}\) jest dane przez
\begin{equation*}
    \mathbf{y}_h = \sigma(\mathbf{W}_h\mathbf{x} + \mathbf{b}_h) = (\sigma \circ \mathbf{L}_h)(\mathbf{x})\,,
\end{equation*} 
gdzie \(\mathbf{W}_h \in \mathbb{R}^{N_h \times N_{h-1}}, \mathbf{b}_h \in \mathbb{R}^{N_h}\) to
odpowiednio macierz wag i wektor obciążeń w danej warstwie ukrytej i zdefiniowaliśmy odwzorowanie
\(\mathbf{L}_h: \mathbb{R}^{N_{h-1}} \mapsto \mathbb{R}^{N_h}\). Przez zapis \(\sigma(\mathbf{X})\)
dla \(\mathbf{X} \in \mathbb{R}^{m_1 \times \cdots \times m_k}\) oraz \(\sigma : \mathbb{R} \mapsto
\mathbb{R}\) rozumiemy tensor \(\mathbf{Y} = \sigma(\mathbf{X})\) taki, że \(Y_{i_1,..,i_k} =
\sigma(X_{i_1,..,i_k})\) tj. stosujemy funkcję \(\sigma\) do każdego elementu \(\mathbf{X}\) osobno.
Bez straty ogólności zakładamy, iż wyjście warstwy wyjściowej jest po prostu obciążoną kombinacją
liniową wejść bez żadnej funkcji aktywacji (lub inaczej z funkcją aktywacji będącą identycznością).
Wyjście z sieci MLP jest dane zatem w postaci złożenia
\begin{equation*}
    \begin{split}
        &\mathbf{F}: \mathbb{R}^{N_{in}} \mapsto \mathbb{R}^{N_{out}}\\
        &\mathbf{F}(\mathbf{x}) = \left(\mathbf{L}_{H+1} \circ \sigma \circ \mathbf{L}_h \circ \cdots \circ \sigma \circ \mathbf{L}_1\right)(\mathbf{x})
    \end{split}\quad.
\end{equation*}
Jest to zatem odwzorowanie, które dla danego wektora zmiennych objaśniających \(\mathbf{x}\) zwraca
\(\mathbf{F}(\mathbf{x})\). Możemy jednak łatwo rozszerzyć definicję \(\mathbf{F}\) i funkcji
\(\mathbf{L}_h\) w taki sposób, aby sieć przyjmowała od razu cały zbiór wektorów w postaci jednej
macierzy \(\mathbf{X}\in\mathbb{R}^{N_{in} \times D}\), gdzie \(D\) jest liczbą przykładów w zbiorze
uczącym. Wówczas
\begin{equation*}
    \begin{split}
        &\mathbf{L}_h: \mathbb{R}^{N_{h-1} \times D} \mapsto \mathbb{R}^{N_h \times D}\\
        &\mathbf{L}_h(\mathbf{X}) = \mathbf{W}_h\mathbf{X} + \mathbf{b}_h\mathbf{I}^T\\
        &\\
        &\mathbf{F}: \mathbb{R}^{N_{in} \times D} \mapsto \mathbb{R}^{N_{out} \times D}\\
        &\mathbf{F}(\mathbf{X}) = \left(\mathbf{L}_{H+1} \circ \sigma \circ \mathbf{L}_h \circ \cdots \circ \sigma \circ \mathbf{L}_1\right)(\mathbf{X})
    \end{split}\quad,
\end{equation*}
gdzie \(\mathbf{W}_h \in \mathbb{R}^{N_h \times N_{h-1}}, \mathbf{b}_h \in \mathbb{R}^{N_h}\),
natomiast \(\mathbf{I} \in \mathbb{R}^{D}\) jest (co wynika z kontekstu) wektorem jednostkowym.
Wyjście z sieci neuronowej będziemy wykorzystywać przy tworzeniu modeli statystycznych w taki sam
sposób jak w modelach płytkich (regresja liniowa, regresja softmax) używaliśmy kombinacji liniowej
wektora obserwacji z wektorem wag \(\mathbf{w}^T\mathbf{x}\). Uczenie parametrów \(\mathbf{W}_h \in
\mathbb{R}^{N_{h} \times N_{h-1}}\), \(\mathbf{b}_h \in \mathbb{R}^{N_h}\) będzie zatem polegało na
znalezieniu ich estymaty punktowej MLE dla danego modelu statystycznego. Będziemy zatem
minimalizować pewien funkcjonał \(J\) (funkcję kosztu) o postaci danej przez zanegowaną
logarytmiczną funkcję wiarygodności. Przykładowo dla regresji użyjemy funkcjonału kwadratowego
\begin{equation*}
    J[\mathbf{F}] = \frac{1}{2}\norm{\mathbf{F}(\mathbf{X}) - \mathbf{Y}}^2\,,
\end{equation*}
gdzie \(\norm{\cdot}\) oznacza normę Frobeniusa, a \(\left\{(\mathbf{Y}_{:,i}, \mathbf{X}_{:,i})
\mid i \in \{1,\ldots,D\}\right\}\) jest zbiorem uczącym. W przypadku wieloklasowej regresji
logistycznej użyjemy jako funkcji kosztu wyprowadzonej dla przypadku płaskiego entropii krzyżowej
\begin{equation*}
    J[\mathbf{F}] = 
\end{equation*}
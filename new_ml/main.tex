\documentclass{myclass}
\usepackage[polish]{babel}

\title{Statystyczne uczenie maszynowe}
\author{Bartosz Hanc}

\begin{document}

\subsubsection*{Definicja przestrzeni probabilistycznej}

Rozkładem prawdopodobieństwa \(P\) w pewnym zbiorze zdarzeń elementarnych \(\Omega \neq \emptyset\)
nazywamy odwzorowanie
\begin{equation*}
    P: \Sigma \mapsto [0;1]\,,
\end{equation*}
gdzie \(\Sigma\) jest rodziną podzbiorów \(\Omega\) (inaczej rodziną zdarzeń) taką, że
\begin{equation*}
    \Omega \in \Sigma\,,\quad A \in \Sigma \implies A' \in \Sigma\,,\quad \forall A_1, A_2, \ldots \in \Sigma : \bigcup_{i}
    A_i \in \Sigma\,,
\end{equation*}
które spełnia: \(P(\Omega) = 1\) oraz dla dowolnych parami rozłącznych zdarzeń \(A_1, A_2, \ldots
\in \Sigma\) zachodzi
\begin{equation*}
    P\left(\bigcup_i A_i\right) = \sum_i P(A_i)\,.
\end{equation*}
Trójkę \((\Omega, \Sigma, P)\) nazywamy przestrzenią probabilistyczną. Z powyższej definicji
wynikają znane własności prawdopodobieństwa tj. \(P(A') = 1 - P(A)\) oraz \(P(A \cup B) = P(A) +
P(B) - P(A , B)\). 

\subsubsection*{Prawdopodobieństwo warunkowe}

Definiujemy również prawdopodobieństwo warunkowe zdarzenia \(A\) pod warunkiem zdarzenia \(B\) o
dodatnim prawdopodobieństwie 
\begin{equation*}
    P(A \mid B) := \frac{P(A , B)}{P(B)}\,.
\end{equation*}
Na podstawie powyższej definicji definiujemy niezależność zdarzeń \(A\), \(B\) jako własność
\(P(A,B) = P(A)P(B)\), co dla zdarzenia \(B\) o dodatnim prawdopodobieństwie jest równoważne z \(P(A
\mid B) = P(A)\). Ponadto jeśli zdarzenia \(A_1, A_2, \ldots \in \Sigma\) są parami rozłączne i
zachodzi \(\bigcup_i A_i = \Omega\) to dla dowolnego zdarzenia \(B \in \Sigma\) możemy zapisać
\begin{equation*}
    P(B) = \sum_i P(B \mid A_i) P(A_i)\,.
\end{equation*}
Z definicji prawdopodobieństwa warunkowego trywialnie udowodnić twierdzenie Bayesa
\begin{equation*}
    P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}\,.
\end{equation*}

\subsubsection*{Zmienne losowe}

W uczeniu maszynowym będą interesować nas zmienne o wartościach w \(\mathbb{R}^n\). Zmienne takie
nazywamy zmiennymi losowymi wielowymiarowymi i definiujemy jako odwzorowania
\begin{equation*}
    X: \Omega \mapsto \mathbb{R}^n
\end{equation*}
takie, że dla każdego \(A \subseteq \mathbb{R}^n\) zbiór \(\{\omega \in \Omega \mid X(\omega) \in
A\}\) należy do rodziny zdarzeń \(\Sigma\). Przy takiej definicji prawdopodobieństwo, iż zmienna
\(X\) ma wartość należącą do pewnego przedziału \(A\) wynosi
\begin{equation*}
    P(X \in A) = P(\{\omega \in \Omega \mid X(\omega) \in A\})\,.
\end{equation*}

Dowolny rozkład prawdopodobieństwa zmiennej losowej \(n\)--wymiarowej \(X = (X_1, X_2, \ldots,
X_n)\) jest wyznaczony jednoznacznie przez zadanie funkcji \(F(\mathbf{x}): \mathbb{R}^n \mapsto
[0;1]\) zwanej dystrybuantą zdefiniowanej jako
\begin{equation*}
    F(\mathbf{x}) = F(x_1, \ldots, x_n) := P(X_1 \leq x_1, \ldots, X_n \leq x_n)\,.
\end{equation*}
Zasadniczo będą nas interesować jednak dwa przypadki rozkładów prawdopodobieństwa zmiennych
losowych: rozkłady dyskretne i rozkłady ciągłe. W przypadku rozkładu dyskretnego istnieje pewien
przeliczalny zbiór \(S \subset \mathbb{R}^n\) taki, że \(P(X \in S) = 1\). Rozkład ten jest zadany
jednoznacznie przez podanie \(|S|\) liczb \(p_i > 0\) określających prawdopodobieństwa \(p_i = P(X =
\mathbf{x}_i)\) dla wszystkich \(\mathbf{x}_i \in S\). W przypadku rozkładu ciągłego istnieje z
kolei funkcja \(p(\mathbf{x}): \mathbb{R}^n \mapsto [0; \infty)\) taka, że
\begin{equation*}
    P(X_1 \in [a_1; b_1], \ldots, X_n \in [a_n; b_n]) = \int\limits_{a_1}^{b_1}\cdots\int\limits_{a_n}^{b_n}p(\mathbf{x})\dd[n]{\mathbf{x}}\,.
\end{equation*}
Funkcje \(p(\mathbf{x})\) nazywamy gęstością prawdopodobieństwa. W obu przypadkach musi być
spełniony warunek unormowania postaci odpowiednio
\begin{equation*}
    \sum_i p_i = 1\,,\quad \int\limits_{\mathbb{R}^n}p(\mathbf{x})\dd[n]{\mathbf{x}} = 1\,.
\end{equation*}

Będziemy często wykorzystywać wartość oczekiwaną pewnej funkcji \(f(\mathbf{x})\) zmiennej losowej
\(X\) zdefiniowaną odpowiednio dla rozkładu \(p\) -- dyskretnego lub ciągłego jako
\begin{equation*}
    \mathbb{E}[f(\mathbf{x})] := \sum_{\mathbf{x}_i \in S} f(\mathbf{x}_i)p_i \cong \int\limits_{\mathbb{R}^n}f(\mathbf{x})p(\mathbf{x})\dd[n]{\mathbf{x}}\,.
\end{equation*}
Zauważmy przy tym, iż funkcja \(f(\mathbf{x})\) może być zupełnie dowolna, np. dla funkcji
charakterystycznej (indykatorowej) zbioru \(A \subset \mathbb{R}^n\) \(f(\mathbf{x}) =
\mathcal{I}_A\) mamy \(\mathbb{E}[\mathcal{I}_A(\mathbf{x})] = P(X \in A)\) lub dla iloczynu funkcji
Heaviside'a \(f(\mathbf{x}) = \theta(t_1 - x_1)\cdots\theta(t_n - x_n)\) mamy
\(\mathbb{E}[f(\mathbf{x})] = F(t_1,\ldots, t_n)\).

\subsubsection*{Rozkłady brzegowe}

Niech \(X = (X_1, \ldots, X_n)\) będzie \(n\)--wymiarową zmienną losową o dystrybuancie
\(F(\mathbf{x})\). Rozkład brzegowy względem \(k\) zmiennych \(X_{\sigma(1)},\ldots,X_{\sigma(k)}\)
definiujemy jako rozkład wyznaczony przez dystrybuantę
\begin{equation*}
    F_{X_{\sigma(1)},\ldots,X_{\sigma(k)}} (x_{\sigma(1)},\ldots,x_{\sigma(k)}) := \lim_{x_{\sigma(k+1)}\to\infty,\ldots,x_{\sigma(n)}\to\infty} F(x_1,\ldots,x_n)\,.
\end{equation*}

\subsubsection*{Zmienne losowe niezależne}
Niech \(X = (X_1, \ldots, X_k)\) będzie \(n\)--wymiarową zmienną losową o rozkładzie wyznaczonym
przez dystrybuantę \(F(\mathbf{x})\). Powiemy, iż zmienne losowe \(n_1,\ldots,n_k\) -- wymiarowych
(\(n_1 + \ldots + n_k = n\)) \(X_1, \ldots, X_k\) są niezależne iff dla dowolnych
\(\mathbf{x}_1\in\mathbb{R}^{n_1},\ldots,\mathbf{x}_k\in\mathbb{R}^{n_k}\) zachodzi
\begin{equation*}
    F(\mathbf{x}_1,\ldots,\mathbf{x}_k) = F_{X_1}(\mathbf{x}_1)\cdot\ldots\cdot F_{X_k}(\mathbf{x}_k)\,.
\end{equation*}

\subsubsection*{Rozkłady warunkowe}

W ogólnym przypadku zmiennej losowej \(n\) -- wymiarowej \(Z = (Z_1, \ldots, Z_n)\) o ciągłym
rozkładzie \(p(\mathbf{z})\) jeśli wydzielimy zmienne \(k\) i \(n-k\) -- wymiarowe \(X =
(Z_{\sigma(1)}, \ldots, Z_{\sigma(k)})\), \(Y = (Z_{\sigma(k+1)}, \ldots, Z_{\sigma(n)})\) to
rozkład warunkowy zmiennej \(X \mid Y\) definiujemy jako rozkład zadany przez gęstość
prawdopodobieństwa
\begin{equation*}
    p(\mathbf{x} \mid \mathbf{y}) := \frac{p(\mathbf{z})}{p_Y(\mathbf{y})} = \frac{p(\mathbf{x},\mathbf{y})}{p_Y(\mathbf{y})}\,.
\end{equation*}

\subsubsection*{Transformacja zmiennych wielowymiarowych}

Niech \(X = (X_1, \ldots, X_n)\) będzie zmienną losową wielowymiarową o rozkładzie ciągłym o
gęstości \(p_X(\mathbf{x})\). Rozważmy bijekcję \((X_1, \ldots, X_n) \mapsto (Y_1, \ldots, Y_n)\).
Chcemy znaleźć wyrażenie na gęstość \(p_Y(\mathbf{y})\) w nowych zmiennych. Ponieważ infinitezymalne
prawdopodobieństwo jest niezmiennicze względem zmiany współrzędnych więc zachodzi
\begin{equation*}
    p_X(x_1,\ldots, x_n)\dd{x_1}\ldots\dd{x_n} = p_Y(y_1,\ldots, y_n)\dd{y_1}\ldots\dd{y_n}\,,
\end{equation*}
skąd
\begin{equation*}
    p_Y(y_1,\ldots,y_n) = \left|\frac{\partial(x_1,\ldots,x_n)}{\partial(y_1,\ldots,y_n)}\right|p_X(x_1(\mathbf{y}),\ldots,x_n(\mathbf{y}))\,.
\end{equation*}

\subsubsection*{Macierz kowariancji}

Macierz kowariancji funkcji \(f(\mathbf{x})\) zmiennej losowej \(X\) definiujemy jako
\begin{equation*}
    \oper{\Sigma}[f(\mathbf{x})] := \mathbb{E}\left[(f(\mathbf{x}) - \boldsymbol{\mu}_f)(f(\mathbf{x}) - \boldsymbol{\mu}_f)^\top\right]\,,
\end{equation*}
gdzie \(\boldsymbol{\mu}_f = \mathbb{E}[f(\mathbf{x})]\). Elementy diagonalne
\(\mathsf{\Sigma}_{ii}\) tej macierzy nazywamy wariancjami zmiennych \(X_i\), natomiast elementy
pozadiagonalne \(\mathsf{\Sigma}_{ij}\) nazywamy kowariancjami zmiennych \(X_i\) i \(X_j\).
Oczywiście \(\oper{\Sigma}\) jest macierzą symetryczną. Nadto jeśli \(f\) jest funkcją
identycznościową tj. \(f(\mathbf{x}) = \mathbf{x}\) to \(\oper{\Sigma}\) jest macierzą nieujemnie
określoną, gdyż dla dowolnego \(\mathbf{v} \in \mathbb{R}^n\) mamy
\begin{equation*}
    \mathbf{v}^\top \oper{\Sigma} \mathbf{v} = \mathbb{E}[\mathbf{v}^\top (\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{v}] = \mathbb{E}[z^2] \geq 0\,,
\end{equation*}
gdzie \(z = \mathbf{v}^\top (\mathbf{x} - \boldsymbol{\mu}) \in \mathbb{R}\). Jeśli \(X_1, \ldots,
X_n\) są niezależne i \(f\) jest funkcją identycznościową to \(\oper{\Sigma}\) jest macierzą
diagonalną.

\subsubsection*{Wielowymiarowy rozkład normalny}

Jeśli zmienna wielowymiarowa \(X = (X_1, \ldots, X_n)\) ma wielowymiarowy rozkład normalny (z ang.
\textit{Multivariate Normal distribution -- MVN}) z wartością oczekiwaną \(\boldsymbol{\mu}\) i
macierzą kowariancji \(\oper{\Sigma}\), co oznaczamy jako \(X \sim \mathcal{N}(\boldsymbol{\mu},
\oper{\Sigma})\), to gęstość prawdopodobieństwa jest dana
\begin{equation*}
    \phi(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^n\det\oper{\Sigma}}}\exp\left\{-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^\top\oper{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})\right\}
\end{equation*}
Macierz \(\oper{\Lambda} = \oper{\Sigma}^{-1}\) nazywamy macierzą precyzji. Jeśli \(\mathbf{v}_i\)
są unormowanymi wektorami własnymi macierzy \(\oper{\Sigma}\), a \(\lambda_i\) odpowiadającymi im
wartościami własnymi i zakładając, iż widmo \(\{\lambda_i\}\) jest niezdegenerowane mamy z
twierdzenia spektralnego
\begin{equation*}
    \oper{\Lambda} = \sum_{i=1}^n\frac{1}{\lambda_i}\mathbf{v}_i\mathbf{v}_i^\top
\end{equation*}
oraz wiemy, iż wektory \(\{\mathbf{v}_i\}\) tworzą bazę ortonormalną przestrzeni \(\mathbb{R}^n\). Z
powyższego możemy zatem wyrazić wektor \(\mathbf{x} - \boldsymbol{\mu}\) jako kombinację liniową
wektorów \(\{\mathbf{v}_i\}\) tj.
\begin{equation*}
    \mathbf{x} - \boldsymbol{\mu} = \sum_{i=1}^n t_i\mathbf{v}_i\,,
\end{equation*}
co pozwala zapisać gęstość prawdopodobieństwa jako
\begin{equation*}
    \phi(t_1,\ldots,t_2) \cong \exp\left\{-\frac{1}{2}\sum_{i=1}^n\frac{t_i^2}{\lambda_i}\right\}\,.
\end{equation*}
Z powyższego wzoru widać, iż poziomice gęstości są wielowymiarowymi elipsoidami, których półosie są
skierowane wzdłuż wektorów własnych \(\oper{\Sigma}\) i mają długości proporcjonalne do
\(\sqrt{\lambda_i}\).

Powiemy, iż wielowymiarowa zmienna losowa \(X \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) ma
standardowy wielowymiarowy rozkład normalny jeśli \(\boldsymbol{\mu} = \mathbf{0}\) i
\(\oper{\Sigma} = \oper{1}\). Wówczas
\begin{equation*}
    \phi(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^n}}\exp\left\{-\frac{1}{2}\mathbf{x}^\top\mathbf{x}\right\}\,.
\end{equation*}

Można wykazać, iż jeśli \(X \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) dla
\(\oper{\Sigma}\) o niezdegenerowanym widmie to wszystkie rozkłady brzegowe i warunkowe \(X\) są
rozkładami normalnymi.

\subsubsection*{Zbieżność w rachunku prawdopodobieństwa}

W rachunku prawdopodobieństwa definiujemy trzy zasadnicze rodzaje zbieżności ciągu zmiennych
losowych \((X_n)\). 
\begin{itemize}
    \item Ciąg \((X_n)\) jest zbieżny do \(X\) stochastycznie iff
    \begin{equation*}
        \forall \epsilon > 0: \lim_{n\to\infty} P(|X_n - X| < \epsilon) = 1\,.
    \end{equation*}

    \item Ciąg \((X_n)\) jest zbieżny do \(X\) z prawdopodobieństwem 1 iff
    \begin{equation*}
        P\left(\lim_{n\to\infty} X_n = X\right) = 1\,.
    \end{equation*}

    \item Ciąg \((X_n)\) \(n\)--wymiarowych zmiennych losowych jest zbieżny do \(X\) według
    dystrybuant iff
    \begin{equation*}
        \forall \mathbf{x} \in \mathbb{R}^n, F_X(\mathbf{x}) \text{ -- ciągła w \(\mathbf{x}\)}: \lim_{n\to\infty} F_{X_n}(\mathbf{x}) = F_X(\mathbf{x})
    \end{equation*}

\end{itemize}

Pomiędzy tak zdefiniowanymi rodzajami zbieżności zachodzą następujące implikacje:
\begin{enumerate}
    \item \(X_n \to X\) z prawdopodobieństwem 1 \(\implies\) \(X_n \to X\) stochastycznie
    \item \(X_n \to X\) stochastycznie \(\implies\) \(X_n \to X\) według dystrybuant
    \item \(X_n \to X\) stochastycznie \(\implies\) istnieje podciąg \((X_{n_k})\) zbieżny do \(X\)
    z prawdopodobieństwem 1
\end{enumerate}

\subsubsection*{Wnioskowanie statystyczne}

Modelem statystycznym nazwiemy parę \((\chi, \mathcal{P})\), gdzie \(\mathcal{P}\) jest rodziną
rozkładów prawdopodobieństwa w zbiorze \(\chi\), przy czym będziemy zakładać \(\chi = \mathbb{R}^n\)
\begin{equation*}
    \mathcal{P} := \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta \right\}\,,
\end{equation*}
gdzie \(\Theta\) jest zbiorem parametrów modelu \(\mathcal{P}\). Prostą próbą losową w modelu
\(\mathcal{P}\) nazwiemy ciąg niezależnych zmiennych losowych \(X_1, \ldots, X_n\) o wartościach w
\(\mathbb{R}^n\) i pochodzących z tego samego rozkładu \(p(\mathbf{x} \mid \theta) \in \mathcal{P}\)
(w angielskiej terminologii taki ciąg zmiennych losowych nazwiemy \textit{i.i.d.} tj.
\textit{independent and identically distributed}). Statystyką z kolei nazwiemy zmienną losową \(T\)
będącą funkcją prostej próby losowej tj. \(T = T(X_1, \ldots, X_n)\). Być może najważniejszym
przykładem statystyki jest średnia oznaczana jako \(\overline{X}\)
\begin{equation*}
    \overline{X}(X_1, \ldots, X_n) := \frac{X_1 + \ldots + X_n}{n}\,.
\end{equation*}

\subsubsection*{Silne prawo wielkich liczb}

Niech \((X_n)\) będzie ciągiem zmiennych losowych i.i.d. z pewnego rozkładu \(X \sim \mathcal{D}\).
Przez \((\overline{X}_n)\) oznaczmy ciąg średnich częściowych tj.
\begin{equation*}
    \overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i\,.
\end{equation*}
Wówczas zachodzi silne prawo wielkich liczb
\begin{equation*}
    P\left(\lim_{n\to\infty} \overline{X}_n = \mathbb{E}[X]\right) = 1\,,
\end{equation*}
czyli średnia próbek zbiega do wartości oczekiwanej z prawdopodobieństwem 1.

Silne prawo wielkich liczb daje nam potężne narzędzie do szacowania wartości oczekiwanych, gdyż
możemy je przybliżać średnią z dużej liczby próbek losowych, a dokładność tego przybliżenia zależy
jedynie od liczby próbek i wariancji \(X\). Jeśli \(X\) jest zmienną wielowymiarową to dokładność
przybliżenia nie zależy wprost od liczby wymiarów i unikamy tzw. \textit{curse of dimensionality}.

\subsubsection*{Centralne Twierdzenie Graniczne}

Niech \((X_n)\) będzie ciągiem \(k\)--wymiarowych zmiennych losowych i.i.d. z dowolnego rozkładu \(X
\sim \mathcal{D}\) o wartości oczekiwanej \(\boldsymbol{\mu} = \mathbb{E}[\mathbf{x}]\) i
odwracalnej macierzy kowariancji \(\oper{\Sigma}\). Oznaczając przez \((\overline{X}_n)\) ciąg
średnich częściowych ciągu \((X_n)\) zachodzi
\begin{equation*}
    \sqrt{n}\left(\overline{X}_n - \boldsymbol{\mu}\right) \to Z \sim \mathcal{N}(\mathbf{0}, \oper{\Sigma})\,.
\end{equation*}

Oznacza to, iż dla ciągu \(X_1,\ldots,X_n\) zmiennych losowych i.i.d. z praktycznie dowolnego
rozkładu \(X\sim\mathcal{D}\) dla odpowiednio dużych \(n\) średnią z próbek możemy traktować jako
zmienną losową o rozkładzie normalnym \(\mathcal{N}(\boldsymbol{\mu}, n^{-1/2}\oper{\Sigma})\).


\subsubsection*{Estymatory punktowe MLE i MAP}

Rozważamy model statystyczny \(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in
\Theta\right\}\). Estymatorem parametru \(\theta\) nazwiemy statystykę
\(\hat{\theta}(X_1,\ldots,X_n)\) służącą do oszacowania wartości tego parametru. Wartość tej
statystki dla konkretnej realizacji prostej próby losowej
\(\hat{\theta}(\mathbf{x}_1,\ldots,\mathbf{x}_n)\) nazwiemy estymatą parametru \(\theta\). Dodatkowo
definiujemy obciążenie (z ang. \textit{bias}) estymatora jako wielkość
\begin{equation*}
    \mathbb{B}[\hat{\theta}] := \mathbb{E}[\hat{\theta}] - \theta\,.
\end{equation*}

Zasadniczo będą nas interesować dwa rodzaje estymat: MLE i MAP. W przypadku estymaty MLE (z ang.
\textit{Maximum Likelihood Estimate}) definiujemy funkcję wiarygodności (\textit{likelihood}) dla
modelu \(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta\right\}\) i
realizacji prostej próby losowej (którą nazwiemy również danymi lub obserwacjami)
\(D=(\mathbf{x}_1,\ldots,\mathbf{x}_n)\) jako
\begin{equation*}
    p(D \mid \theta) = \prod_{i=1}^n p(\mathbf{x}_i \mid \theta)\,.
\end{equation*}
Estymatą MLE nazywamy taką wartość parametru \(\theta_\text{MLE} \in \Theta\), że
\begin{equation*}
    p(D \mid \theta_\text{MLE}) = \max_{\theta \in \Theta} p(D \mid \theta)\,.
\end{equation*}
Ponieważ znajdywanie maksimum funkcji będącej iloczynem nie jest zadaniem przyjemnym (chociażby
obliczanie pochodnych iloczynu funkcji jest trudniejsze od sumy), więc wprowadzamy zanegowaną
logarytmiczną funkcję wiarygodności
\begin{equation*}
    \ell(D \mid \theta) = -\log p(D \mid \theta) = -\sum_{i=1}^n \log p(\mathbf{x}_i \mid \theta)\,,
\end{equation*}
wówczas ze względu na fakt, iż funkcja \(\log x\) jest ściśle rosnąca estymatę MLE możemy
równoważnie wyznaczyć jako
\begin{equation*}
    \ell(D \mid \theta_\text{MLE}) = \min_{\theta \in \Theta} \ell(D \mid \theta)\,.
\end{equation*}
Funkcję \(\ell\) będziemy również nazywać funkcją kosztu.

W przypadku estymaty MAP (z ang. \textit{Maximum a posteriori estimate}) wprowadzamy gęstość
rozkładu a posteriori jako
\begin{equation*}
    p(\theta \mid D) = \frac{1}{Z}p(D \mid \theta)\pi(\theta)\,,
\end{equation*}
gdzie \(Z\) jest stałą wynikającą z warunku unormowania, a \(\pi(\theta)\) to gęstość
prawdopodobieństwa opisująca rozkład a priori parametru \(\theta\). Estymatą MAP nazywamy taką
wartość parametru \(\theta_\text{MAP} \in \Theta\), że
\begin{equation*}
    p(\theta_\text{MAP} \mid D) = \max_{\theta \in \Theta} p(\theta \mid D)\,.
\end{equation*}
Zauważmy przy tym iż liczba \(Z\) nie jest nam potrzebna, gdyż wystarczy zmaksymalizować licznik tj.
\begin{equation*}
    \theta_\text{MAP} = \arg\max_{\theta \in \Theta} p(D \mid \theta)\pi(\theta)\,.
\end{equation*}

\subsubsection*{Wnioskowanie Bayesowskie}

Zajmiemy się teraz wnioskowaniem opartym na twierdzeniu Bayesa. Rozpatrujemy model statystyczny
\(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta\right\}\). Załóżmy, iż mamy
obserwacje \(D = (\mathbf{x}_1, \ldots, \mathbf{x}_n)\), wówczas twierdzenie Bayesa możemy zapisać
jako
\begin{equation*}
    p(\theta \mid D) = \frac{p(D \mid \theta)\pi(\theta)}{p_D(D)} = \frac{p(D \mid \theta)\pi(\theta)}{\int\limits_\Theta p(D \mid \theta)\pi(\theta) \dd{\theta}}\,,
\end{equation*}
gdzie \(p(\theta \mid D)\) nazywamy rozkładem a posteriori (posteriorem), \(p(D \mid \theta)\) --
wiarygodnością (likelihood), a \(\pi(\theta)\) -- rozkładem a priori (priorem).

Całe wnioskowanie Bayesowskie opiera się na wyznaczeniu rozkładu a posteriori, który wyraża całą
naszą wiedzę o estymowanym parametrze \(\theta\). Na podstawie tego rozkładu możemy wyznaczyć
estymatę punktową MAP, jak również niepewność związaną z wyznaczeniem tej estymaty np. poprzez
wyznaczenie przedziału wiarygodności \(C_{1-\alpha}(\theta \mid D) = [\theta_l ; \theta_u]\)
takiego, że
\begin{equation*}
    P(\theta \in [\theta_l ; \theta_u] \mid D) = 1 - \alpha\,,
\end{equation*}
dla ustalonego \(0 < \alpha < 1\). Możemy również skonstruować rozkład predykcyjny (z ang.
\textit{posterior predictive distribution}) określający prawdopodobieństwo zaobserwowania nowej
obserwacji \(\mathbf{x}\)
\begin{equation*}
    p(\mathbf{x} \mid D) = \int\limits_\Theta p(\mathbf{x} \mid \theta) p(\theta \mid D) \dd{\theta}\,.
\end{equation*}

\subsubsection*{Modele Gaussowskie}

Jak już wspomnieliśmy w przypadku gdy zmienna losowa ma wielowymiarowy rozkład normalny
\(\mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) wszystkie rozkłady brzegowe i warunkowe są również
rozkładami normalnymi. W szczególnym przypadku gdy zmienne \(k\) i \(n-k\) --wymiarowe
\(\mathbf{x}\) i \(\mathbf{y}\) mają łącznie rozkład normalny
\begin{equation*}
    \mqty[\mathbf{x} \\ \mathbf{y}] \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\,,
\end{equation*}
gdzie
\begin{equation*}
    \boldsymbol{\mu} = \mqty[\boldsymbol{\mu}_\mathbf{x} \\ \boldsymbol{\mu}_\mathbf{y}]\,,\quad \oper{\Sigma} = \mqty[\oper{\Sigma}_{\mathbf{xx}} & \oper{\Sigma}_{\mathbf{xy}} \\ \oper{\Sigma}_{\mathbf{yx}} & \oper{\Sigma}_\mathbf{yy}]
\end{equation*}
można pokazać iż
\begin{equation*}
    \mathbf{x} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}}, \oper{\Sigma}_{\mathbf{x}|\mathbf{y}})\,,\quad \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_\mathbf{y}, \oper{\Sigma}_\mathbf{yy})\,,
\end{equation*}
gdzie
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}} = \boldsymbol{\mu}_\mathbf{x} + \oper{\Sigma}_\mathbf{xy}\oper{\Sigma}_\mathbf{yy}^{-1}(\mathbf{y} - \boldsymbol{\mu}_\mathbf{y})\\
        &\oper{\Sigma}_{\mathbf{x}|\mathbf{y}} = \oper{\Sigma}_\mathbf{xx} - \oper{\Sigma}_\mathbf{xy}\oper{\Sigma}_\mathbf{yy}^{-1}\oper{\Sigma}_\mathbf{yx}
    \end{split}\quad.
\end{equation*}

\subsubsection*{Liniowe modele Gaussowskie}

Powyższe własności rozkładów łącznych pozwalają jawnie wnioskować w tzw. liniowych modelach
Gaussowskich (z ang. \textit{Linear Gaussian Models}). Załóżmy, iż nasze obserwacje są modelowane
przez \(n\)--wymiarową zmienną losową \(\mathbf{y}\) o rozkładzie normalnym z estymowanym parametrem
\(\mathbf{x}\) i znanymi parametrami \(\oper{A}, \mathbf{b}, \oper{\Sigma}_\mathbf{y}\) tak, że
wiarygodność ma postać
\begin{equation*}
    \mathbf{y}\mid\mathbf{x} \sim \mathcal{N}(\oper{A}\mathbf{x} + \mathbf{b}, \oper{\Sigma}_\mathbf{y})\,,
\end{equation*}
gdzie \(\oper{A}\) jest macierzą wymiaru \(n\times k\). Jako prior na parametr \(\mathbf{x}\)
przyjmiemy również rozkład normalny o pewnych zadanych parametrach \(\boldsymbol{\mu}_\mathbf{x},
\oper{\Sigma}_\mathbf{x}\) (taki wybór rozkładu a priori nazywamy rozkładem sprzężonym do
wiarygodności)
\begin{equation*}
    \mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}_\mathbf{x}, \oper{\Sigma}_\mathbf{x})\,.
\end{equation*}
Wówczas łatwo pokazać, iż rozkład a posteriori jest rozkładem normalnym
\begin{equation*}
    \mathbf{x} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}}, \oper{\Sigma}_{\mathbf{x}|\mathbf{y}})
\end{equation*}
z parametrami
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{\mathbf{x}|\mathbf{y}} = \left[\oper{\Sigma}_\mathbf{x}^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}} = \oper{\Sigma}_{\mathbf{x}|\mathbf{y}}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y} - \mathbf{b}) + \oper{\Sigma}_\mathbf{x}^{-1}\boldsymbol{\mu}_\mathbf{x}\right]
    \end{split}\quad.
\end{equation*}

Załóżmy teraz, iż mamy ciąg obserwacji \((\mathbf{y}_1, \ldots, \mathbf{y}_m)\). Wnioskowanie
Bayesowskie możemy wówczas stosować iteracyjnie tzn. na początku dla 0 obserwacji rozkład
estymowanego parametru jest opisany przez prior \(\mathcal{N}(\boldsymbol{\mu}_0,
\oper{\Sigma}_0)\). Po zaobserwowaniu jednego \(\mathbf{y}_1\) aktualizujemy nasze przekonania co do
parametru \(\mathbf{x}\) zgodnie z powyższym wzorem i otrzymujemy rozkład normalny o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_1 = \left[\oper{\Sigma}_0^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_1 = \oper{\Sigma}_1\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_1 - \mathbf{b}) + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]
    \end{split}\quad.
\end{equation*}
Po zaobserwowaniu kolejnego \(\mathbf{y}_2\) ponownie wykorzystujemy powyższe wzory ale jako prior
wykorzystując rozkład w poprzedniej iteracji. W ogólności możemy zapisać wzór rekurencyjny na
\(m+1\) rozkład jako
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m+1} = \left[\oper{\Sigma}_m^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{m+1} = \oper{\Sigma}_{m+1}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_{m+1} - \mathbf{b}) + \oper{\Sigma}_m^{-1}\boldsymbol{\mu}_m\right]
    \end{split}\quad,
\end{equation*}
skąd możemy od razu podać wzór na parametry \(m\)--tego rozkładu
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m} = \left[\oper{\Sigma}_0^{-1} + m\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{m} = \oper{\Sigma}_{m}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\left(\sum_{i=1}^{m}\mathbf{y}_{i} - m\mathbf{b}\right) + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]
    \end{split}\quad.
\end{equation*}
Taki sam wynik można by uzyskać rozpatrując łączny rozkład a posteriori dla obserwacji \(D =
(\mathbf{y}_1, \ldots, \mathbf{y}_m)\) tj.
\begin{equation*}
    \begin{split}
        &p(\mathbf{x} \mid D) \cong \pi(\mathbf{x})\prod_{i=1}^m p(\mathbf{y}_i \mid \mathbf{x})\cong \\
        &\exp\left\{-\frac{1}{2}\left[(\mathbf{x}-\boldsymbol{\mu}_0)^\top\oper{\Sigma}_0^{-1}(\mathbf{x}-\boldsymbol{\mu}_0) + \sum_{i=1}^m(\mathbf{y}_i - \oper{A}\mathbf{x}-\mathbf{b})^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_i - \oper{A}\mathbf{x}-\mathbf{b})\right]\right\}
    \end{split}\,.
\end{equation*}

\subsubsection*{Regresja liniowa}

Załóżmy, iż modelujemy obserwacje postaci \((y,\mathbf{x})\) gdzie \(y\) to skalar zwany zmienną
objaśnianą, którego wartość obserwujemy, a \(\mathbf{x}\) to wektor zmiennych objaśniających, który
kontrolujemy tj. zakładamy, iż wektor \(\mathbf{x}\) dla danego pomiaru \(y\) znamy dokładnie.
Dodatkowo zakładamy, iż \(y\) zależy liniowo od \(\mathbf{x}\) tj.
\begin{equation*}
    y = \mathbf{w}^\top\mathbf{x} + \epsilon\,,
\end{equation*}
gdzie \(\epsilon \sim \mathcal{N}(0, \sigma^2)\) dla znanego \(\sigma\) jest tzw. błędem losowym, a
\(\mathbf{w}\) jest estymowanym przez nas parametrem. Możemy zatem zapisać
\begin{equation*}
    y \mid \mathbf{w} \sim \mathcal{N}(\mathbf{w}^\top\mathbf{x}, \sigma^2)\,.
\end{equation*}
Powiedzmy, iż zaobserwowaliśmy ciąg obserwacji \(D = (y_1, \ldots, y_m)\) dla zadanych (lub
dokładnie znanych) przez nas \((\mathbf{x}_1,\ldots,\mathbf{x}_m)\). Wiarygodność ma zatem postać
\begin{equation*}
    p(D \mid \mathbf{w}) \cong \prod_{i=1}^m \exp\left\{-\frac{1}{2\sigma^2}\left(y_i - \mathbf{w}^\top\mathbf{x}_i\right)^2\right\}\,.
\end{equation*}
W przypadku regresji liniowej zamiast pełnego wnioskowania Bayesowskiego o parametrze \(\mathbf{w}\)
często stosuje się prostsze podejście polegające na znalezieniu estymaty punktowej MLE. Zanegowana
logarytmiczna funkcja wiarygodności ma postać
\begin{equation*}
    \ell(D \mid \mathbf{w}) = \frac{1}{2\sigma^2}\sum_{i=1}^m(y_i - \mathbf{w}^\top\mathbf{x}_i)^2 + \text{const.}
\end{equation*}
Człon stały możemy oczywiście pominąć i zapisać
\begin{equation*}
    \ell(D \mid \mathbf{w}) \cong \sum_{i=1}^m(y_i - \mathbf{w}^\top\mathbf{x}_i)^2 = \left(\mathbf{y} - \oper{X}\mathbf{w}\right)^\top\left(\mathbf{y} - \oper{X}\mathbf{w}\right)\,,
\end{equation*}
gdzie
\begin{equation*}
    \mathbf{y} = \mqty[y_1 \\ \vdots \\ y_m]\,,\quad \oper{X} = \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,.
\end{equation*}
Ponieważ otrzymana funkcja \(\ell\) ma postać formy kwadratowej, więc problem optymalizacyjny
polegający na znalezieniu minimum \(\ell\) nazywa się metodą najmniejszych kwadratów (z ang.
\textit{OLS -- Ordinary Least Squares}). Aby wyznaczyć estymatę \(\mathbf{w}_\text{MLE}\) musimy
rozwiązać równanie
\begin{equation*}
    \pdv{\ell}{\mathbf{w}} = \pdv{~}{\mathbf{w}}\left[\mathbf{y}^\top\mathbf{y} + \mathbf{w}^\top\oper{X}^\top\oper{X}\mathbf{w} - 2\mathbf{y}^\top\oper{X}\mathbf{w}\right] = \mathbf{0}\,,
\end{equation*}
skąd
\begin{equation*}
    2\oper{X}^\top\oper{X}\mathbf{w} - 2\oper{X}^\top\mathbf{y} = \mathbf{0}\,,
\end{equation*}
zatem
\begin{equation*}
    \mathbf{w}_\text{MLE} = (\oper{X}^\top\oper{X})^{-1}\oper{X}^\top\mathbf{y}\,.
\end{equation*}
Pełniejszą informację o parametrze \(\mathbf{w}\) możemy uzyskać rozpatrując rozkład a posteriori
\(p(\mathbf{w} \mid D)\). Jeśli jako prior przyjmiemy rozkład normalny z pewnymi parametrami
\(\boldsymbol{\mu}_0, \oper{\Sigma}_0\) to zauważmy, iż otrzymujemy instancję liniowego modelu
Gaussowskiego
\begin{equation*}
    \begin{split}
        \mathbf{y} \mid \mathbf{w} &\sim \mathcal{N}(\oper{X}\mathbf{w}, \sigma^2\oper{1})\\
        \mathbf{w} &\sim \mathcal{N}(\boldsymbol{\mu}_0, \oper{\Sigma}_0)
    \end{split}\quad,
\end{equation*}
skąd rozkład a posteriori jest rozkładem normalnym
\begin{equation*}
    \mathbf{w} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_m, \oper{\Sigma}_m)
\end{equation*}
o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_m = \left[\oper{\Sigma}_0^{-1} + \sigma^{-2}\oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_m = \oper{\Sigma}_m\left[\sigma^{-2}\oper{X}^\top\mathbf{y} + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]    
    \end{split}\quad.
\end{equation*}
W powyższych wzorach nazwy parametrów nie są przykładowe: po zaobserwowaniu 0 przykładów rozkład
parametru \(\mathbf{w}\) jest rozkładem a priori \(\mathcal{N}(\boldsymbol{\mu}_0,
\oper{\Sigma}_0)\); po zaobserwowaniu po jednej wartości \(y_i\) w \(m\) zadanych (znanych
dokładnie) punktach \(\mathbf{x}_i\) otrzymujemy rozkład a posteriori
\(\mathcal{N}(\boldsymbol{\mu}_m, \oper{\Sigma}_m)\). Gdybyśmy w każdym z \(m\) punktów
\(\mathbf{x}_i\) dokonywali pomiaru \(y_i\) \(s\)--krotnie to wtedy wykorzystując wzory wyprowadzone
przy iteracyjnym stosowaniu wnioskowania w liniowym modelu Gaussowskim otrzymujemy rozkład normalny
o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m;s} = \left[\oper{\Sigma}_0^{-1} + \frac{s}{\sigma^2}\oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_{m;s} = \oper{\Sigma}_{m;s}\left[\sigma^{-2}\oper{X}^\top\sum_{i=1}^s\mathbf{y}_i + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]    
    \end{split}\quad.
\end{equation*} 
Rozkład predykcyjny dla nowej obserwacji \(y\) poczynionej w punkcie \(\mathbf{x}\) jest dany przez
\begin{equation*}
    p(y \mid \mathbf{y}) = \int\limits_{\mathbb{R}^n}p(y\mid\mathbf{w})p(\mathbf{w}\mid\mathbf{y}) \dd[n]\mathbf{w}\,.
\end{equation*}
Nietrudno zauważyć, iż będzie to rozkład normalny o parametrach
\begin{equation*}
    \begin{split}
        \mu_{y|\mathbf{y}} = \mathbb{E}[y\mid\mathbf{y}] &= \int\limits_{\mathbb{R}} y p(y\mid\mathbf{y}) \dd{y} = \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} yp(y\mid\mathbf{w}) \\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \mathbf{x}^\top\mathbf{w} = \mathbf{x}^\top\boldsymbol{\mu}_m\,.
    \end{split}
\end{equation*}
oraz
\begin{equation*}
    \begin{split}
        \sigma_{y|\mathbf{y}}^2 &= \mathbb{E}\left[(y - \mu_{y|\mathbf{y}} )^2 \mid \mathbf{y}\right] = \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} (y-\mu_{y|\mathbf{y}})^2p(y\mid\mathbf{w})\\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} \left(y^2 + \mu_{y|\mathbf{y}}^2 - 2\mu_{y|\mathbf{y}}y\right)p(y\mid\mathbf{w})\\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \left(\sigma^2 + (\mathbf{x}^\top\mathbf{w})^2 + \mu_{y|\mathbf{y}}^2 - 2\mu_{y|\mathbf{y}}\mathbf{x}^\top\mathbf{w}\right)\\
        &=\sigma^2 + \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \left(\mathbf{x}^\top\mathbf{w} - \mathbf{x}^\top\boldsymbol{\mu}_m\right)^2\\
        &=\sigma^2 + \mathbf{x}^\top \mathbb{E}[(\mathbf{w}-\boldsymbol{\mu}_m)(\mathbf{w}-\boldsymbol{\mu}_m)^\top\mid\mathbf{y}]\mathbf{x} = \sigma^2 +\mathbf{x}^\top\oper{\Sigma}_m\mathbf{x}\,.
    \end{split}
\end{equation*}
Powyżej skorzystaliśmy ze znanego faktu, iż dla jednowymiarowej zmiennej losowej zachodzi \(\sigma^2
= \mathbb{E}[(X - \mu_X)^2] = \mathbb{E}[X^2] - \mu_X^2\), skąd \(\mathbb{E}[X^2] = \sigma^2 +
\mu_X^2\). Podsumowując rozkład predykcyjny ma postać
\begin{equation*}
    y \mid \mathbf{y} \sim \mathcal{N}(\mathbf{x}^\top\boldsymbol{\mu}_m, \sigma^2 + \mathbf{x}^\top\oper{\Sigma}_m\mathbf{x})\,.
\end{equation*}

\subsubsection*{Regularyzacja}

Regularyzacją nazywamy proces polegający na wprowadzeniu ad hoc do zagadnienia optymalizacji
dodatkowych członów tak, aby rozwiązanie było ,,regularne'' (prostsze, nieosobliwe, jednoznaczne
...). W przypadku funkcji kosztu \(\ell\) najczęściej dodajemy człon penalizujący rozwiązania o
dużej normie estymowanego parametru postaci
\begin{equation*}
    \gamma\norm{\theta}
\end{equation*}
dla pewnej normy \(\norm{\cdot}\) i hiper-parametru \(\gamma\) określającego siłę regularyzacji. W
kontekście Bayesowskim regularyzację można również rozumieć jako pewną niechęć (,,tłumienie'',
zachowawczość) modelu do zmiany rozkładu a priori estymowanego parametru po pojawieniu się kolejnych
obserwacji.

Przykładowo jeśli w zagadnieniu Bayesowskiej regresji liniowej jako prior przyjmiemy rozkład
normalny
\begin{equation*}
    \mathbf{w} \sim \mathcal{N}(\mathbf{0}, \tau^2\oper{1})
\end{equation*}
to rozkład a posteriori jest rozkładem normalnym o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_m = \sigma^2 \left[\gamma\oper{1} + \oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_m = \left[\gamma\oper{1} + \oper{X}^\top\oper{X}\right]^{-1}\oper{X}^\top\mathbf{y}
    \end{split}\quad,
\end{equation*}
gdzie \(\gamma = \sigma^2 / \tau^2\) jest hiper-parametrem określającym siłę regularyzacji.
Zauważmy, że im większa jest wartość \(\gamma\) (mniejsza niepewność związana z rozkładem a priori)
tym drugi człon w nawiasie staje się mniej istotny. Taki sam wynik możemy uzyskać metodą OLS jeśli
do funkcji kosztu dodamy człon regularyzujący dla zwykłej normy euklidesowej. Zagadnienie
minimalizacji funkcji kosztu będącej formą kwadratową z dodanym członem regularyzującym nazywamy
również regresją grzbietową.

\subsubsection*{Procesy Gaussowskie}

Jak już wspomnieliśmy macierz kowariancji \(n\)--wymiarowej zmiennej losowej \(\mathbf{x}\) o
wartości oczekiwanej \(\boldsymbol{\mu}\) jest zdefiniowana jako
\begin{equation*}
    \oper{\Sigma} = \mathbb{E}\left[(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top\right]\,.
\end{equation*}
Pokazaliśmy również, iż macierz ta jest nieujemnie określona. Dodatkowo pokażemy, iż dla każdej
nieujemnie określonej macierzy symetrycznej \(\oper{K}\) wymiaru \(n\times n\) istnieje
\(n\)--wymiarowa zmienna losowa o wielowymiarowym rozkładzie normalnym dla której \(\oper{K}\) jest
macierzą kowariancji. Istotnie dla każdej nieujemnie określonej macierzy symetrycznej istnieje
macierz \(\oper{L}\) taka, że
\begin{equation*}
    \oper{K} = \oper{L}\oper{L}^\top\,,
\end{equation*}
jest to tzw. dekompozycja Choleskiego. Niech \(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \oper{1})\),
wówczas zmienna losowa \(\oper{L}\mathbf{z}\) ma rozkład o zerowej wartości oczekiwanej i macierzy
kowariancji
\begin{equation*}
    \mathbb{E}\left[(\oper{L}\mathbf{z})(\oper{L}\mathbf{z})^\top\right] = \mathbb{E}\left[\oper{L}\mathbf{z}\mathbf{z}^\top\oper{L}^\top\right] = \oper{L}\mathbb{E}[\mathbf{z}\mathbf{z}^\top]\oper{L}^\top = \oper{L}\oper{1}\oper{L}^\top = \oper{K}\,.
\end{equation*}
Powyższe własności wskazują, iż macierze kowariancji można w pewnym sensie utożsamiać z nieujemnie
określonymi macierzami symetrycznymi.

Zdefiniujemy teraz funkcję kowariancji \(k: \mathbb{R}^n\times\mathbb{R}^n\mapsto\mathbb{R}\) taką,
że \(\forall m\in\mathbb{N} : \forall X = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\} \subset
\mathbb{R}^n\) macierz
\begin{equation*}
    k(X,X) = \mqty[k(\mathbf{x}_1, \mathbf{x}_1) & k(\mathbf{x}_1, \mathbf{x}_2) & \cdots & k(\mathbf{x}_1, \mathbf{x}_m)\\
    k(\mathbf{x}_2, \mathbf{x}_1) & k(\mathbf{x}_2, \mathbf{x}_2) & \cdots & k(\mathbf{x}_2, \mathbf{x}_m)\\
    \vdots & \vdots & \ddots & \vdots\\
    k(\mathbf{x}_m, \mathbf{x}_1) & k(\mathbf{x}_m, \mathbf{x}_2) & \cdots & k(\mathbf{x}_m, \mathbf{x}_m)\\]
\end{equation*}
jest dodatnio określoną macierzą symetryczną. Funkcję \(k\) nazywamy również jądrem dodatnio
określonym (z ang. \textit{positive definite kernel}) lub jądrem Mercera. Dla dwóch zbiorów punktów
\(X = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\} \subset \mathbb{R}^n\) i \(Y =
\{\mathbf{y}_1,\ldots,\mathbf{y}_s\} \subset \mathbb{R}^n\) i funkcji kowariancji \(k\) wprowadzimy
oznaczenie
\begin{equation*}
    k(X,Y) := \mqty[k(\mathbf{x}_1, \mathbf{y}_1) & k(\mathbf{x}_1, \mathbf{y}_2) & \cdots & k(\mathbf{x}_1, \mathbf{y}_s)\\
    k(\mathbf{x}_2, \mathbf{y}_1) & k(\mathbf{x}_2, \mathbf{y}_2) & \cdots & k(\mathbf{x}_2, \mathbf{y}_s)\\
    \vdots & \vdots & \ddots & \vdots\\
    k(\mathbf{x}_m, \mathbf{y}_1) & k(\mathbf{x}_m, \mathbf{y}_2) & \cdots & k(\mathbf{x}_m, \mathbf{y}_s)\\]\,.
\end{equation*}
Poniżej podajemy kilka przykładów funkcji kowariancji
\begin{itemize}
    \item \textit{Gaussian kernel} dla normy \(\norm{\cdot}\) i hiper-parametru \(l\)
    \begin{equation*}
        k(\mathbf{x}, \mathbf{y}) = \exp\left\{-\frac{1}{2l^2}\norm{\mathbf{x} - \mathbf{y}}^2\right\}
    \end{equation*}
    
    \item \textit{Periodic kernel} dla normy \(\norm{\cdot}\) i hiper-parametrów \(l, p\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \exp\left\{-\frac{2}{l^2}\sin^2\left(\frac{\pi}{p}\norm{\mathbf{x} - \mathbf{y}}\right)\right\}
    \end{equation*}

    \item \textit{White noise kernel} dla hiper-parametru \(\sigma\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \sigma^2 \delta_{\mathbf{x},\mathbf{y}}
    \end{equation*}

    \item \textit{Mat\'ern kernel} dla normy \(\norm{\cdot}\) i hiper-parametrów \(l, \nu\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \frac{2^{1-\nu}}{\Gamma(\nu)}\left(\frac{\sqrt{2\nu}}{l}\norm{\mathbf{x} - \mathbf{y}}\right)^\nu K_\nu\left(\frac{\sqrt{2\nu}}{l}\norm{\mathbf{x} - \mathbf{y}}\right)\,,
    \end{equation*}
    gdzie \(\Gamma(x)\) to funkcja gamma Eulera, a \(K_\nu(x)\) to zmodyfikowana funkcja Bessela
    2-go rodzaju rzędu \(\nu\).

\end{itemize}
Dodatkowo suma lub iloczyn dwóch funkcji kowariancji oraz złożenie funkcji kowariancji z wielomianem
o nieujemnych współczynnikach jest również funkcją kowariancji.

Procesem Gaussowskim (z ang. \textit{Gaussian Process}) nazywamy rodzinę skalarnych zmiennych
losowych indeksowanych przez punkty \(\mathbf{x} \in \mathbb{R}^n\)
\begin{equation*}
    \mathcal{GP} = \left\{f_\mathbf{x} \mid \mathbf{x} \in \mathbb{R}^n\right\}
\end{equation*}
taką że każdy skończony podzbiór \(\mathcal{GP}\) ma łącznie wielowymiarowy rozkład normalny tj. dla
dowolnego zbioru \(X = \{\mathbf{x}_1, \ldots, \mathbf{x}_m\} \subset \mathbb{R}^n\) zachodzi
\begin{equation*}
    \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\boldsymbol{\mu}_X, \oper{\Sigma}_{X})\,.
\end{equation*}
Zauważmy, iż process Gaussowski możemy jednoznacznie zdefiniować podając ,,przepisy'' na parametry
\(\boldsymbol{\mu}_X\) i \(\oper{\Sigma}_X\) dla dowolnego zbioru \(X\). W praktyce często
przyjmujemy \(\boldsymbol{\mu}_X = \mathbf{0}\), natomiast przepisem na macierz kowariancji może być
zdefiniowana wyżej funkcja kowariancji \(k(X,X)\) tj.
\begin{equation*}
    \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\mathbf{0}, k(X,X))\,.
\end{equation*}
Process Gaussowski daje nam w praktyce rozkład prawdopodobieństwa nad funkcjami
\(f:\mathbb{R}^n\mapsto\mathbb{R}\), których charakter jest określony przez jądro \(k\) (np. funkcja
gładka dla jądra Gaussowskiego, okresowa dla jądra periodycznego, itp.). Zauważmy, że nie
wnioskujemy tu o parametrach konkretnej rodziny funkcji (jak w przypadku regresji liniowej);
interesuje nas jedynie rozkład predykcyjny. Załóżmy, iż w zadanych (lub dokładnie znanych) przez nas
punktach \(X = \{\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m\}\) zaobserwowaliśmy wartości pewnej
funkcji, o których zakładamy, iż pochodzą z procesu Gaussowskiego zadanego jądrem \(k\), które
wyraża nasze założenia a priori co do charakteru badanej funkcji
\begin{equation*}
    \mathbf{f}_X = \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\mathbf{0}, k(X,X))\,.
\end{equation*}
Powiedzmy, iż chcemy znać wartości \(\mathbf{f}_Y\) tej funkcji w zadanych punktach \(Y =
\{\mathbf{y}_1,\mathbf{y}_2,\ldots,\mathbf{y}_s\}\). Ponieważ założyliśmy, iż wartości funkcji
pochodzą z procesu Gaussowskiego, więc rozkład łączny \(\mathbf{f}_X\) i \(\mathbf{f}_Y\) jest
rozkładem normalnym
\begin{equation*}
    \mqty[\mathbf{f}_X \\ \mathbf{f}_Y] \sim \mathcal{N}\left(\mathbf{0}, \mqty[k(X,X) & k(X,Y) \\ k(Y,X) & k(Y,Y)]\right)\,.
\end{equation*}
Zauważmy, iż jest to instancja modelu Gaussowskiego, więc rozkład warunkowy \(\mathbf{f}_Y\mid
\mathbf{f}_X\) jest również rozkładem normalnym o parametrach
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu} = k(Y,X)k^{-1}(X,X)\mathbf{f}_X\\
        &\oper{\Sigma} = k(Y,Y) - k(Y,X)k^{-1}(X,X)k(X,Y)
    \end{split}\quad.
\end{equation*}
Dodatkową niepewność związaną z pomiarem wartości \(\mathbf{f}_X\) możemy uchwycić zmieniając postać
jądra 
\begin{equation*}
    k(\mathbf{x},\mathbf{y}) \leftarrow k(\mathbf{x},\mathbf{y}) + \mathcal{I}_X(\mathbf{x})\sigma^2\delta_{\mathbf{x},\mathbf{y}}\,,
\end{equation*}
gdzie \(\sigma\) jest hiper-parametrem określającym precyzję pomiaru. Oczywiście \(k\) jest dalej
funkcją kowariancji, gdyż takie podstawienie powoduje jedynie dodanie dodatnich członów do pewnych
elementów diagonalnych macierzy kowariancji, więc macierz ta jest nadal symetryczna i dodatnio
określona. Wówczas rozkład predykcyjny ma parametry
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu} = k(Y,X)\left[k(X,X) + \sigma^2\oper{1}\right]^{-1}\mathbf{f}_X\\
        &\oper{\Sigma} = k(Y,Y) - k(Y,X)\left[k(X,X) + \sigma^2\oper{1}\right]^{-1}k(X,Y)
    \end{split}\quad.
\end{equation*}

\subsubsection*{Wieloklasowa regresja logistyczna}

Załóżmy, iż modelujemy obserwacje postaci \((t,\mathbf{x})\), gdzie \(t \in
\{\tau_1,\tau_2,\ldots,\tau_s\}\) to etykieta określająca przynależność do jednej z \(s\) klas, a
\(\mathbf{x} \in \mathbb{R}^n\) jest znanym (lub zadanym) przez nas dokładnie wektorem cech obiektu
dla których zaobserwowaną klasą jest \(t\). Zakładamy ponadto, iż prawdopodobieństwo przynależności
do klasy \(\tau_j\) (jednej z \(s\) klas) dla wektora cech \(\mathbf{x}\) ma postać tzw. funkcji
softmax
\begin{equation*}
    \pi_j(\mathbf{x}) = \frac{1}{Z(\mathbf{x})}\e^{\mathbf{w}_j^\top\mathbf{x}}\,,
\end{equation*}
gdzie \(\mathbf{w}_j\) są estymowanymi przez nas parametrami. Ze względu na warunek unormowania
musimy mieć
\begin{equation*}
    \sum_{j=1}^s \pi_j = 1\,,
\end{equation*}
skąd stała normalizacyjna \(Z(\mathbf{x})\) ma postać
\begin{equation*}
    Z(\mathbf{x}) = \sum_{j=1}^s \e^{\mathbf{w}_j^\top\mathbf{x}}\,.
\end{equation*}
Rozkład zmiennej losowej \(t\) jest  w takim razie dyskretnym rozkładem wielopunktowym (z ang.
\textit{categorical distribution}) postaci
\begin{equation*}
    t \mid \mathbf{w}_1,\ldots,\mathbf{w}_s \sim \text{Cat}(\pi_1(\mathbf{x}),\ldots,\pi_s(\mathbf{x}))\,.
\end{equation*}
Zauważmy, iż prawdopodobieństwo wylosowania etykiety \(t\) dla parametrów \(\mathbf{w}_j\) możemy
zapisać jako
\begin{equation*}
    p(t \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{j=1}^s \pi_j(\mathbf{x})^{\delta(t,\tau_j)}\,.
\end{equation*}
Powiedzmy, że mamy obserwacje \(D = (t_1,\ldots,t_m)\) dla znanych (lub zadanych) przez nas
dokładnie wektorów cech \((\mathbf{x}_1, \ldots, \mathbf{x}_m)\). Funkcja wiarygodności ma wówczas
postać
\begin{equation*}
    p(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{i=1}^m p(t_i \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{i=1}^m \prod_{j=1}^s \pi_j(\mathbf{x}_i)^{\delta(t_i,\tau_j)}\,.
\end{equation*}
Jako prior dla parametrów \(\mathbf{w}_j\) przyjmiemy rozkład normalny z pewnym hiper-parametrem
\(\gamma\)
\begin{equation*}
    \forall j\in \{1,\ldots,s\} : \mathbf{w}_j \sim \mathcal{N}(\mathbf{0}, \gamma^{-1}\oper{1})\,.
\end{equation*}
W przypadku regresji logistycznej ograniczymy się do znalezienia estymaty MAP parametrów
\(\mathbf{w}_j\) tak, aby w przyszłości do nowego wektora cech \(\mathbf{x}\) przyporządkować klasę
o największym prawdopodobieństwie \(\pi_j(\mathbf{x})\). Znalezienie estymaty MAP sprowadza się do
znalezienia minimum zregularyzowanej funkcji kosztu
\begin{equation*}
    \begin{split}
        \ell^*(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) &= -\log [p(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s ) \pi(\mathbf{w}_1, \ldots, \mathbf{w}_s)] \\
        &= - \log \left[\prod_{k=1}^s\e^{-\frac{\gamma}{2}\mathbf{w}_k^\top\mathbf{w}_k}\prod_{i=1}^m \prod_{j=1}^s \pi_j(\mathbf{x}_i)^{\delta(t_i,\tau_j)}\right]\\
        &= \frac{\gamma}{2}\sum_{j=1}^s \mathbf{w}_j^\top\mathbf{w}_j - \sum_{i=1}^m\sum_{j=1}^s \delta(t_i,\tau_j)\log\pi_j(\mathbf{x}_i)\,.
    \end{split}
\end{equation*}
Niestety dla tak zdefiniowanej funkcji kosztu nie można znaleźć wzoru na minimum w postaci
analitycznej, dlatego wykorzystamy numeryczny algorytm optymalizacji zwany spadkiem wzdłuż
gradientu.

\linesep
\subsubsection*{Metoda spadku wzdłuż gradientu}
Algorytm spadku wzdłuż gradientu (z ang. \textit{gradient descent}) dla funkcji \(f(\mathbf{x}_1,
\ldots, \mathbf{x}_m)\) ma postać
\begin{enumerate}
    \item Wybierz parametry początkowe \(\mathbf{x}_1^{(0)}, \ldots, \mathbf{x}_m^{(0)}\)
    \item Powtarzaj
    \begin{equation*}
        \begin{split}
            &\mathbf{x}_1^{(t+1)} = \mathbf{x}_1^{(t)} - \epsilon_1\pdv{f}{\mathbf{x}_1}\bigg|_{\mathbf{x}_1^{(t)}, \ldots, \mathbf{x}_m^{(t)}}\\
            &\vdots\\
            &\mathbf{x}_m^{(t+1)} = \mathbf{x}_m^{(t)} - \epsilon_m\pdv{f}{\mathbf{x}_m}\bigg|_{\mathbf{x}_1^{(t)}, \ldots, \mathbf{x}_m^{(t)}}
        \end{split}
    \end{equation*}
    gdzie \(\epsilon_1,\ldots,\epsilon_m\) to hiper-parametry zwane stałymi uczącymi (z ang.
    \textit{learning rate}).
\end{enumerate}
Zakładając \(\epsilon_1 = \ldots = \epsilon_m = \epsilon\) i wprowadzając
\begin{equation*}
    \oper{X} := \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,,\quad \pdv{f}{\oper{X}} := \mqty[\pdv{f}{\mathbf{x}_1}^\top \\ \vdots \\ \pdv{f}{\mathbf{x}_m}^\top]
\end{equation*}
możemy zapisać powyższe równania w kompaktowej formie
\begin{equation*}
    \oper{X}^{(t+1)} = \oper{X}^{(t)} - \epsilon \pdv{f}{\oper{X}}\bigg|_{\oper{X}^{(t)}}\,.
\end{equation*}
\linesep

Aby zminimalizować numerycznie funkcję kosztu \(\ell^*\) stosując metodę spadku wzdłuż gradientu
musimy obliczyć pochodne funkcji kosztu po parametrach \(\mathbf{w}_j\)
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k - \sum_{i=1}^m\sum_{j=1}^s \delta(t_i,\tau_j)\pdv{~}{\mathbf{w}_k}\log\pi_j(\mathbf{x}_i)\,,
\end{equation*}
ale
\begin{equation*}
    \begin{split}
        \pdv{~}{\mathbf{w}_k}\log\pi_j(\mathbf{x}_i) &= \frac{1}{\pi_j(\mathbf{x}_i)}\frac{Z(\mathbf{x}_i)\pdv{\e^{\mathbf{x}_i^\top\mathbf{w}_j}}{\mathbf{w}_k} - \e^{\mathbf{x}_i^\top\mathbf{w}_j}\pdv{Z(\mathbf{x}_i)}{\mathbf{w}_k}}{Z^2(\mathbf{x}_i)}\\
        &= \frac{Z(\mathbf{x}_i)}{\e^{\mathbf{x}_i^\top\mathbf{w}_j}}\frac{Z(\mathbf{x}_i)\mathbf{x}_i\e^{\mathbf{x}_i^\top\mathbf{w}_k}\delta_{jk} - \e^{\mathbf{x}_i^\top\mathbf{w}_j}\e^{\mathbf{x}_i^\top\mathbf{w}_k}\mathbf{x}_i}{Z^2(\mathbf{x}_i)}\\
        &= \mathbf{x}_i\delta_{jk} - \mathbf{x}_i\pi_k(\mathbf{x}_i)
    \end{split}
\end{equation*}
zatem
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k - \sum_{i=1}^m\mathbf{x}_i\sum_{j=1}^s \delta(t_i, \tau_j)\delta_{jk} + \sum_{i=1}^m\mathbf{x}_i\pi_k(\mathbf{x}_i)\sum_{j=1}^s\delta(t_i, \tau_j)\,.
\end{equation*}
Zauważmy jednak, iż
\begin{equation*}
    \sum_{j=1}^s\delta(t_i, \tau_j) = 1\,,\quad \sum_{j=1}^s \delta(t_i, \tau_j)\delta_{jk} = \delta(t_i, \tau_k)\,,
\end{equation*}
zatem ostatecznie
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k + \sum_{i=1}^m \mathbf{x}_i\left[\pi_k(\mathbf{x}_i) - \delta(t_i, \tau_k)\right]\,.
\end{equation*}
Wprowadzając macierze
\begin{equation*}
    \begin{split}
        &\oper{X} = \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,,\quad \oper{W} = \mqty[\mathbf{w}_1^\top \\ \vdots \\ \mathbf{w}_s^\top]\,,\\
        &\oper{S} = \mqty[\pi_1(\mathbf{x}_1) & \cdots & \pi_s(\mathbf{x}_1) \\ \vdots & \ddots & \vdots \\ \pi_1(\mathbf{x}_m) & \cdots & \pi_s(\mathbf{x}_m)]\,,\quad \oper{T} = \mqty[\delta(t_1,\tau_1) & \cdots & \delta(t_1,\tau_s) \\ \vdots & \ddots & \vdots \\ \delta(t_m, \tau_1) & \cdots & \delta(t_m, \tau_s)]
    \end{split}
\end{equation*}
możemy w takim razie zapisać zdefiniowaną wyżej macierz pochodnych wymaganych do algorytmu spadku
wzdłuż gradient w kompaktowej formie jako
\begin{equation*}
    \pdv{\ell^*}{\oper{W}} = (\oper{S} - \oper{T})^\top\oper{X}\,.
\end{equation*}
Zauważmy, iż zregularyzowana funkcja kosztu rośnie wraz ze wzrostem liczby obserwacji \(m\). Wynika
z tego, iż stała ucząca musi być zależna od liczby przykładów. Możemy na przykład stwierdzić, iż
\(\epsilon \leftarrow m^{-1}\epsilon\) i wówczas minimalizujemy tak naprawdę średni koszt \(\ell^* /
m\).

\subsubsection*{Wnioskowanie metodami Monte Carlo}

Całe wnioskowanie Bayesowskie opiera się na wyznaczaniu rozkładów a posteriori, które wyrażają naszą
wiedzę o estymowanym parametrze. Do tej pory rozważaliśmy modele Bayesowskie dla których prior i
wiarygodność były dane przez rozkłady normalne. Dzięki temu mogliśmy wyprowadzić analityczne wzory
na parametry rozkładu a posteriori, który również był rozkładem normalnym. Dla wielu interesujących
modeli nie jesteśmy jednak w stanie tego zrobić (np. w zagadnieniu regresji logistycznej
ograniczyliśmy się jedynie do estymaty punktowej), gdyż obliczenie stałej normalizującej dla
rozkładu \(p(\theta \mid D)\) może wymagać obliczenia całki, której nie jesteśmy w stanie wyrazić w
sposób jawny lub sumy po wykładniczo wielu elementach. Wnioskowanie Bayesowskie można jednak
prowadzić w modelach, w których nie dysponujemy jawnym wzorem na gęstość prawdopodobieństwa rozkładu
a posteriori. Okazuje się, iż do generowania próbek z rozkładu \(p(\theta \mid D)\) wystarcza
znajomość tego rozkładu z dokładnością do stałej normalizującej, a zatem wystarczy znać rozkład
łączny \(p(\theta, D) = p(D\mid\theta)\pi(\theta)\). Generowanie próbek z kolei wystarcza natomiast,
na mocy silnego prawa wielkich liczb, do szacowania wartości średnich dowolnych funkcji estymowanego
parametru \(\theta\). Przypomnijmy, iż na mocy silnego prawa wielkich liczb ciąg średnich
częściowych \((\overline{X}_n)\) ciągu zmiennych losowych \((X_n)\) i.i.d. z rozkładu \(X \sim
\mathcal{D}\) jest zbieżny z prawdopodobieństwem 1 do wartości oczekiwanej \(\mathbb{E}[X]\) tj.
\begin{equation*}
    P\left(\lim_{n \to \infty} \overline{X}_n = \mathbb{E}[X]\right) = 1\,.
\end{equation*}
Wartość oczekiwaną \(\mathbb{E}[X]\) możemy zatem przybliżyć średnią \(\overline{X}_n\) z dużej
ilości próbek.

Wnioskowanie Monte Carlo pozwala nam szacować różne wielkości w tzw. hierarchicznych modelach
Bayesowskich (z ang. \textit{Bayesian hierarchical modeling}). Rozważmy jeszcze raz przykład
regresji liniowej w ujęciu Bayesowskim, ale rozważmy teraz model postaci
\begin{equation*}
    \begin{split}
        \sigma^2 &\sim \mathcal{D}(\lambda)\\
        \mathbf{w} &\sim \mathcal{N}(\boldsymbol{\mu}_0, \oper{\Sigma}_0)\\
        y \mid \mathbf{w}, \sigma^2 &\sim \mathcal{N}(\mathbf{w}^\top\mathbf{x}, \sigma^2)
    \end{split}\quad,
\end{equation*}
gdzie \(\lambda, \boldsymbol{\mu}_0, \oper{\Sigma}_0\) są pewnymi hiper-parametrami. Dla takiego
modelu nie możemy w ogólności znaleźć jawnej postaci rozkładu a posteriori. Jeśli jednak umiemy
generować próbki z rozkładu łącznego
\begin{equation*}
    Z\cdot p(\mathbf{w}, \sigma^2 \mid D) = p(D, \mathbf{w}, \sigma^2) = p(D \mid \mathbf{w},\sigma^2)\pi(\mathbf{w})\pi(\sigma^2)
\end{equation*}
to wszystkie interesujące wielkości możemy oszacować jako odpowiednie średnie.
\linesep
\subsubsection*{Algorytm Importance Sampling (IS)}

Załóżmy, iż chcemy obliczyć wartość oczekiwaną pewnej funkcji zmiennej losowej \(\mathbf{x}\)
względem skomplikowanego rozkładu prawdopodobieństwa \(p(\mathbf{x})\), który znamy jedynie z
dokładnością do stałej normalizującej
\begin{equation*}
    p(\mathbf{x}) = \frac{1}{Z_p}\tilde{p}(\mathbf{x})
\end{equation*}
tj. szukamy
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] = \int f(\mathbf{x}) p(\mathbf{x}) \dd[n]\mathbf{x}\,.
\end{equation*}
Jeśli umiemy generować próbki \(\mathbf{x}\) z innego rozkładu \(q(\mathbf{x})\), który nazywamy
rozkładem proponującym kandydatów (z ang. \textit{proposal distribution}) to możemy zapisać
\begin{equation*}
    \begin{split}
        \mathbb{E}_p[f(\mathbf{x})] &= \int f(\mathbf{x}) p(\mathbf{x}) \dd[n]\mathbf{x} = \int f(\mathbf{x}) \frac{p(\mathbf{x})}{q(\mathbf{x})} q(\mathbf{x}) \dd[n]\mathbf{x}\\
         &=\mathbb{E}_q\left[f(\mathbf{x}) \frac{p(\mathbf{x})}{q(\mathbf{x})}\right] = \frac{Z_q}{Z_p}\mathbb{E}_q\left[f(\mathbf{x}) \frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]\,.
    \end{split}\quad.
\end{equation*}
Stosunek stałych \(Z_p / Z_q\) również możemy oszacować z próbek z \(q\), gdyż mamy
\begin{equation*}
    Z_p = \int \tilde{p}(\mathbf{x}) \dd[n]{\mathbf{x}} = Z_q\int \frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})} q(\mathbf{x})\dd[n]{\mathbf{x}} = Z_q \mathbb{E}_q\left[\frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]\,,
\end{equation*}
skąd ostatecznie
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] = \frac{\mathbb{E}_q\left[f(\mathbf{x}) \frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]}{\mathbb{E}_q\left[\frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]}\,.
\end{equation*}
Jeśli z rozkładu \(q\) wygenerowaliśmy próbki \(X =
\left\{\mathbf{x}_1,\ldots,\mathbf{x}_m\right\}\) to na mocy silnego prawa wielkich liczb mamy
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] \approx \frac{\sum_{i=1}^m f(\mathbf{x}_i) \frac{\tilde{p}(\mathbf{x}_i)}{\tilde{q}(\mathbf{x}_i)}}{\sum_{i=1}^m \frac{\tilde{p}(\mathbf{x}_i)}{\tilde{q}(\mathbf{x}_i)}} = \sum_{i=1}^m \lambda_i f(\mathbf{x}_i)\,,
\end{equation*}
gdzie
\begin{equation*}
    \lambda_i = \frac{\tilde{p}(\mathbf{x}_i) / \tilde{q}(\mathbf{x}_i)}{\sum_{j=1}^m \tilde{p}(\mathbf{x}_j) / \tilde{q}(\mathbf{x}_j) }\,.
\end{equation*}

\linesep

\subsubsection*{Markov Chain Monte Carlo (MCMC)}

\linesep


\end{document}
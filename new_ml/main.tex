\documentclass{myclass}
\usepackage[polish]{babel}

% My notes on ML and related concepts
\author{Bartosz Hanc}

\tikzset{%
  every neuron/.style={ circle, draw, minimum size=1cm }, neuron missing/.style={ draw=none,
    scale=4, text height=0.333cm, execute at begin node=\color{black}$\vdots$ }, }

\begin{document}
\tableofcontents
\newpage

\section{Rachunek prawdopodobieństwa}

\subsection{Definicja przestrzeni probabilistycznej}

Rozkładem prawdopodobieństwa \(P\) w pewnym zbiorze zdarzeń elementarnych \(\Omega \neq \emptyset\)
nazywamy odwzorowanie
\begin{equation*}
    P: \Sigma \mapsto [0;1]\,,
\end{equation*}
gdzie \(\Sigma\) jest rodziną podzbiorów \(\Omega\) (inaczej rodziną zdarzeń) taką, że
\begin{equation*}
    \Omega \in \Sigma\,,\quad A \in \Sigma \implies A' \in \Sigma\,,\quad \forall A_1, A_2, \ldots \in \Sigma : \bigcup_{i}
    A_i \in \Sigma\,,
\end{equation*}
które spełnia: \(P(\Omega) = 1\) oraz dla dowolnych parami rozłącznych zdarzeń \(A_1, A_2, \ldots
\in \Sigma\) zachodzi
\begin{equation*}
    P\left(\bigcup_i A_i\right) = \sum_i P(A_i)\,.
\end{equation*}
Trójkę \((\Omega, \Sigma, P)\) nazywamy przestrzenią probabilistyczną. Z powyższej definicji
wynikają znane własności prawdopodobieństwa tj. \(P(A') = 1 - P(A)\) oraz \(P(A \cup B) = P(A) +
P(B) - P(A , B)\). 

\subsection{Prawdopodobieństwo warunkowe}

Definiujemy również prawdopodobieństwo warunkowe zdarzenia \(A\) pod warunkiem zdarzenia \(B\) o
dodatnim prawdopodobieństwie 
\begin{equation*}
    P(A \mid B) := \frac{P(A , B)}{P(B)}\,.
\end{equation*}
Na podstawie powyższej definicji definiujemy niezależność zdarzeń \(A\), \(B\) jako własność
\(P(A,B) = P(A)P(B)\), co dla zdarzenia \(B\) o dodatnim prawdopodobieństwie jest równoważne z \(P(A
\mid B) = P(A)\). Ponadto jeśli zdarzenia \(A_1, A_2, \ldots \in \Sigma\) są parami rozłączne i
zachodzi \(\bigcup_i A_i = \Omega\) to dla dowolnego zdarzenia \(B \in \Sigma\) możemy zapisać
\begin{equation*}
    P(B) = \sum_i P(B \mid A_i) P(A_i)\,.
\end{equation*}
Z definicji prawdopodobieństwa warunkowego trywialnie udowodnić twierdzenie Bayesa
\begin{equation*}
    P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}\,.
\end{equation*}

\subsection{Zmienne losowe}

W uczeniu maszynowym będą interesować nas zmienne o wartościach w \(\mathbb{R}^n\). Zmienne takie
nazywamy zmiennymi losowymi wielowymiarowymi i definiujemy jako odwzorowania
\begin{equation*}
    X: \Omega \mapsto \mathbb{R}^n
\end{equation*}
takie, że dla każdego \(A \subseteq \mathbb{R}^n\) zbiór \(\{\omega \in \Omega \mid X(\omega) \in
A\}\) należy do rodziny zdarzeń \(\Sigma\). Przy takiej definicji prawdopodobieństwo, iż zmienna
\(X\) ma wartość należącą do pewnego przedziału \(A\) wynosi
\begin{equation*}
    P(X \in A) = P(\{\omega \in \Omega \mid X(\omega) \in A\})\,.
\end{equation*}

Dowolny rozkład prawdopodobieństwa zmiennej losowej \(n\)--wymiarowej \(X = (X_1, X_2, \ldots,
X_n)\) jest wyznaczony jednoznacznie przez zadanie funkcji \(F(\mathbf{x}): \mathbb{R}^n \mapsto
[0;1]\) zwanej dystrybuantą zdefiniowanej jako
\begin{equation*}
    F(\mathbf{x}) = F(x_1, \ldots, x_n) := P(X_1 \leq x_1, \ldots, X_n \leq x_n)\,.
\end{equation*}
Zasadniczo będą nas interesować jednak dwa przypadki rozkładów prawdopodobieństwa zmiennych
losowych: rozkłady dyskretne i rozkłady ciągłe. W przypadku rozkładu dyskretnego istnieje pewien
przeliczalny zbiór \(S \subset \mathbb{R}^n\) taki, że \(P(X \in S) = 1\). Rozkład ten jest zadany
jednoznacznie przez podanie \(|S|\) liczb \(p_i > 0\) określających prawdopodobieństwa \(p_i = P(X =
\mathbf{x}_i)\) dla wszystkich \(\mathbf{x}_i \in S\). W przypadku rozkładu ciągłego istnieje z
kolei funkcja \(p(\mathbf{x}): \mathbb{R}^n \mapsto [0; \infty)\) taka, że
\begin{equation*}
    P(X_1 \in [a_1; b_1], \ldots, X_n \in [a_n; b_n]) = \int\limits_{a_1}^{b_1}\cdots\int\limits_{a_n}^{b_n}p(\mathbf{x})\dd[n]{\mathbf{x}}\,.
\end{equation*}
Funkcje \(p(\mathbf{x})\) nazywamy gęstością prawdopodobieństwa. W obu przypadkach musi być
spełniony warunek unormowania postaci odpowiednio
\begin{equation*}
    \sum_i p_i = 1\,,\quad \int\limits_{\mathbb{R}^n}p(\mathbf{x})\dd[n]{\mathbf{x}} = 1\,.
\end{equation*}

Będziemy często wykorzystywać wartość oczekiwaną pewnej funkcji \(f(\mathbf{x})\) zmiennej losowej
\(X\) zdefiniowaną odpowiednio dla rozkładu \(p\) -- dyskretnego lub ciągłego jako
\begin{equation*}
    \mathbb{E}[f(\mathbf{x})] := \sum_{\mathbf{x}_i \in S} f(\mathbf{x}_i)p_i \cong \int\limits_{\mathbb{R}^n}f(\mathbf{x})p(\mathbf{x})\dd[n]{\mathbf{x}}\,.
\end{equation*}
Zauważmy przy tym, iż funkcja \(f(\mathbf{x})\) może być zupełnie dowolna, np. dla funkcji
charakterystycznej (indykatorowej) zbioru \(A \subset \mathbb{R}^n\) \(f(\mathbf{x}) =
\mathcal{I}_A\) mamy \(\mathbb{E}[\mathcal{I}_A(\mathbf{x})] = P(X \in A)\) lub dla iloczynu funkcji
Heaviside'a \(f(\mathbf{x}) = \theta(t_1 - x_1)\cdots\theta(t_n - x_n)\) mamy
\(\mathbb{E}[f(\mathbf{x})] = F(t_1,\ldots, t_n)\).

\subsection{Rozkłady brzegowe}

Niech \(X = (X_1, \ldots, X_n)\) będzie \(n\)--wymiarową zmienną losową o dystrybuancie
\(F(\mathbf{x})\). Rozkład brzegowy względem \(k\) zmiennych \(X_{\sigma(1)},\ldots,X_{\sigma(k)}\)
definiujemy jako rozkład wyznaczony przez dystrybuantę
\begin{equation*}
    F_{X_{\sigma(1)},\ldots,X_{\sigma(k)}} (x_{\sigma(1)},\ldots,x_{\sigma(k)}) := \lim_{x_{\sigma(k+1)}\to\infty,\ldots,x_{\sigma(n)}\to\infty} F(x_1,\ldots,x_n)\,.
\end{equation*}

\subsection{Zmienne losowe niezależne}
Niech \(X = (X_1, \ldots, X_k)\) będzie \(n\)--wymiarową zmienną losową o rozkładzie wyznaczonym
przez dystrybuantę \(F(\mathbf{x})\). Powiemy, iż zmienne losowe \(n_1,\ldots,n_k\) -- wymiarowych
(\(n_1 + \ldots + n_k = n\)) \(X_1, \ldots, X_k\) są niezależne iff dla dowolnych
\(\mathbf{x}_1\in\mathbb{R}^{n_1},\ldots,\mathbf{x}_k\in\mathbb{R}^{n_k}\) zachodzi
\begin{equation*}
    F(\mathbf{x}_1,\ldots,\mathbf{x}_k) = F_{X_1}(\mathbf{x}_1)\cdot\ldots\cdot F_{X_k}(\mathbf{x}_k)\,.
\end{equation*}

\subsection{Funkcja tworząca momenty}

Funkcją tworzącą momenty (z ang. \textit{moment generating function}) nazywamy funkcję określoną
wzorem
\begin{equation*}
    M_X(t) := \mathbb{E}\left[\e^{t X}\right]
\end{equation*}
dla zmiennej losowej rzeczywistej \(X: \Sigma \mapsto \mathbb{R}\). Powyższa wielkość jest określona
zawsze tylko dla \(t=0\). Dla innych \(t\), \(M_X(t)\) może w ogólności nie istnieć. MGF używamy,
aby łatwiej obliczać momenty różnych rzędów. Istotnie jeśli \(M_X(t)\) istnieje w pewnym otoczeniu
\(t=0\) to
\begin{equation*}
    \mathbb{E}[X^k] = \dv[k]{M_X}{t}\Big|_{t=0}\,.
\end{equation*}
Jednocześnie łatwo pokazać, że zachodzi \(M_X(at) = M_{aX}(t)\) oraz \(M_{X+b}(t) = M_X(t)\e^{tb}\).

\subsection{Funkcja charakterystyczna}

Funkcję charakterystyczną rozkładu o gęstości \(p(x)\) definiujemy jako
\begin{equation*}
    \varphi_X(x) = \mathbb{E}\left[\e^{\im t x}\right] = \int\limits_{-\infty}^{+\infty} p(x)\e^{\im tx} \dd{x}\,.
\end{equation*}
Widzimy, iż jest to zatem transformata Fouriera funkcji gęstości. Funkcja charakterystyczna koduje
pełną informację o rozkładzie i możemy wyciągną z niej funkcję gęstości przez zastosowanie odwrotnej
transformacji Fouriera.

\subsection{Rozkłady warunkowe}

W ogólnym przypadku zmiennej losowej \(n\) -- wymiarowej \(Z = (Z_1, \ldots, Z_n)\) o ciągłym
rozkładzie \(p(\mathbf{z})\) jeśli wydzielimy zmienne \(k\) i \(n-k\) -- wymiarowe \(X =
(Z_{\sigma(1)}, \ldots, Z_{\sigma(k)})\), \(Y = (Z_{\sigma(k+1)}, \ldots, Z_{\sigma(n)})\) to
rozkład warunkowy zmiennej \(X \mid Y\) definiujemy jako rozkład zadany przez gęstość
prawdopodobieństwa
\begin{equation*}
    p(\mathbf{x} \mid \mathbf{y}) := \frac{p(\mathbf{z})}{p_Y(\mathbf{y})} = \frac{p(\mathbf{x},\mathbf{y})}{p_Y(\mathbf{y})}\,.
\end{equation*}

\subsection{Transformacja zmiennych wielowymiarowych}

Niech \(X = (X_1, \ldots, X_n)\) będzie zmienną losową wielowymiarową o rozkładzie ciągłym o
gęstości \(p_X(\mathbf{x})\). Rozważmy bijekcję \((X_1, \ldots, X_n) \mapsto (Y_1, \ldots, Y_n)\).
Chcemy znaleźć wyrażenie na gęstość \(p_Y(\mathbf{y})\) w nowych zmiennych. Ponieważ infinitezymalne
prawdopodobieństwo jest niezmiennicze względem zmiany współrzędnych więc zachodzi
\begin{equation*}
    p_X(x_1,\ldots, x_n)\dd{x_1}\ldots\dd{x_n} = p_Y(y_1,\ldots, y_n)\dd{y_1}\ldots\dd{y_n}\,,
\end{equation*}
skąd
\begin{equation*}
    p_Y(y_1,\ldots,y_n) = \left|\frac{\partial(x_1,\ldots,x_n)}{\partial(y_1,\ldots,y_n)}\right|p_X(x_1(\mathbf{y}),\ldots,x_n(\mathbf{y}))\,.
\end{equation*}

\subsection{Macierz kowariancji}

Macierz kowariancji funkcji \(f(\mathbf{x})\) zmiennej losowej \(X\) definiujemy jako
\begin{equation*}
    \oper{\Sigma}[f(\mathbf{x})] := \mathbb{E}\left[(f(\mathbf{x}) - \boldsymbol{\mu}_f)(f(\mathbf{x}) - \boldsymbol{\mu}_f)^\top\right]\,,
\end{equation*}
gdzie \(\boldsymbol{\mu}_f = \mathbb{E}[f(\mathbf{x})]\). Elementy diagonalne
\(\mathsf{\Sigma}_{ii}\) tej macierzy nazywamy wariancjami zmiennych \(X_i\), natomiast elementy
pozadiagonalne \(\mathsf{\Sigma}_{ij}\) nazywamy kowariancjami zmiennych \(X_i\) i \(X_j\).
Oczywiście \(\oper{\Sigma}\) jest macierzą symetryczną. Nadto jeśli \(f\) jest funkcją
identycznościową tj. \(f(\mathbf{x}) = \mathbf{x}\) to \(\oper{\Sigma}\) jest macierzą nieujemnie
określoną, gdyż dla dowolnego \(\mathbf{v} \in \mathbb{R}^n\) mamy
\begin{equation*}
    \mathbf{v}^\top \oper{\Sigma} \mathbf{v} = \mathbb{E}[\mathbf{v}^\top (\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{v}] = \mathbb{E}[z^2] \geq 0\,,
\end{equation*}
gdzie \(z = \mathbf{v}^\top (\mathbf{x} - \boldsymbol{\mu}) \in \mathbb{R}\). Jeśli \(X_1, \ldots,
X_n\) są niezależne i \(f\) jest funkcją identycznościową to \(\oper{\Sigma}\) jest macierzą
diagonalną.

\subsection{Wielowymiarowy rozkład normalny}

Jeśli zmienna wielowymiarowa \(X = (X_1, \ldots, X_n)\) ma wielowymiarowy rozkład normalny (z ang.
\textit{Multivariate Normal distribution -- MVN}) z wartością oczekiwaną \(\boldsymbol{\mu}\) i
macierzą kowariancji \(\oper{\Sigma}\), co oznaczamy jako \(X \sim \mathcal{N}(\boldsymbol{\mu},
\oper{\Sigma})\), to gęstość prawdopodobieństwa jest dana
\begin{equation*}
    \phi(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^n\det\oper{\Sigma}}}\exp\left\{-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^\top\oper{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})\right\}
\end{equation*}
Macierz \(\oper{\Lambda} = \oper{\Sigma}^{-1}\) nazywamy macierzą precyzji. Jeśli \(\mathbf{v}_i\)
są unormowanymi wektorami własnymi macierzy \(\oper{\Sigma}\), a \(\lambda_i\) odpowiadającymi im
wartościami własnymi i zakładając, iż widmo \(\{\lambda_i\}\) jest niezdegenerowane mamy z
twierdzenia spektralnego
\begin{equation*}
    \oper{\Lambda} = \sum_{i=1}^n\frac{1}{\lambda_i}\mathbf{v}_i\mathbf{v}_i^\top
\end{equation*}
oraz wiemy, iż wektory \(\{\mathbf{v}_i\}\) tworzą bazę ortonormalną przestrzeni \(\mathbb{R}^n\). Z
powyższego możemy zatem wyrazić wektor \(\mathbf{x} - \boldsymbol{\mu}\) jako kombinację liniową
wektorów \(\{\mathbf{v}_i\}\) tj.
\begin{equation*}
    \mathbf{x} - \boldsymbol{\mu} = \sum_{i=1}^n t_i\mathbf{v}_i\,,
\end{equation*}
co pozwala zapisać gęstość prawdopodobieństwa jako
\begin{equation*}
    \phi(t_1,\ldots,t_2) \cong \exp\left\{-\frac{1}{2}\sum_{i=1}^n\frac{t_i^2}{\lambda_i}\right\}\,.
\end{equation*}
Z powyższego wzoru widać, iż poziomice gęstości są wielowymiarowymi elipsoidami, których półosie są
skierowane wzdłuż wektorów własnych \(\oper{\Sigma}\) i mają długości proporcjonalne do
\(\sqrt{\lambda_i}\).

Powiemy, iż wielowymiarowa zmienna losowa \(X \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) ma
standardowy wielowymiarowy rozkład normalny jeśli \(\boldsymbol{\mu} = \mathbf{0}\) i
\(\oper{\Sigma} = \oper{1}\). Wówczas
\begin{equation*}
    \phi(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^n}}\exp\left\{-\frac{1}{2}\mathbf{x}^\top\mathbf{x}\right\}\,.
\end{equation*}

Można wykazać, iż jeśli \(X \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) dla
\(\oper{\Sigma}\) o niezdegenerowanym widmie to wszystkie rozkłady brzegowe i warunkowe \(X\) są
rozkładami normalnymi.

\subsection{Zbieżność w rachunku prawdopodobieństwa}

W rachunku prawdopodobieństwa definiujemy trzy zasadnicze rodzaje zbieżności ciągu zmiennych
losowych \((X_n)\). 
\begin{itemize}
    \item Ciąg \((X_n)\) jest zbieżny do \(X\) stochastycznie iff
    \begin{equation*}
        \forall \epsilon > 0: \lim_{n\to\infty} P(|X_n - X| < \epsilon) = 1\,.
    \end{equation*}

    \item Ciąg \((X_n)\) jest zbieżny do \(X\) z prawdopodobieństwem 1 iff
    \begin{equation*}
        P\left(\lim_{n\to\infty} X_n = X\right) = 1\,.
    \end{equation*}

    \item Ciąg \((X_n)\) \(n\)--wymiarowych zmiennych losowych jest zbieżny do \(X\) według
    dystrybuant iff
    \begin{equation*}
        \forall \mathbf{x} \in \mathbb{R}^n, F_X(\mathbf{x}) \text{ -- ciągła w \(\mathbf{x}\)}: \lim_{n\to\infty} F_{X_n}(\mathbf{x}) = F_X(\mathbf{x})
    \end{equation*}

\end{itemize}

Pomiędzy tak zdefiniowanymi rodzajami zbieżności zachodzą następujące implikacje:
\begin{enumerate}
    \item \(X_n \to X\) z prawdopodobieństwem 1 \(\implies\) \(X_n \to X\) stochastycznie
    \item \(X_n \to X\) stochastycznie \(\implies\) \(X_n \to X\) według dystrybuant
    \item \(X_n \to X\) stochastycznie \(\implies\) istnieje podciąg \((X_{n_k})\) zbieżny do \(X\)
    z prawdopodobieństwem 1
\end{enumerate}

\subsection{Rozkłady prawdopodobieństwa}
\subsubsection{Rozkład Bernoulliego}
Jeśli zmienna losowa ma wartości w zbiorze \(\{x_1, x_2\}\) oraz \(P(X = x_1) = p\) i \(P(X = x_2) =
1 - p\) (dla \(0\leq p \leq 1\)) to mówimy, że \(X \sim \text{Ber}(p)\) (zmienna \(X\) ma rozkład
Bernoulliego z parametrem \(p\)).

\subsubsection{Rozkład dwumianowy}
Próbą Bernoulliego nazywamy doświadczenie losowe, którego wynik \(X \sim \text{Ber}(p)\). Schematem
dwumianowym nazywamy \(n\)--krotne powtórzenie próby Bernoulliego przy założeniu, iż poszczególne
próby są niezależne. Jeśli \(S\) będzie zmienną losową o wartościach w \(\mathbb{N} \cup \{0\}\),
która opisuje liczbę sukcesów w schemacie dwumianowym długości \(n\). Wówczas
\begin{equation*}
    P(S = k) = {n \choose k} p^k (1 - p)^{n-k}
\end{equation*}
i mówimy, że \(S \sim \text{Bin}(n, p)\) (zmienna \(S\) ma rozkład dwumianowy z parametrami \(n,
p\)).

\subsubsection{Rozkład geometryczny}
Rozważamy schemat Bernoulliego o nieskończonej długości. Jeśli \(T\) będzie zmienną losową o
wartościach w \(\mathbb{N} \cup \{0\}\), która opisuje liczbę prób Bernoulliego z paramterem \(p\)
do momentu uzyskania pierwszego sukcesu to
\begin{equation*}
    P(T=k) = (1-p)^{k-1}p
\end{equation*}
i mówimy, że \(T \sim \text{Geo}(p)\) (zmienna \(T\) ma rozkład geometryczny z parametrem \(p\)).

\subsubsection{Rozkład Poissona}
Załóżmy, iż mamy dany skończony przedział czasowy \([0; \tau]\) dla pewnego \(\tau\). Niech zmienna
losowa \(N\) o wartościach w \(\mathbb{N} \cup \{0\}\) opisuje liczbę wystąpień pewnego zdarzenia w
tym przedziale, przy czym
\begin{itemize}
    \item zdarzenia występują niezależnie od siebie
    \item intensywność wystąpień jest stała
\end{itemize}
to 
\begin{equation*}
    P(N = k) = \frac{\e^{-\lambda}\lambda^k}{k!}
\end{equation*}
i mówimy, że \(N \sim \text{Pois}(\lambda)\) (zmienna \(N\) ma rozkład Poissona z parametrem
\(\lambda\)). Zachodzi ponadto \textbf{twierdzenie Poissona}: niech \((S_n)\) będzie ciągiem takim,
że \(S_n \sim \text{Bin}(n, p_n)\), gdzie ciąg \((p_n)\) jest taki, iż \(\lim_{n \to \infty} np_n =
\lambda\), wówczas \(\lim_{n\to\infty}P(S_n = k) = \e^\lambda \lambda^k / k!\).

\subsubsection{Rozkład jednostajny}
Jeśli zmienna losowa \(X\) o wartościach rzeczywistych ma gęstość prawdopodobieństwa daną przez
\begin{equation*}
    p(x) = \begin{cases}
        \frac{1}{b - a}\,,\quad &x \in [a;b]\\
        0\,, &x \notin [a;b]
    \end{cases}
\end{equation*}
to mówimy \(X \sim \mathcal{U}(a,b)\) (zmienna \(X\) ma rozkład jednostajny na odcinku \([a;b]\)).

\subsubsection{Rozkład wykładniczy}
Jeśli zmienna losowa \(T\) o wartościach rzeczywistych opisuje prawdopodobieństwo uzyskania
pierwszego zdarzenia po czasie \(x\) modelowanego przez rozkład \(\text{Pois}(\lambda)\) to
\begin{equation*}
    p(x) = \begin{cases}
        \lambda \e^{-\lambda x}\,, &x \geq 0\\
        0\,, &x < 0 
    \end{cases}
\end{equation*}
i mówimy \(T \sim \text{Exp}(\lambda)\) (zmienna \(T\) ma rozkład wykładniczy z parametrem
\(\lambda\)).

\subsubsection{Rozkład gamma}
Mówimy, że zmienna \(X\) o wartościach rzeczywistych ma rozkład gamma z parametrami \(p, a > 0\) tj.
\(X \sim \Gamma(p, a)\) iff gęstość prawdopodobieństwa ma postać
\begin{equation*}
    p(x) = \begin{cases}
        \frac{a^p}{\Gamma(p)}x^{p-1}\e^{-ax}\,, &x > 0\\
        0\,, &x \leq 0
    \end{cases}\quad,
\end{equation*}
gdzie \(\Gamma\) to funkcja Eulera. Parametr \(p\) nazywamy parametrem kształtu, a \(a\) --
parametrem intensywności. Szczególnym przypadkiem rozkładu gamma jest rozkład \(\chi^2\)
zdefiniowany jako rozkład \(\chi^2(n) := \Gamma(n/2, 1/2)\).

\section{Elementarz teorii informacji}

\subsection{Definicja i własności entropii}

Mając dany skończony zbiór zdarzeń elementarnych \(\{A_1,\ldots,A_n\}\) taki, że wynikiem
eksperymentu losowego może być dokładnie jedno z nich oraz prawdopodobieństwa \(p_1,\ldots,p_n\),
\(\sum_{i}p_i = 1\) każdego z nich powiemy, iż
\begin{equation*}
    A := \mqty(A_1 & A_2 & \cdots & A_n \\ p_1 & p_2 & \cdots & p_n)
\end{equation*} 
jest \textit{schematem skończonym} (z ang. \textit{finite scheme}). Przykładowo rzut sprawiedliwą,
sześcienną kostką do gry jest opisany przez schemat
\begin{equation*}
    \mqty(A_1 & A_2 & A_3 & A_4 & A_5 & A_6 \\ 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6) \,.
\end{equation*} 
Zauważmy, że każdy schemat skończony opisuje pewną \textit{niepewność} dotyczącą doświadczenia
losowego. Przykładowo jest oczywiste, iż dla schematów
\begin{equation*}
    \mqty(A_1 & A_2 \\ 0.99 & 0.01)\,,\quad \mqty(A_1 & A_2 \\ 0.5 & 0.5)
\end{equation*}
pierwszy z nich opisuje znacznie mniejszą niepewność od drugiego, gdyż prawie z pewnością wynikiem
eksperymentu losowego będzie \(A_1\). Wprowadzimy teraz wielkość, która w sensowny sposób mierzy
ilość niepewności w danym schemacie skończonym. Wielkością taką jest \textit{entropia Shannona}
zdefiniowana dla schematu
\begin{equation*}
    A = \mqty(A_1 & A_2 & \cdots & A_n \\ p_1 & p_2 & \cdots & p_n)
\end{equation*}
jako
\begin{equation*}
    H(A) = H(p_1,p_2,\ldots,p_n) := -\sum_{i=1}^n p_i\lg p_i\,,
\end{equation*}
gdzie możemy wybrać dowolną ustaloną podstawę logarytmu oraz stwierdzamy, iż jeśli \(p_k = 0\) to
\(p_k \lg p_k = 0\). Jeśli jako podstawę wybierzemy liczbę 2 to entropię mierzymy w \textit{bitach}
tj. 1 bit jest to ilość niepewności zawarta w schemacie skończonym o  dwóch jednakowo
prawdopodobnych wynikach
\begin{equation*}
    H = -\log_2\frac{1}{2} = 1\,.
\end{equation*}
Przekonamy się teraz, iż tak zdefiniowana miara niepewności ma szereg własności, których
spodziewalibyśmy się dla sensownej miary niepewności. Zauważmy wpierw, iż \(H(p_1,\ldots,p_n) = 0\)
iff dokładnie jedno zdarzenie \(A_k \in A\) jest pewne, a pozostałe niemożliwe. Zauważmy dodatkowo,
iż z nierówności Jensena mamy dla funkcji wypukłej \(\phi(x) = x \lg x\)
\begin{equation*}
    \phi\left(\sum_{i=1}^n \lambda_i x_i\right) \leq \sum_{i=1}^n \lambda_i \phi(x_i)\,,
\end{equation*}
dla dowolnych \(x_1,\ldots,x_n \in \mathbb{R}\) i \(\lambda_1,\ldots,\lambda_n \in [0;1]\), \(\sum_i
\lambda_i = 1\), skąd
\begin{equation*}
    \frac{1}{n}\lg\frac{1}{n} \leq \frac{1}{n}\sum_{i=1}^n p_i \lg p_i = - \frac{1}{n}H(p_1,\ldots,p_n)\,,
\end{equation*}
czyli
\begin{equation*}
    H(p_1,\ldots,p_n) \leq - \lg\frac{1}{n} = H(1/n,1/n,\ldots,1/n)\,,
\end{equation*}
czyli niepewność zawarta w danym schemacie skończonym jest mniejsza lub równa od niepewności
zawartej w analogicznym schemacie, w którym wszystkie wyniki są jednakowo prawdopodobne.

Załóżmy teraz, że mamy dwa niezależne schematy skończone
\begin{equation*}
    A = \mqty(A_1 & A_2 & \cdots & A_n \\ p_1 & p_2 & \cdots & p_n)\,,\quad B = \mqty(B_1 & B_2 & \cdots & B_m \\ q_1 & q_2 & \cdots & q_m)
\end{equation*}
takie, że dla każdej pary zdarzeń \(A_i, B_j\) prawdopodobieństwo wystąpienia zdarzenia \(A_iB_j\)
wynosi \(p_iq_j\). Zbiór zdarzeń \(A_iB_j\) z prawdopodobieństwami \(r_{ij} = p_i q_j\) reprezentuje
nowy schemat skończony \(AB\). Wówczas
\begin{equation*}
    \begin{split}
        -H(AB) &= \sum_{i=1}^n\sum_{j=1}^m r_{ij}\lg r_{ij} = \sum_{i=1}^n\sum_{j=1}^m p_iq_j\left(\lg p_i + \lg q_j\right) \\
        &= \sum_{i=1}^n p_i\lg p_i + \sum_{j=1}^m q_j \lg q_j = -H(A) - H(B)\,,  
    \end{split}
\end{equation*}
skąd
\begin{equation*}
    H(AB) = H(A) + H(B)\,.
\end{equation*}
Rozważmy teraz przypadek gdy schematy \(A\), \(B\) są zależne. Przez \(q_{ij}\) oznaczmy
prawdopodobieństwo zajścia zdarzenia \(B_j\) pod warunkiem zdarzenia \(A_i\) tj. \(q_{ij} =
p(B_j\mid A_i)\). Schemat \(AB\) jest teraz opisany prawdopodobieństwami \(r_{ij} = p_i q_{ij}\)
zatem
\begin{equation*}
    -H(AB) = \sum_{i=1}^n\sum_{j=1}^m p_i q_{ij} \left(\lg p_i + \lg q_{ij}\right) = - H(A) + \sum_{i=1}^n p_i \sum_{j=1}^m q_{ij} \lg q_{ij}
\end{equation*}
gdyż \(\sum_j q_{ij} = 1\) (prawdopodobieństwo zajścia dowolnego zdarzenia z B pod warunkiem
wystąpienia zdarzenia \(A_i\) wynosi 1), natomiast wielkość \(-\sum_{j=1}^m q_{ij} \lg q_{ij}\) jest
warunkową entropią schematu \(B\) pod warunkiem zajścia zdarzenia \(A_i\), co oznaczymy jako
\(H(B\mid A=A_i)\)
\begin{equation*}
    H(AB) = H(A) + \sum_{i=1}^n p_i H(B\mid A=A_i)\,.
\end{equation*}
Ostatni człon jest w takim razie wartością oczekiwaną wielkości \(H(B)\) w schemacie \(A\), co
oznaczymy jako \(H(B \mid A)\). Mamy w takim razie
\begin{equation*}
    H(AB) = H(A) + H(B \mid A)\,.
\end{equation*}
Z nierówności Jensena można dodatkowo pokazać, że zachodzi \(H(B\mid A) \leq H(B)\).

\subsection{Entropia względna}
Dla dwóch ciągłych rozkładów prawdopodobieństwa \(p(\mathbf{x})\), \(q(\mathbf{x})\) definiujemy ich
entropię względną (nazywaną również \textit{Kullback-Leibler (KL) divergence}) jako
\begin{equation*}
    \mathbb{D}_\text{KL}(p , q) = \int\limits_{\mathbb{R}^n} p(\mathbf{x})\log\frac{p(\mathbf{x})}{q(\mathbf{x})} \dd[n]{\mathbf{x}}\,,
\end{equation*}
która określa podobieństwo między dwoma rozkładami prawdopodobieństwa tj. dla ustalonego rozkładu
\(p\) dla wszystkich \(q\) zachodzi \(\mathbb{D}_\text{KL}(p,q) \geq 0\), przy czym równość zachodzi
iff \(p = q\) (ponownie nierówność Jensena).

Rozważmy teraz rozkład łączny \(p(\mathbf{x}, \mathbf{y})\). Jeśli zmienne losowe \(\mathbf{x},
\mathbf{y}\) są niezależne to \(p(\mathbf{x}, \mathbf{y}) = p(\mathbf{x}) p(\mathbf{y})\). Jeśli
zmienne nie są niezależne to możemy określić stopień ich zależności właśnie poprzez entropię
względną między rozkładem łącznym \(p(\mathbf{x}, \mathbf{y})\), a rozkładem faktoryzowanym
\(p(\mathbf{x})p(\mathbf{y})\). Wielkość taką nazywamy informacją wzajemną (z ang/ \textit{mutual
information})
\begin{equation*}
    \mathbb{I}(\mathbf{x} , \mathbf{y}) = \mathbb{D}_\text{KL}(p(\mathbf{x}, \mathbf{y}), p(\mathbf{x})p(\mathbf{y})) = \int\limits_{\mathbb{R}^n\times\mathbb{R}^m} p(\mathbf{x}, \mathbf{y})\log\left\{\frac{p(\mathbf{x}, \mathbf{y})}{p(\mathbf{x})p(\mathbf{y})}\right\} \dd[n]{\mathbf{x}} \dd[m]{\mathbf{y}}\,.
\end{equation*}

\section{Statystyka}

\subsection{Wnioskowanie statystyczne}

Modelem statystycznym nazwiemy parę \((\chi, \mathcal{P})\), gdzie \(\mathcal{P}\) jest rodziną
rozkładów prawdopodobieństwa w zbiorze \(\chi\), przy czym będziemy zakładać \(\chi = \mathbb{R}^n\)
\begin{equation*}
    \mathcal{P} := \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta \right\}\,,
\end{equation*}
gdzie \(\Theta\) jest zbiorem parametrów modelu \(\mathcal{P}\). Prostą próbą losową w modelu
\(\mathcal{P}\) nazwiemy ciąg niezależnych zmiennych losowych \(X_1, \ldots, X_n\) o wartościach w
\(\mathbb{R}^n\) i pochodzących z tego samego rozkładu \(p(\mathbf{x} \mid \theta) \in \mathcal{P}\)
(w angielskiej terminologii taki ciąg zmiennych losowych nazwiemy \textit{i.i.d.} tj.
\textit{independent and identically distributed}). Statystyką z kolei nazwiemy zmienną losową \(T\)
będącą funkcją prostej próby losowej tj. \(T = T(X_1, \ldots, X_n)\). Być może najważniejszym
przykładem statystyki jest średnia oznaczana jako \(\overline{X}\)
\begin{equation*}
    \overline{X}(X_1, \ldots, X_n) := \frac{X_1 + \ldots + X_n}{n}\,.
\end{equation*}
Wartość oczekiwana statystyki średniej \(\overline{X}(X_1, \ldots, X_n)\) dla \(X_i\) z rozkładu \(X
\sim \mathcal{D}\) o gęstości \(p\) wynosi
\begin{equation*}
    \mathbb{E}[\overline{X}] = \int\cdots\int\frac{1}{n}\left(\sum_{i=1}^nX_i\right)p(X_1)\cdots p(X_n) \dd{X_1}\ldots\dd{X_n} = \mathbb{E}[X]\,.
\end{equation*}
Wariancja statystyki średniej wynosi z kolei
\begin{equation*}
    \begin{split}
        &\text{Var}[\overline{X}] = \mathbb{E}[\overline{X}^2] - \mathbb{E}[\overline{X}]^2 \\
        &= \int\cdots\int\frac{1}{n^2}\left(\sum_{i=1}^n X_i^2 + \underbrace{\sum_{i\neq j}X_iX_j}_{n(n-1)}\right) p(X_1)\cdots p(X_n)\dd{X_1}\ldots\dd{X_n} - \mathbb{E}[X]^2\\
        &= \frac{1}{n}\mathbb{E}[X^2] + \frac{n(n-1)}{n^2}\mathbb{E}[X]^2 - \mathbb{E}[X]^2 = \frac{1}{n}\left[\mathbb{E}[X^2] - \mathbb{E}[X]^2\right] = \frac{1}{n}\text{Var}[X]\,.
    \end{split}
\end{equation*}

\subsection{Twierdzenie Gliwenki--Cantelliego}
Dystrybuantą empiryczną nazywa się funkcję
\begin{equation*}
    \hat{F}(x) = \frac{1}{N}\#\left\{i \in \{1,\ldots,N\} \mid x_i \leq x \right\}\,,
\end{equation*}
gdzie \(\{x_1,\ldots,x_N\}\) jest realizacją prostej próby losowej. Twierdzenie
Gliwenki--Cantelliego stwierdza, iż jeśli \(F(x)\) jest dystrybuantą pewnego rozkładu
prawdopodobieństwa to
\begin{equation*}
    \sup_{x\in\mathbb{R}} |\hat{F}_n(x) - F(x)| \to 0\,,\text{przy \(n\to\infty\).}
\end{equation*}

\subsection{Silne prawo wielkich liczb}

Niech \((X_n)\) będzie ciągiem zmiennych losowych i.i.d. z pewnego rozkładu \(X \sim \mathcal{D}\).
Przez \((\overline{X}_n)\) oznaczmy ciąg średnich częściowych tj.
\begin{equation*}
    \overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i\,.
\end{equation*}
Wówczas zachodzi silne prawo wielkich liczb
\begin{equation*}
    P\left(\lim_{n\to\infty} \overline{X}_n = \mathbb{E}[X]\right) = 1\,,
\end{equation*}
czyli średnia próbek zbiega do wartości oczekiwanej z prawdopodobieństwem 1.

Silne prawo wielkich liczb daje nam potężne narzędzie do szacowania wartości oczekiwanych, gdyż
możemy je przybliżać średnią z dużej liczby próbek losowych, a dokładność tego przybliżenia zależy
jedynie od liczby próbek i wariancji \(X\). Jeśli \(X\) jest zmienną wielowymiarową to dokładność
przybliżenia nie zależy wprost od liczby wymiarów i unikamy tzw. \textit{curse of dimensionality}.

\subsection{Centralne Twierdzenie Graniczne}

Niech \((X_n)\) będzie ciągiem \(k\)--wymiarowych zmiennych losowych i.i.d. z dowolnego rozkładu \(X
\sim \mathcal{D}\) o wartości oczekiwanej \(\boldsymbol{\mu} = \mathbb{E}[\mathbf{x}]\) i
odwracalnej macierzy kowariancji \(\oper{\Sigma}\). Oznaczając przez \((\overline{X}_n)\) ciąg
średnich częściowych ciągu \((X_n)\) zachodzi
\begin{equation*}
    \sqrt{n}\left(\overline{X}_n - \boldsymbol{\mu}\right) \to Z \sim \mathcal{N}(\mathbf{0}, \oper{\Sigma})\,.
\end{equation*}

Oznacza to, iż dla ciągu \(X_1,\ldots,X_n\) zmiennych losowych i.i.d. z praktycznie dowolnego
rozkładu \(X\sim\mathcal{D}\) dla odpowiednio dużych \(n\) średnią z próbek możemy traktować jako
zmienną losową o rozkładzie normalnym \(\mathcal{N}(\boldsymbol{\mu}, n^{-1/2}\oper{\Sigma})\).


\subsection{Estymatory punktowe MLE i MAP}

Rozważamy model statystyczny \(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in
\Theta\right\}\). Estymatorem parametru \(\theta\) nazwiemy statystykę
\(\hat{\theta}(X_1,\ldots,X_n)\) służącą do oszacowania wartości tego parametru. Wartość tej
statystki dla konkretnej realizacji prostej próby losowej
\(\hat{\theta}(\mathbf{x}_1,\ldots,\mathbf{x}_n)\) nazwiemy estymatą parametru \(\theta\). Dodatkowo
definiujemy obciążenie (z ang. \textit{bias}) estymatora jako wielkość
\begin{equation*}
    \mathbb{B}[\hat{\theta}] := \mathbb{E}[\hat{\theta}] - \theta\,.
\end{equation*}

Zasadniczo będą nas interesować dwa rodzaje estymat: MLE i MAP. W przypadku estymaty MLE (z ang.
\textit{Maximum Likelihood Estimate}) definiujemy funkcję wiarygodności (\textit{likelihood}) dla
modelu \(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta\right\}\) i
realizacji prostej próby losowej (którą nazwiemy również danymi lub obserwacjami)
\(D=(\mathbf{x}_1,\ldots,\mathbf{x}_n)\) jako
\begin{equation*}
    p(D \mid \theta) = \prod_{i=1}^n p(\mathbf{x}_i \mid \theta)\,.
\end{equation*}
Estymatą MLE nazywamy taką wartość parametru \(\theta_\text{MLE} \in \Theta\), że
\begin{equation*}
    p(D \mid \theta_\text{MLE}) = \max_{\theta \in \Theta} p(D \mid \theta)\,.
\end{equation*}
Ponieważ znajdywanie maksimum funkcji będącej iloczynem nie jest zadaniem przyjemnym (chociażby
obliczanie pochodnych iloczynu funkcji jest trudniejsze od sumy), więc wprowadzamy zanegowaną
logarytmiczną funkcję wiarygodności
\begin{equation*}
    \ell(D \mid \theta) = -\log p(D \mid \theta) = -\sum_{i=1}^n \log p(\mathbf{x}_i \mid \theta)\,,
\end{equation*}
wówczas ze względu na fakt, iż funkcja \(\log x\) jest ściśle rosnąca estymatę MLE możemy
równoważnie wyznaczyć jako
\begin{equation*}
    \ell(D \mid \theta_\text{MLE}) = \min_{\theta \in \Theta} \ell(D \mid \theta)\,.
\end{equation*}
Funkcję \(\ell\) będziemy również nazywać funkcją kosztu.

W przypadku estymaty MAP (z ang. \textit{Maximum a posteriori estimate}) wprowadzamy gęstość
rozkładu a posteriori jako
\begin{equation*}
    p(\theta \mid D) = \frac{1}{Z}p(D \mid \theta)\pi(\theta)\,,
\end{equation*}
gdzie \(Z\) jest stałą wynikającą z warunku unormowania, a \(\pi(\theta)\) to gęstość
prawdopodobieństwa opisująca rozkład a priori parametru \(\theta\). Estymatą MAP nazywamy taką
wartość parametru \(\theta_\text{MAP} \in \Theta\), że
\begin{equation*}
    p(\theta_\text{MAP} \mid D) = \max_{\theta \in \Theta} p(\theta \mid D)\,.
\end{equation*}
Zauważmy przy tym iż liczba \(Z\) nie jest nam potrzebna, gdyż wystarczy zmaksymalizować licznik tj.
\begin{equation*}
    \theta_\text{MAP} = \arg\max_{\theta \in \Theta} p(D \mid \theta)\pi(\theta)\,.
\end{equation*}

\section{Probabilistyczne uczenie maszynowe}

\subsection{Wnioskowanie Bayesowskie}

Zajmiemy się teraz wnioskowaniem opartym na twierdzeniu Bayesa. Rozpatrujemy model statystyczny
\(\mathcal{P} = \left\{p(\mathbf{x} \mid \theta) \mid \theta \in \Theta\right\}\). Załóżmy, iż mamy
obserwacje \(D = (\mathbf{x}_1, \ldots, \mathbf{x}_n)\), wówczas twierdzenie Bayesa możemy zapisać
jako
\begin{equation*}
    p(\theta \mid D) = \frac{p(D \mid \theta)\pi(\theta)}{p_D(D)} = \frac{p(D \mid \theta)\pi(\theta)}{\int\limits_\Theta p(D \mid \theta)\pi(\theta) \dd{\theta}}\,,
\end{equation*}
gdzie \(p(\theta \mid D)\) nazywamy rozkładem a posteriori (posteriorem), \(p(D \mid \theta)\) --
wiarygodnością (likelihood), a \(\pi(\theta)\) -- rozkładem a priori (priorem).

Całe wnioskowanie Bayesowskie opiera się na wyznaczeniu rozkładu a posteriori, który wyraża całą
naszą wiedzę o estymowanym parametrze \(\theta\). Na podstawie tego rozkładu możemy wyznaczyć
estymatę punktową MAP maksymalizującą gęstość prawdopodobieństwa a posteriori, jak również
niepewność związaną z wyznaczeniem tej estymaty np. poprzez wyznaczenie przedziału wiarygodności
\(C_{1-\alpha}(\theta \mid D) = [\theta_l ; \theta_u]\) takiego, że
\begin{equation*}
    P(\theta \in [\theta_l ; \theta_u] \mid D) = 1 - \alpha\,,
\end{equation*}
dla ustalonego \(0 < \alpha < 1\). Możemy również skonstruować rozkład predykcyjny (z ang.
\textit{posterior predictive distribution}) określający prawdopodobieństwo zaobserwowania nowej
obserwacji \(\mathbf{x}\)
\begin{equation*}
    p(\mathbf{x} \mid D) = \int\limits_\Theta p(\mathbf{x} \mid \theta) p(\theta \mid D) \dd{\theta}\,.
\end{equation*}
Znając rozkład a posteriori estymowanego parametru \(\theta\) możemy nie tylko wyznaczyć estymaty
punktowe, wartości oczekiwane i przedziały wiarygodności, ale również znaleźć estymator Bayesa (z
ang. \textit{Bayes estimator}), który minimalizuje wartość oczekiwaną pewnej funkcji kosztu (z ang.
\textit{loss/cost function}) \(L(\theta, \hat{\theta})\) po wszystkich estymatorach \(\hat{\theta}\)
\begin{equation*}
    \theta_\text{Bayes} = \arg\min_{\hat{\theta}} \int\limits_{\Theta} L(\theta, \hat{\theta}) p(\theta \mid D) \dd{\theta}\,.
\end{equation*}
Całkę w powyższym wzorze nazywa się również funkcją ryzyka (z ang. \textit{risk function})
\(R(\hat{\theta})\), która określa oczekiwaną stratę spowodowaną wykorzystaniem danego estymatora
parametru \(\theta\). W przypadku gdy funkcja kosztu ma postać błędu kwadratowego (L2)
\begin{equation*}
    L(\theta,\hat{\theta}) = (\theta - \hat{\theta})^2
\end{equation*}
funkcję ryzyka możemy zapisać jako
\begin{equation*}
    \begin{split}
        R(\hat{\theta}) &= \int\limits_\Theta \theta^2 p(\theta \mid D) \dd{\theta} - 2 \hat{\theta}\int\limits_\Theta \theta p(\theta \mid D) \dd{\theta} + \hat{\theta}^2 \\
        &= \text{Var}[\theta \mid D] + \mathbb{E}[\theta \mid D]^2 - 2 \hat{\theta}\mathbb{E}[\theta \mid D] + \hat{\theta}^2\\
        &= \text{Var}[\theta \mid D] + \left(\mathbb{E}[\theta \mid D] - \hat{\theta}\right)^2\,.
    \end{split}
\end{equation*}

\subsection{Bayesowski wybór modeli}

Załóżmy, iż mamy rodzinę \(\mathcal{M}\) modeli statystycznych (może to być zbiór dyskretny lub
zbiór modeli indeksowanych ciągłym, wielowymiarowym parametrem \(\boldsymbol{\lambda}\)). Naszym
zadaniem jest wybór najbardziej prawdopodobnego modelu dla danych \(D\). Możemy na to zadanie
patrzeć jako zadanie z teorii decyzji: dla danej funkcji kosztu \(L(M, M^*)\) i rozkładu a
posteriori nad modelami \(p(M \mid D)\) chcemy wybrać model, który minimalizuje ryzyko
\(\mathbb{E}[L(M,M^*)]\). Jeśli jako koszt wybierzemy tzw. \textit{0--1 loss} tj.
\begin{equation*}
    L(M, M^*) = \begin{cases}
        0&\,, \text{jeśli \(M = M^*\)} \\
        1&\,, \text{w.p.p.}
    \end{cases}
\end{equation*}
to
\begin{equation*}
    \mathbb{E}[L(M, M^*)] = 1 - p(M^* \mid D)
\end{equation*}
i wybieramy model \(M\) o największym prawdopodobieństwie (estymata MAP). Pozostaje tylko
wyznaczenie \(p(M \mid D)\)
\begin{equation*}
    p(M \mid D) = \frac{p(D \mid M)\pi(M)}{\sum_{M\in\mathcal{M}} p(D \mid M)\pi(M)}\,.
\end{equation*}
Jeśli jako prior przyjmiemy rozkład jednostajny \(\pi(M) = |\mathcal{M}|^{-1}\) to estymata MAP
sprowadza się do MLE czyli szukamy modelu
\begin{equation*}
    M^* = \arg\max_{M\in\mathcal{M}} p(D \mid M)\,.
\end{equation*}
Jeśli przez \(\theta_M\) oznaczymy parametry modelu \(M\) to 
\begin{equation*}
    p(D \mid M) = \int\limits_{\Theta_M} p(D \mid \theta_M) \pi(\theta_M) \dd{\theta}_M\,.
\end{equation*}
Powyższą wielkość nazywamy wiarygodnością brzegową (z ang. \textit{marginal likelihood}) lub
\textit{model evidence}.

\subsection{Estymator jądrowy gęstości (KDE)}

Załóżmy, że mamy zbiór obserwacji iid \(\{\mathbf{x}_1, \ldots, \mathbf{x}_m\}\) taki, że
\(\mathbf{x}_i \sim \mathcal{D}\) dla pewnego \(n\)--wymiarowego ciągłego rozkładu
prawdopodobieństwa \(\mathcal{D}\) z nieznaną gęstością prawdopodobieństwa \(p(\mathbf{x})\). Chcemy
znaleźć estymator \(\hat{p}(\mathbf{x})\) tej funkcji. Estymatorem jądrowym gęstości funkcji \(p\)
(z ang. \textit{kernel density estimator}) nazywamy funkcję
\begin{equation*}
    \hat{p}(\mathbf{x}) := \frac{1}{mh^n}\sum_{i=1}^m K\left(\frac{\mathbf{x} - \mathbf{x}_i}{h}\right)\,,
\end{equation*}
gdzie \(h \in \mathbb{R}\) jest pewnym hiperparametrem zwanym \textit{bandwidth}, a \(K:
\mathbb{R}^n \mapsto [0; \infty)\) to tzw. funkcja jądrowa będąca parzystą funkcją posiadającą w 0
maksimum globalne oraz spełniającą warunek unormowania
\begin{equation*}
    \int\limits_{\mathbb{R}^n} K(\mathbf{x}) \dd[n]{\mathbf{x}}= 1\,.
\end{equation*}
Ze statystycznego punktu widzenia, postać jądra nie ma istotnego znaczenia i wybór funkcji  \(K\)
może być arbitralny, uwzględniający przede wszystkim pożądane własności otrzymanego estymatora, na
przykład klasę jego regularności (ciągłość, różniczkowalność itp.). W przypadku jednowymiarowym jako
funkcję \(K\) przyjmuje się klasyczne postacie gęstości rozkładów probabilistycznych, na przykład
gęstość rozkładu normalnego. W przypadku wielowymiarowym stosuje się tzw. jądro radialne tj. dla
jądra jednowymiarowego \(K\) wielowymiarowe jądro radialne definiujemy jako
\begin{equation*}
    K(\mathbf{x}) = K(\norm{\mathbf{x}})
\end{equation*}
dla pewnej normy (typowo normy euklidesowej) \(\norm{\cdot}\).

\subsection{Modele Gaussowskie}

Jak już wspomnieliśmy w przypadku gdy zmienna losowa ma wielowymiarowy rozkład normalny
\(\mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\) wszystkie rozkłady brzegowe i warunkowe są również
rozkładami normalnymi. W szczególnym przypadku gdy zmienne \(k\) i \(n-k\) --wymiarowe
\(\mathbf{x}\) i \(\mathbf{y}\) mają łącznie rozkład normalny
\begin{equation*}
    \mqty[\mathbf{x} \\ \mathbf{y}] \sim \mathcal{N}(\boldsymbol{\mu}, \oper{\Sigma})\,,
\end{equation*}
gdzie
\begin{equation*}
    \boldsymbol{\mu} = \mqty[\boldsymbol{\mu}_\mathbf{x} \\ \boldsymbol{\mu}_\mathbf{y}]\,,\quad \oper{\Sigma} = \mqty[\oper{\Sigma}_{\mathbf{xx}} & \oper{\Sigma}_{\mathbf{xy}} \\ \oper{\Sigma}_{\mathbf{yx}} & \oper{\Sigma}_\mathbf{yy}]
\end{equation*}
można pokazać iż
\begin{equation*}
    \mathbf{x} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}}, \oper{\Sigma}_{\mathbf{x}|\mathbf{y}})\,,\quad \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_\mathbf{y}, \oper{\Sigma}_\mathbf{yy})\,,
\end{equation*}
gdzie
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}} = \boldsymbol{\mu}_\mathbf{x} + \oper{\Sigma}_\mathbf{xy}\oper{\Sigma}_\mathbf{yy}^{-1}(\mathbf{y} - \boldsymbol{\mu}_\mathbf{y})\\
        &\oper{\Sigma}_{\mathbf{x}|\mathbf{y}} = \oper{\Sigma}_\mathbf{xx} - \oper{\Sigma}_\mathbf{xy}\oper{\Sigma}_\mathbf{yy}^{-1}\oper{\Sigma}_\mathbf{yx}
    \end{split}\quad.
\end{equation*}

\subsection{Liniowe modele Gaussowskie}

Powyższe własności rozkładów łącznych pozwalają jawnie wnioskować w tzw. liniowych modelach
Gaussowskich (z ang. \textit{Linear Gaussian Models}). Załóżmy, iż nasze obserwacje są modelowane
przez \(n\)--wymiarową zmienną losową \(\mathbf{y}\) o rozkładzie normalnym z estymowanym parametrem
\(\mathbf{x}\) i znanymi parametrami \(\oper{A}, \mathbf{b}, \oper{\Sigma}_\mathbf{y}\) tak, że
wiarygodność ma postać
\begin{equation*}
    \mathbf{y}\mid\mathbf{x} \sim \mathcal{N}(\oper{A}\mathbf{x} + \mathbf{b}, \oper{\Sigma}_\mathbf{y})\,,
\end{equation*}
gdzie \(\oper{A}\) jest macierzą wymiaru \(n\times k\). Jako prior na parametr \(\mathbf{x}\)
przyjmiemy również rozkład normalny o pewnych zadanych parametrach \(\boldsymbol{\mu}_\mathbf{x},
\oper{\Sigma}_\mathbf{x}\) (taki wybór rozkładu a priori nazywamy rozkładem sprzężonym do
wiarygodności)
\begin{equation*}
    \mathbf{x} \sim \mathcal{N}(\boldsymbol{\mu}_\mathbf{x}, \oper{\Sigma}_\mathbf{x})\,.
\end{equation*}
Wówczas łatwo pokazać, iż rozkład a posteriori jest rozkładem normalnym
\begin{equation*}
    \mathbf{x} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}}, \oper{\Sigma}_{\mathbf{x}|\mathbf{y}})
\end{equation*}
z parametrami
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{\mathbf{x}|\mathbf{y}} = \left[\oper{\Sigma}_\mathbf{x}^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{\mathbf{x}|\mathbf{y}} = \oper{\Sigma}_{\mathbf{x}|\mathbf{y}}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y} - \mathbf{b}) + \oper{\Sigma}_\mathbf{x}^{-1}\boldsymbol{\mu}_\mathbf{x}\right]
    \end{split}\quad.
\end{equation*}

Załóżmy teraz, iż mamy ciąg obserwacji \((\mathbf{y}_1, \ldots, \mathbf{y}_m)\). Wnioskowanie
Bayesowskie możemy wówczas stosować iteracyjnie tzn. na początku dla 0 obserwacji rozkład
estymowanego parametru jest opisany przez prior \(\mathcal{N}(\boldsymbol{\mu}_0,
\oper{\Sigma}_0)\). Po zaobserwowaniu jednego \(\mathbf{y}_1\) aktualizujemy nasze przekonania co do
parametru \(\mathbf{x}\) zgodnie z powyższym wzorem i otrzymujemy rozkład normalny o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_1 = \left[\oper{\Sigma}_0^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_1 = \oper{\Sigma}_1\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_1 - \mathbf{b}) + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]
    \end{split}\quad.
\end{equation*}
Po zaobserwowaniu kolejnego \(\mathbf{y}_2\) ponownie wykorzystujemy powyższe wzory ale jako prior
wykorzystując rozkład w poprzedniej iteracji. W ogólności możemy zapisać wzór rekurencyjny na
\(m+1\) rozkład jako
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m+1} = \left[\oper{\Sigma}_m^{-1} + \oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{m+1} = \oper{\Sigma}_{m+1}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_{m+1} - \mathbf{b}) + \oper{\Sigma}_m^{-1}\boldsymbol{\mu}_m\right]
    \end{split}\quad,
\end{equation*}
skąd możemy od razu podać wzór na parametry \(m\)--tego rozkładu
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m} = \left[\oper{\Sigma}_0^{-1} + m\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\oper{A}\right]^{-1}\\
        &\boldsymbol{\mu}_{m} = \oper{\Sigma}_{m}\left[\oper{A}^\top\oper{\Sigma}_\mathbf{y}^{-1}\left(\sum_{i=1}^{m}\mathbf{y}_{i} - m\mathbf{b}\right) + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]
    \end{split}\quad.
\end{equation*}
Taki sam wynik można by uzyskać rozpatrując łączny rozkład a posteriori dla obserwacji \(D =
(\mathbf{y}_1, \ldots, \mathbf{y}_m)\) tj.
\begin{equation*}
    \begin{split}
        &p(\mathbf{x} \mid D) \cong \pi(\mathbf{x})\prod_{i=1}^m p(\mathbf{y}_i \mid \mathbf{x})\cong \\
        &\exp\left\{-\frac{1}{2}\left[(\mathbf{x}-\boldsymbol{\mu}_0)^\top\oper{\Sigma}_0^{-1}(\mathbf{x}-\boldsymbol{\mu}_0) + \sum_{i=1}^m(\mathbf{y}_i - \oper{A}\mathbf{x}-\mathbf{b})^\top\oper{\Sigma}_\mathbf{y}^{-1}(\mathbf{y}_i - \oper{A}\mathbf{x}-\mathbf{b})\right]\right\}
    \end{split}\,.
\end{equation*}

\subsection{Regresja liniowa}

Załóżmy, iż modelujemy obserwacje postaci \((y,\mathbf{x})\) gdzie \(y\) to skalar zwany zmienną
objaśnianą, którego wartość obserwujemy, a \(\mathbf{x}\) to wektor zmiennych objaśniających, który
kontrolujemy tj. zakładamy, iż wektor \(\mathbf{x}\) dla danego pomiaru \(y\) znamy dokładnie.
Dodatkowo zakładamy, iż \(y\) zależy liniowo od \(\mathbf{x}\) tj.
\begin{equation*}
    y = \mathbf{w}^\top\mathbf{x} + \epsilon\,,
\end{equation*}
gdzie \(\epsilon \sim \mathcal{N}(0, \sigma^2)\) dla znanego \(\sigma\) jest tzw. błędem losowym, a
\(\mathbf{w}\) jest estymowanym przez nas parametrem. Możemy zatem zapisać
\begin{equation*}
    y \mid \mathbf{w} \sim \mathcal{N}(\mathbf{w}^\top\mathbf{x}, \sigma^2)\,.
\end{equation*}
Powiedzmy, iż zaobserwowaliśmy ciąg obserwacji \(D = (y_1, \ldots, y_m)\) dla zadanych (lub
dokładnie znanych) przez nas \((\mathbf{x}_1,\ldots,\mathbf{x}_m)\). Wiarygodność ma zatem postać
\begin{equation*}
    p(D \mid \mathbf{w}) \cong \prod_{i=1}^m \exp\left\{-\frac{1}{2\sigma^2}\left(y_i - \mathbf{w}^\top\mathbf{x}_i\right)^2\right\}\,.
\end{equation*}
W przypadku regresji liniowej zamiast pełnego wnioskowania Bayesowskiego o parametrze \(\mathbf{w}\)
często stosuje się prostsze podejście polegające na znalezieniu estymaty punktowej MLE. Zanegowana
logarytmiczna funkcja wiarygodności ma postać
\begin{equation*}
    \ell(D \mid \mathbf{w}) = \frac{1}{2\sigma^2}\sum_{i=1}^m(y_i - \mathbf{w}^\top\mathbf{x}_i)^2 + \text{const.}
\end{equation*}
Człon stały możemy oczywiście pominąć i zapisać
\begin{equation*}
    \ell(D \mid \mathbf{w}) \cong \sum_{i=1}^m(y_i - \mathbf{w}^\top\mathbf{x}_i)^2 = \left(\mathbf{y} - \oper{X}\mathbf{w}\right)^\top\left(\mathbf{y} - \oper{X}\mathbf{w}\right)\,,
\end{equation*}
gdzie
\begin{equation*}
    \mathbf{y} = \mqty[y_1 \\ \vdots \\ y_m]\,,\quad \oper{X} = \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,.
\end{equation*}
Ponieważ otrzymana funkcja \(\ell\) ma postać formy kwadratowej, więc problem optymalizacyjny
polegający na znalezieniu minimum \(\ell\) nazywa się metodą najmniejszych kwadratów (z ang.
\textit{OLS -- Ordinary Least Squares}). Aby wyznaczyć estymatę \(\mathbf{w}_\text{MLE}\) musimy
rozwiązać równanie
\begin{equation*}
    \pdv{\ell}{\mathbf{w}} = \pdv{~}{\mathbf{w}}\left[\mathbf{y}^\top\mathbf{y} + \mathbf{w}^\top\oper{X}^\top\oper{X}\mathbf{w} - 2\mathbf{y}^\top\oper{X}\mathbf{w}\right] = \mathbf{0}\,,
\end{equation*}
skąd
\begin{equation*}
    2\oper{X}^\top\oper{X}\mathbf{w} - 2\oper{X}^\top\mathbf{y} = \mathbf{0}\,,
\end{equation*}
zatem
\begin{equation*}
    \mathbf{w}_\text{MLE} = (\oper{X}^\top\oper{X})^{-1}\oper{X}^\top\mathbf{y}\,.
\end{equation*}
Pełniejszą informację o parametrze \(\mathbf{w}\) możemy uzyskać rozpatrując rozkład a posteriori
\(p(\mathbf{w} \mid D)\). Jeśli jako prior przyjmiemy rozkład normalny z pewnymi parametrami
\(\boldsymbol{\mu}_0, \oper{\Sigma}_0\) to zauważmy, iż otrzymujemy instancję liniowego modelu
Gaussowskiego
\begin{equation*}
    \begin{split}
        \mathbf{y} \mid \mathbf{w} &\sim \mathcal{N}(\oper{X}\mathbf{w}, \sigma^2\oper{1})\\
        \mathbf{w} &\sim \mathcal{N}(\boldsymbol{\mu}_0, \oper{\Sigma}_0)
    \end{split}\quad,
\end{equation*}
skąd rozkład a posteriori jest rozkładem normalnym
\begin{equation*}
    \mathbf{w} \mid \mathbf{y} \sim \mathcal{N}(\boldsymbol{\mu}_m, \oper{\Sigma}_m)
\end{equation*}
o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_m = \left[\oper{\Sigma}_0^{-1} + \sigma^{-2}\oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_m = \oper{\Sigma}_m\left[\sigma^{-2}\oper{X}^\top\mathbf{y} + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]    
    \end{split}\quad.
\end{equation*}
W powyższych wzorach nazwy parametrów nie są przykładowe: po zaobserwowaniu 0 przykładów rozkład
parametru \(\mathbf{w}\) jest rozkładem a priori \(\mathcal{N}(\boldsymbol{\mu}_0,
\oper{\Sigma}_0)\); po zaobserwowaniu po jednej wartości \(y_i\) w \(m\) zadanych (znanych
dokładnie) punktach \(\mathbf{x}_i\) otrzymujemy rozkład a posteriori
\(\mathcal{N}(\boldsymbol{\mu}_m, \oper{\Sigma}_m)\). Gdybyśmy w każdym z \(m\) punktów
\(\mathbf{x}_i\) dokonywali pomiaru \(y_i\) \(s\)--krotnie to wtedy wykorzystując wzory wyprowadzone
przy iteracyjnym stosowaniu wnioskowania w liniowym modelu Gaussowskim otrzymujemy rozkład normalny
o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_{m;s} = \left[\oper{\Sigma}_0^{-1} + \frac{s}{\sigma^2}\oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_{m;s} = \oper{\Sigma}_{m;s}\left[\sigma^{-2}\oper{X}^\top\sum_{i=1}^s\mathbf{y}_i + \oper{\Sigma}_0^{-1}\boldsymbol{\mu}_0\right]    
    \end{split}\quad.
\end{equation*} 
Rozkład predykcyjny dla nowej obserwacji \(y\) poczynionej w punkcie \(\mathbf{x}\) jest dany przez
\begin{equation*}
    p(y \mid \mathbf{y}) = \int\limits_{\mathbb{R}^n}p(y\mid\mathbf{w})p(\mathbf{w}\mid\mathbf{y}) \dd[n]\mathbf{w}\,.
\end{equation*}
Nietrudno zauważyć, iż będzie to rozkład normalny o parametrach
\begin{equation*}
    \begin{split}
        \mu_{y|\mathbf{y}} = \mathbb{E}[y\mid\mathbf{y}] &= \int\limits_{\mathbb{R}} y p(y\mid\mathbf{y}) \dd{y} = \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} yp(y\mid\mathbf{w}) \\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \mathbf{x}^\top\mathbf{w} = \mathbf{x}^\top\boldsymbol{\mu}_m\,.
    \end{split}
\end{equation*}
oraz
\begin{equation*}
    \begin{split}
        \sigma_{y|\mathbf{y}}^2 &= \mathbb{E}\left[(y - \mu_{y|\mathbf{y}} )^2 \mid \mathbf{y}\right] = \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} (y-\mu_{y|\mathbf{y}})^2p(y\mid\mathbf{w})\\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \int\limits_\mathbb{R}\dd{y} \left(y^2 + \mu_{y|\mathbf{y}}^2 - 2\mu_{y|\mathbf{y}}y\right)p(y\mid\mathbf{w})\\
        &= \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \left(\sigma^2 + (\mathbf{x}^\top\mathbf{w})^2 + \mu_{y|\mathbf{y}}^2 - 2\mu_{y|\mathbf{y}}\mathbf{x}^\top\mathbf{w}\right)\\
        &=\sigma^2 + \int\limits_{\mathbb{R}^n}\dd[n]{\mathbf{w}} p(\mathbf{w}\mid\mathbf{y}) \left(\mathbf{x}^\top\mathbf{w} - \mathbf{x}^\top\boldsymbol{\mu}_m\right)^2\\
        &=\sigma^2 + \mathbf{x}^\top \mathbb{E}[(\mathbf{w}-\boldsymbol{\mu}_m)(\mathbf{w}-\boldsymbol{\mu}_m)^\top\mid\mathbf{y}]\mathbf{x} = \sigma^2 +\mathbf{x}^\top\oper{\Sigma}_m\mathbf{x}\,.
    \end{split}
\end{equation*}
Powyżej skorzystaliśmy ze znanego faktu, iż dla jednowymiarowej zmiennej losowej zachodzi \(\sigma^2
= \mathbb{E}[(X - \mu_X)^2] = \mathbb{E}[X^2] - \mu_X^2\), skąd \(\mathbb{E}[X^2] = \sigma^2 +
\mu_X^2\). Podsumowując rozkład predykcyjny ma postać
\begin{equation*}
    y \mid \mathbf{y} \sim \mathcal{N}(\mathbf{x}^\top\boldsymbol{\mu}_m, \sigma^2 + \mathbf{x}^\top\oper{\Sigma}_m\mathbf{x})\,.
\end{equation*}

\subsection{Regularyzacja}

Regularyzacją nazywamy proces polegający na wprowadzeniu ad hoc do zagadnienia optymalizacji
dodatkowych członów tak, aby rozwiązanie było regularne (prostsze, nieosobliwe, jednoznaczne ...). W
przypadku funkcji kosztu \(\ell\) najczęściej dodajemy człon penalizujący rozwiązania o dużej normie
estymowanego parametru postaci
\begin{equation*}
    \gamma\norm{\theta}
\end{equation*}
dla pewnej normy \(\norm{\cdot}\) i hiper-parametru \(\gamma\) określającego siłę regularyzacji. W
kontekście Bayesowskim regularyzację można również rozumieć jako pewną niechęć ("tłumienie",
zachowawczość) modelu do zmiany rozkładu a priori estymowanego parametru po pojawieniu się kolejnych
obserwacji.

Przykładowo jeśli w zagadnieniu Bayesowskiej regresji liniowej jako prior przyjmiemy rozkład
normalny
\begin{equation*}
    \mathbf{w} \sim \mathcal{N}(\mathbf{0}, \tau^2\oper{1})
\end{equation*}
to rozkład a posteriori jest rozkładem normalnym o parametrach
\begin{equation*}
    \begin{split}
        &\oper{\Sigma}_m = \sigma^2 \left[\gamma\oper{1} + \oper{X}^\top\oper{X}\right]^{-1}\\
        &\boldsymbol{\mu}_m = \left[\gamma\oper{1} + \oper{X}^\top\oper{X}\right]^{-1}\oper{X}^\top\mathbf{y}
    \end{split}\quad,
\end{equation*}
gdzie \(\gamma = \sigma^2 / \tau^2\) jest hiper-parametrem określającym siłę regularyzacji.
Zauważmy, że im większa jest wartość \(\gamma\) (mniejsza niepewność związana z rozkładem a priori)
tym drugi człon w nawiasie staje się mniej istotny. Taki sam wynik możemy uzyskać metodą OLS jeśli
do funkcji kosztu dodamy człon regularyzujący dla zwykłej normy euklidesowej. Zagadnienie
minimalizacji funkcji kosztu będącej formą kwadratową z dodanym członem regularyzującym nazywamy
również regresją grzbietową.

\subsection{Procesy Gaussowskie}

Jak już wspomnieliśmy macierz kowariancji \(n\)--wymiarowej zmiennej losowej \(\mathbf{x}\) o
wartości oczekiwanej \(\boldsymbol{\mu}\) jest zdefiniowana jako
\begin{equation*}
    \oper{\Sigma} = \mathbb{E}\left[(\mathbf{x} - \boldsymbol{\mu})(\mathbf{x} - \boldsymbol{\mu})^\top\right]\,.
\end{equation*}
Pokazaliśmy również, iż macierz ta jest nieujemnie określona. Dodatkowo pokażemy, iż dla każdej
nieujemnie określonej macierzy symetrycznej \(\oper{K}\) wymiaru \(n\times n\) istnieje
\(n\)--wymiarowa zmienna losowa o wielowymiarowym rozkładzie normalnym dla której \(\oper{K}\) jest
macierzą kowariancji. Istotnie dla każdej nieujemnie określonej macierzy symetrycznej istnieje
macierz \(\oper{L}\) taka, że
\begin{equation*}
    \oper{K} = \oper{L}\oper{L}^\top\,,
\end{equation*}
jest to tzw. dekompozycja Choleskiego. Niech \(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \oper{1})\),
wówczas zmienna losowa \(\oper{L}\mathbf{z}\) ma rozkład o zerowej wartości oczekiwanej i macierzy
kowariancji
\begin{equation*}
    \mathbb{E}\left[(\oper{L}\mathbf{z})(\oper{L}\mathbf{z})^\top\right] = \mathbb{E}\left[\oper{L}\mathbf{z}\mathbf{z}^\top\oper{L}^\top\right] = \oper{L}\mathbb{E}[\mathbf{z}\mathbf{z}^\top]\oper{L}^\top = \oper{L}\oper{1}\oper{L}^\top = \oper{K}\,.
\end{equation*}
Powyższe własności wskazują, iż macierze kowariancji można w pewnym sensie utożsamiać z nieujemnie
określonymi macierzami symetrycznymi.

Zdefiniujemy teraz funkcję kowariancji \(k: \mathbb{R}^n\times\mathbb{R}^n\mapsto\mathbb{R}\) taką,
że \(\forall m\in\mathbb{N} : \forall X = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\} \subset
\mathbb{R}^n\) macierz
\begin{equation*}
    k(X,X) = \mqty[k(\mathbf{x}_1, \mathbf{x}_1) & k(\mathbf{x}_1, \mathbf{x}_2) & \cdots & k(\mathbf{x}_1, \mathbf{x}_m)\\
    k(\mathbf{x}_2, \mathbf{x}_1) & k(\mathbf{x}_2, \mathbf{x}_2) & \cdots & k(\mathbf{x}_2, \mathbf{x}_m)\\
    \vdots & \vdots & \ddots & \vdots\\
    k(\mathbf{x}_m, \mathbf{x}_1) & k(\mathbf{x}_m, \mathbf{x}_2) & \cdots & k(\mathbf{x}_m, \mathbf{x}_m)\\]
\end{equation*}
jest dodatnio określoną macierzą symetryczną. Funkcję \(k\) nazywamy również jądrem dodatnio
określonym (z ang. \textit{positive definite kernel}) lub jądrem Mercera. Dla dwóch zbiorów punktów
\(X = \{\mathbf{x}_1,\ldots,\mathbf{x}_m\} \subset \mathbb{R}^n\) i \(Y =
\{\mathbf{y}_1,\ldots,\mathbf{y}_s\} \subset \mathbb{R}^n\) i funkcji kowariancji \(k\) wprowadzimy
oznaczenie
\begin{equation*}
    k(X,Y) := \mqty[k(\mathbf{x}_1, \mathbf{y}_1) & k(\mathbf{x}_1, \mathbf{y}_2) & \cdots & k(\mathbf{x}_1, \mathbf{y}_s)\\
    k(\mathbf{x}_2, \mathbf{y}_1) & k(\mathbf{x}_2, \mathbf{y}_2) & \cdots & k(\mathbf{x}_2, \mathbf{y}_s)\\
    \vdots & \vdots & \ddots & \vdots\\
    k(\mathbf{x}_m, \mathbf{y}_1) & k(\mathbf{x}_m, \mathbf{y}_2) & \cdots & k(\mathbf{x}_m, \mathbf{y}_s)\\]\,.
\end{equation*}
Poniżej podajemy kilka przykładów funkcji kowariancji
\begin{itemize}
    \item \textit{Gaussian kernel} dla normy \(\norm{\cdot}\) i hiper-parametru \(l\)
    \begin{equation*}
        k(\mathbf{x}, \mathbf{y}) = \exp\left\{-\frac{1}{2l^2}\norm{\mathbf{x} - \mathbf{y}}^2\right\}
    \end{equation*}
    
    \item \textit{Periodic kernel} dla normy \(\norm{\cdot}\) i hiper-parametrów \(l, p\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \exp\left\{-\frac{2}{l^2}\sin^2\left(\frac{\pi}{p}\norm{\mathbf{x} - \mathbf{y}}\right)\right\}
    \end{equation*}

    \item \textit{White noise kernel} dla hiper-parametru \(\sigma\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \sigma^2 \delta_{\mathbf{x},\mathbf{y}}
    \end{equation*}

    \item \textit{Mat\'ern kernel} dla normy \(\norm{\cdot}\) i hiper-parametrów \(l, \nu\)
    \begin{equation*}
        k(\mathbf{x},\mathbf{y}) = \frac{2^{1-\nu}}{\Gamma(\nu)}\left(\frac{\sqrt{2\nu}}{l}\norm{\mathbf{x} - \mathbf{y}}\right)^\nu K_\nu\left(\frac{\sqrt{2\nu}}{l}\norm{\mathbf{x} - \mathbf{y}}\right)\,,
    \end{equation*}
    gdzie \(\Gamma(x)\) to funkcja gamma Eulera, a \(K_\nu(x)\) to zmodyfikowana funkcja Bessela
    2-go rodzaju rzędu \(\nu\).

\end{itemize}
Dodatkowo suma lub iloczyn dwóch funkcji kowariancji oraz złożenie funkcji kowariancji z wielomianem
o nieujemnych współczynnikach jest również funkcją kowariancji.

Procesem Gaussowskim (z ang. \textit{Gaussian Process}) nazywamy rodzinę skalarnych zmiennych
losowych indeksowanych przez punkty \(\mathbf{x} \in \mathbb{R}^n\)
\begin{equation*}
    \mathcal{GP} = \left\{f_\mathbf{x} \mid \mathbf{x} \in \mathbb{R}^n\right\}
\end{equation*}
taką że każdy skończony podzbiór \(\mathcal{GP}\) ma łącznie wielowymiarowy rozkład normalny tj. dla
dowolnego zbioru \(X = \{\mathbf{x}_1, \ldots, \mathbf{x}_m\} \subset \mathbb{R}^n\) zachodzi
\begin{equation*}
    \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\boldsymbol{\mu}_X, \oper{\Sigma}_{X})\,.
\end{equation*}
Zauważmy, iż process Gaussowski możemy jednoznacznie zdefiniować podając przepisy na parametry
\(\boldsymbol{\mu}_X\) i \(\oper{\Sigma}_X\) dla dowolnego zbioru \(X\). W praktyce często
przyjmujemy \(\boldsymbol{\mu}_X = \mathbf{0}\), natomiast przepisem na macierz kowariancji może być
zdefiniowana wyżej funkcja kowariancji \(k(X,X)\) tj.
\begin{equation*}
    \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\mathbf{0}, k(X,X))\,.
\end{equation*}
Process Gaussowski daje nam w praktyce rozkład prawdopodobieństwa nad funkcjami
\(f:\mathbb{R}^n\mapsto\mathbb{R}\), których charakter jest określony przez jądro \(k\) (np. funkcja
gładka dla jądra Gaussowskiego, okresowa dla jądra periodycznego, itp.). Zauważmy, że nie
wnioskujemy tu o parametrach konkretnej rodziny funkcji (jak w przypadku regresji liniowej);
interesuje nas jedynie rozkład predykcyjny. Załóżmy, iż w zadanych (lub dokładnie znanych) przez nas
punktach \(X = \{\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_m\}\) zaobserwowaliśmy wartości pewnej
funkcji, o których zakładamy, iż pochodzą z procesu Gaussowskiego zadanego jądrem \(k\), które
wyraża nasze założenia a priori co do charakteru badanej funkcji
\begin{equation*}
    \mathbf{f}_X = \mqty[f_{\mathbf{x}_1} \\ \vdots \\ f_{\mathbf{x}_m}] \sim \mathcal{N}(\mathbf{0}, k(X,X))\,.
\end{equation*}
Powiedzmy, iż chcemy znać wartości \(\mathbf{f}_Y\) tej funkcji w zadanych punktach \(Y =
\{\mathbf{y}_1,\mathbf{y}_2,\ldots,\mathbf{y}_s\}\). Ponieważ założyliśmy, iż wartości funkcji
pochodzą z procesu Gaussowskiego, więc rozkład łączny \(\mathbf{f}_X\) i \(\mathbf{f}_Y\) jest
rozkładem normalnym
\begin{equation*}
    \mqty[\mathbf{f}_X \\ \mathbf{f}_Y] \sim \mathcal{N}\left(\mathbf{0}, \mqty[k(X,X) & k(X,Y) \\ k(Y,X) & k(Y,Y)]\right)\,.
\end{equation*}
Zauważmy, iż jest to instancja modelu Gaussowskiego, więc rozkład warunkowy \(\mathbf{f}_Y\mid
\mathbf{f}_X\) jest również rozkładem normalnym o parametrach
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu} = k(Y,X)k^{-1}(X,X)\mathbf{f}_X\\
        &\oper{\Sigma} = k(Y,Y) - k(Y,X)k^{-1}(X,X)k(X,Y)
    \end{split}\quad.
\end{equation*}
Dodatkową niepewność związaną z pomiarem wartości \(\mathbf{f}_X\) możemy uchwycić zmieniając postać
jądra 
\begin{equation*}
    k(\mathbf{x},\mathbf{y}) \leftarrow k(\mathbf{x},\mathbf{y}) + \mathcal{I}_X(\mathbf{x})\sigma^2\delta_{\mathbf{x},\mathbf{y}}\,,
\end{equation*}
gdzie \(\sigma\) jest hiper-parametrem określającym precyzję pomiaru. Oczywiście \(k\) jest dalej
funkcją kowariancji, gdyż takie podstawienie powoduje jedynie dodanie dodatnich członów do pewnych
elementów diagonalnych macierzy kowariancji, więc macierz ta jest nadal symetryczna i dodatnio
określona. Wówczas rozkład predykcyjny ma parametry
\begin{equation*}
    \begin{split}
        &\boldsymbol{\mu} = k(Y,X)\left[k(X,X) + \sigma^2\oper{1}\right]^{-1}\mathbf{f}_X\\
        &\oper{\Sigma} = k(Y,Y) - k(Y,X)\left[k(X,X) + \sigma^2\oper{1}\right]^{-1}k(X,Y)
    \end{split}\quad.
\end{equation*}

\subsection{Wieloklasowa regresja logistyczna}

Załóżmy, iż modelujemy obserwacje postaci \((t,\mathbf{x})\), gdzie \(t \in
\{\tau_1,\tau_2,\ldots,\tau_s\}\) to etykieta określająca przynależność do jednej z \(s\) klas, a
\(\mathbf{x} \in \mathbb{R}^n\) jest znanym (lub zadanym) przez nas dokładnie wektorem cech obiektu
dla których zaobserwowaną klasą jest \(t\). Zakładamy ponadto, iż prawdopodobieństwo przynależności
do klasy \(\tau_j\) (jednej z \(s\) klas) dla wektora cech \(\mathbf{x}\) ma postać tzw. funkcji
softmax
\begin{equation*}
    \pi_j(\mathbf{x}) = \frac{1}{Z(\mathbf{x})}\e^{\mathbf{w}_j^\top\mathbf{x}}\,,
\end{equation*}
gdzie \(\mathbf{w}_j\) są estymowanymi przez nas parametrami. Ze względu na warunek unormowania
musimy mieć
\begin{equation*}
    \sum_{j=1}^s \pi_j = 1\,,
\end{equation*}
skąd stała normalizacyjna \(Z(\mathbf{x})\) ma postać
\begin{equation*}
    Z(\mathbf{x}) = \sum_{j=1}^s \e^{\mathbf{w}_j^\top\mathbf{x}}\,.
\end{equation*}
Rozkład zmiennej losowej \(t\) jest  w takim razie dyskretnym rozkładem wielopunktowym (z ang.
\textit{categorical distribution}) postaci
\begin{equation*}
    t \mid \mathbf{w}_1,\ldots,\mathbf{w}_s \sim \text{Cat}(\pi_1(\mathbf{x}),\ldots,\pi_s(\mathbf{x}))\,.
\end{equation*}
Zauważmy, iż prawdopodobieństwo wylosowania etykiety \(t\) dla parametrów \(\mathbf{w}_j\) możemy
zapisać jako
\begin{equation*}
    p(t \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{j=1}^s \pi_j(\mathbf{x})^{\delta(t,\tau_j)}\,.
\end{equation*}
Powiedzmy, że mamy obserwacje \(D = (t_1,\ldots,t_m)\) dla znanych (lub zadanych) przez nas
dokładnie wektorów cech \((\mathbf{x}_1, \ldots, \mathbf{x}_m)\). Funkcja wiarygodności ma wówczas
postać
\begin{equation*}
    p(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{i=1}^m p(t_i \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) = \prod_{i=1}^m \prod_{j=1}^s \pi_j(\mathbf{x}_i)^{\delta(t_i,\tau_j)}\,.
\end{equation*}
Jako prior dla parametrów \(\mathbf{w}_j\) przyjmiemy rozkład normalny z pewnym hiper-parametrem
\(\gamma\)
\begin{equation*}
    \forall j\in \{1,\ldots,s\} : \mathbf{w}_j \sim \mathcal{N}(\mathbf{0}, \gamma^{-1}\oper{1})\,.
\end{equation*}
W przypadku regresji logistycznej ograniczymy się do znalezienia estymaty MAP parametrów
\(\mathbf{w}_j\) tak, aby w przyszłości do nowego wektora cech \(\mathbf{x}\) przyporządkować klasę
o największym prawdopodobieństwie \(\pi_j(\mathbf{x})\). Znalezienie estymaty MAP sprowadza się do
znalezienia minimum zregularyzowanej funkcji kosztu
\begin{equation*}
    \begin{split}
        \ell^*(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s) &= -\log [p(D \mid \mathbf{w}_1,\ldots,\mathbf{w}_s ) \pi(\mathbf{w}_1, \ldots, \mathbf{w}_s)] \\
        &= - \log \left[\prod_{k=1}^s\e^{-\frac{\gamma}{2}\mathbf{w}_k^\top\mathbf{w}_k}\prod_{i=1}^m \prod_{j=1}^s \pi_j(\mathbf{x}_i)^{\delta(t_i,\tau_j)}\right]\\
        &= \frac{\gamma}{2}\sum_{j=1}^s \mathbf{w}_j^\top\mathbf{w}_j - \sum_{i=1}^m\sum_{j=1}^s \delta(t_i,\tau_j)\log\pi_j(\mathbf{x}_i)\,.
    \end{split}
\end{equation*}
Niestety dla tak zdefiniowanej funkcji kosztu nie można znaleźć wzoru na minimum w postaci
analitycznej, dlatego wykorzystamy numeryczny algorytm optymalizacji zwany spadkiem wzdłuż
gradientu.

\begin{tcolorbox}[title=Algorytm spadku wzdłuż gradientu]
\begin{enumerate}
    \item Wybierz parametry początkowe \(\mathbf{x}_1^{(0)}, \ldots, \mathbf{x}_m^{(0)}\)
    \item Powtarzaj
    \begin{equation*}
        \begin{split}
            &\mathbf{x}_1^{(t+1)} = \mathbf{x}_1^{(t)} - \epsilon_1\pdv{f}{\mathbf{x}_1}\bigg|_{\mathbf{x}_1^{(t)}, \ldots, \mathbf{x}_m^{(t)}}\\
            &\vdots\\
            &\mathbf{x}_m^{(t+1)} = \mathbf{x}_m^{(t)} - \epsilon_m\pdv{f}{\mathbf{x}_m}\bigg|_{\mathbf{x}_1^{(t)}, \ldots, \mathbf{x}_m^{(t)}}
        \end{split}
    \end{equation*}
    gdzie \(\epsilon_1,\ldots,\epsilon_m\) to hiper-parametry zwane stałymi uczącymi (z ang.
    \textit{learning rate}).
\end{enumerate}
\end{tcolorbox}

Zakładając \(\epsilon_1 = \ldots = \epsilon_m = \epsilon\) i wprowadzając
\begin{equation*}
    \oper{X} := \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,,\quad \pdv{f}{\oper{X}} := \mqty[\pdv{f}{\mathbf{x}_1}^\top \\ \vdots \\ \pdv{f}{\mathbf{x}_m}^\top]
\end{equation*}
możemy zapisać powyższe równania w kompaktowej formie
\begin{equation*}
    \oper{X}^{(t+1)} = \oper{X}^{(t)} - \epsilon \pdv{f}{\oper{X}}\bigg|_{\oper{X}^{(t)}}\,.
\end{equation*}

Aby zminimalizować numerycznie funkcję kosztu \(\ell^*\) stosując metodę spadku wzdłuż gradientu
musimy obliczyć pochodne funkcji kosztu po parametrach \(\mathbf{w}_j\)
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k - \sum_{i=1}^m\sum_{j=1}^s \delta(t_i,\tau_j)\pdv{~}{\mathbf{w}_k}\log\pi_j(\mathbf{x}_i)\,,
\end{equation*}
ale
\begin{equation*}
    \begin{split}
        \pdv{~}{\mathbf{w}_k}\log\pi_j(\mathbf{x}_i) &= \frac{1}{\pi_j(\mathbf{x}_i)}\frac{Z(\mathbf{x}_i)\pdv{\e^{\mathbf{x}_i^\top\mathbf{w}_j}}{\mathbf{w}_k} - \e^{\mathbf{x}_i^\top\mathbf{w}_j}\pdv{Z(\mathbf{x}_i)}{\mathbf{w}_k}}{Z^2(\mathbf{x}_i)}\\
        &= \frac{Z(\mathbf{x}_i)}{\e^{\mathbf{x}_i^\top\mathbf{w}_j}}\frac{Z(\mathbf{x}_i)\mathbf{x}_i\e^{\mathbf{x}_i^\top\mathbf{w}_k}\delta_{jk} - \e^{\mathbf{x}_i^\top\mathbf{w}_j}\e^{\mathbf{x}_i^\top\mathbf{w}_k}\mathbf{x}_i}{Z^2(\mathbf{x}_i)}\\
        &= \mathbf{x}_i\delta_{jk} - \mathbf{x}_i\pi_k(\mathbf{x}_i)
    \end{split}
\end{equation*}
zatem
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k - \sum_{i=1}^m\mathbf{x}_i\sum_{j=1}^s \delta(t_i, \tau_j)\delta_{jk} + \sum_{i=1}^m\mathbf{x}_i\pi_k(\mathbf{x}_i)\sum_{j=1}^s\delta(t_i, \tau_j)\,.
\end{equation*}
Zauważmy jednak, iż
\begin{equation*}
    \sum_{j=1}^s\delta(t_i, \tau_j) = 1\,,\quad \sum_{j=1}^s \delta(t_i, \tau_j)\delta_{jk} = \delta(t_i, \tau_k)\,,
\end{equation*}
zatem ostatecznie
\begin{equation*}
    \pdv{\ell^*}{\mathbf{w}_k} = \gamma\mathbf{w}_k + \sum_{i=1}^m \mathbf{x}_i\left[\pi_k(\mathbf{x}_i) - \delta(t_i, \tau_k)\right]\,.
\end{equation*}
Wprowadzając macierze
\begin{equation*}
    \begin{split}
        &\oper{X} = \mqty[\mathbf{x}_1^\top \\ \vdots \\ \mathbf{x}_m^\top]\,,\quad \oper{W} = \mqty[\mathbf{w}_1^\top \\ \vdots \\ \mathbf{w}_s^\top]\,,\\
        &\oper{S} = \mqty[\pi_1(\mathbf{x}_1) & \cdots & \pi_s(\mathbf{x}_1) \\ \vdots & \ddots & \vdots \\ \pi_1(\mathbf{x}_m) & \cdots & \pi_s(\mathbf{x}_m)]\,,\quad \oper{T} = \mqty[\delta(t_1,\tau_1) & \cdots & \delta(t_1,\tau_s) \\ \vdots & \ddots & \vdots \\ \delta(t_m, \tau_1) & \cdots & \delta(t_m, \tau_s)]
    \end{split}
\end{equation*}
możemy w takim razie zapisać zdefiniowaną wyżej macierz pochodnych wymaganych do algorytmu spadku
wzdłuż gradient w kompaktowej formie jako
\begin{equation*}
    \pdv{\ell^*}{\oper{W}} = (\oper{S} - \oper{T})^\top\oper{X}\,.
\end{equation*}
Zauważmy, iż zregularyzowana funkcja kosztu rośnie wraz ze wzrostem liczby obserwacji \(m\). Wynika
z tego, iż stała ucząca musi być zależna od liczby przykładów. Możemy na przykład stwierdzić, iż
\(\epsilon \leftarrow m^{-1}\epsilon\) i wówczas minimalizujemy tak naprawdę średni koszt \(\ell^* /
m\).

\subsection{Wnioskowanie metodami Monte Carlo}

Całe wnioskowanie Bayesowskie opiera się na wyznaczaniu rozkładów a posteriori, które wyrażają naszą
wiedzę o estymowanym parametrze. Do tej pory rozważaliśmy modele Bayesowskie dla których prior i
wiarygodność były dane przez rozkłady normalne. Dzięki temu mogliśmy wyprowadzić analityczne wzory
na parametry rozkładu a posteriori, który również był rozkładem normalnym. Dla wielu interesujących
modeli nie jesteśmy jednak w stanie tego zrobić (np. w zagadnieniu regresji logistycznej
ograniczyliśmy się jedynie do estymaty punktowej), gdyż obliczenie stałej normalizującej dla
rozkładu \(p(\theta \mid D)\) może wymagać obliczenia całki, której nie jesteśmy w stanie wyrazić w
sposób jawny lub sumy po wykładniczo wielu elementach. Wnioskowanie Bayesowskie można jednak
prowadzić w modelach, w których nie dysponujemy jawnym wzorem na gęstość prawdopodobieństwa rozkładu
a posteriori. Okazuje się, iż do generowania próbek z rozkładu \(p(\theta \mid D)\) wystarcza
znajomość tego rozkładu z dokładnością do stałej normalizującej, a zatem wystarczy znać rozkład
łączny \(p(\theta, D) = p(D\mid\theta)\pi(\theta)\). Generowanie próbek z kolei wystarcza natomiast,
na mocy silnego prawa wielkich liczb, do szacowania wartości średnich dowolnych funkcji estymowanego
parametru \(\theta\). Przypomnijmy, iż na mocy silnego prawa wielkich liczb ciąg średnich
częściowych \((\overline{X}_n)\) ciągu zmiennych losowych \((X_n)\) i.i.d. z rozkładu \(X \sim
\mathcal{D}\) jest zbieżny z prawdopodobieństwem 1 do wartości oczekiwanej \(\mathbb{E}[X]\) tj.
\begin{equation*}
    P\left(\lim_{n \to \infty} \overline{X}_n = \mathbb{E}[X]\right) = 1\,.
\end{equation*}
Wartość oczekiwaną \(\mathbb{E}[X]\) możemy zatem przybliżyć średnią \(\overline{X}_n\) z dużej
ilości próbek.

Wnioskowanie Monte Carlo pozwala nam szacować różne wielkości w tzw. hierarchicznych modelach
Bayesowskich (z ang. \textit{Bayesian hierarchical modeling}). Rozważmy jeszcze raz przykład
regresji liniowej w ujęciu Bayesowskim, ale rozważmy teraz model postaci
\begin{equation*}
    \begin{split}
        \sigma^2 &\sim \mathcal{D}(\lambda)\\
        \mathbf{w} &\sim \mathcal{N}(\boldsymbol{\mu}_0, \oper{\Sigma}_0)\\
        y \mid \mathbf{w}, \sigma^2 &\sim \mathcal{N}(\mathbf{w}^\top\mathbf{x}, \sigma^2)
    \end{split}\quad,
\end{equation*}
gdzie \(\lambda, \boldsymbol{\mu}_0, \oper{\Sigma}_0\) są pewnymi hiper-parametrami. Dla takiego
modelu nie możemy w ogólności znaleźć jawnej postaci rozkładu a posteriori. Jeśli jednak umiemy
generować próbki z rozkładu łącznego
\begin{equation*}
    Z\cdot p(\mathbf{w}, \sigma^2 \mid D) = p(D, \mathbf{w}, \sigma^2) = p(D \mid \mathbf{w},\sigma^2)\pi(\mathbf{w})\pi(\sigma^2)
\end{equation*}
to wszystkie interesujące wielkości możemy oszacować jako odpowiednie średnie. Pozostaje pytanie w
jaki sposób generować próbki ze skomplikowanych rozkładów prawdopodobieństwa, których gęstości znamy
jedynie z dokładnością do stałej normalizującej. Poniżej przedstawimy dwa algorytmy próbkowania:
algorytm IS oraz Metropolisa--Hastingsa będący szczególną realizacją całej rodziny algorytmów
próbkowania zwanych Markov Chain Monte Carlo (MCMC).

\subsubsection{Algorytm Importance Sampling (IS)}

Załóżmy, iż chcemy obliczyć wartość oczekiwaną pewnej funkcji zmiennej losowej \(\mathbf{x}\)
względem skomplikowanego rozkładu prawdopodobieństwa \(p(\mathbf{x})\), który znamy jedynie z
dokładnością do stałej normalizującej
\begin{equation*}
    p(\mathbf{x}) = \frac{1}{Z_p}\tilde{p}(\mathbf{x})
\end{equation*}
tj. szukamy
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] = \int f(\mathbf{x}) p(\mathbf{x})\dd[n]\mathbf{x}\,.
\end{equation*}
Jeśli umiemy generować próbki \(\mathbf{x}\) z innego (prostszego) rozkładu \(q(\mathbf{x})\), który
nazywamy rozkładem proponującym kandydatów (z ang. \textit{proposal distribution}) to możemy zapisać
\begin{equation*}
    \begin{split}
        \mathbb{E}_p[f(\mathbf{x})] &= \int\limits_{\mathbb{R}^n}f(\mathbf{x})p(\mathbf{x})\dd[n]\mathbf{x} = \int\limits_{\mathbb{R}^n}f(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})}q(\mathbf{x})\dd[n]\mathbf{x}\\
         &=\mathbb{E}_q\left[f(\mathbf{x}) \frac{p(\mathbf{x})}{q(\mathbf{x})}\right] = \frac{Z_q}{Z_p}\mathbb{E}_q\left[f(\mathbf{x}) \frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]\,.
    \end{split}\quad.
\end{equation*}
Zakładamy tutaj, iż nośnik rozkładu \(p\) zawiera się w nośniku \(q\) tj. \(\text{supp}\,p \subseteq
\text{supp}\,q\). Stosunek stałych \(Z_p / Z_q\) również możemy oszacować z próbek z \(q\), gdyż
mamy
\begin{equation*}
    Z_p = \int\limits_{\mathbb{R}^n}\tilde{p}(\mathbf{x})\dd[n]{\mathbf{x}} = Z_q\int\limits_{\mathbb{R}^n}\frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})} q(\mathbf{x})\dd[n]{\mathbf{x}} = Z_q \mathbb{E}_q\left[\frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]\,,
\end{equation*}
skąd ostatecznie
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] = \frac{\mathbb{E}_q\left[f(\mathbf{x}) \frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]}{\mathbb{E}_q\left[\frac{\tilde{p}(\mathbf{x})}{\tilde{q}(\mathbf{x})}\right]}\,.
\end{equation*}
Jeśli z rozkładu \(q\) wygenerowaliśmy próbki \(X =
\left\{\mathbf{x}_1,\ldots,\mathbf{x}_m\right\}\) to na mocy silnego prawa wielkich liczb mamy
\begin{equation*}
    \mathbb{E}_p[f(\mathbf{x})] \approx \frac{\sum_{i=1}^m f(\mathbf{x}_i) \frac{\tilde{p}(\mathbf{x}_i)}{\tilde{q}(\mathbf{x}_i)}}{\sum_{i=1}^m \frac{\tilde{p}(\mathbf{x}_i)}{\tilde{q}(\mathbf{x}_i)}} = \sum_{i=1}^m \lambda_i f(\mathbf{x}_i)\,,
\end{equation*}
gdzie
\begin{equation*}
    \lambda_i = \frac{\tilde{p}(\mathbf{x}_i) / \tilde{q}(\mathbf{x}_i)}{\sum_{j=1}^m \tilde{p}(\mathbf{x}_j) / \tilde{q}(\mathbf{x}_j) }\,.
\end{equation*}

Algorytm Importance Sampling jest prostym algorytmem Monte Carlo, który ma jeden zasadniczy problem.
W jaki sposób mamy wybrać rozkład proponujący kandydatów \(q\)? Pewną odpowiedź na to pytanie
sugeruje analiza wariancji statystyki 
\begin{equation*}
    \overline{f}_m(\mathbf{x}_1,\ldots,\mathbf{x}_m) = \frac{1}{m}\sum_{i=1}^m \frac{f(\mathbf{x}_i)p(\mathbf{x}_i)}{q(\mathbf{x}_i)}
\end{equation*}
dla \(\mathbf{x}_i \sim q\) i zakładając dla uproszczenia, iż \(f\) jest funkcją skalarną mamy
\begin{equation*}
    \begin{split}
        \text{Var}[\overline{f}_m] &= \frac{1}{m}\text{Var}_q\left[f(\mathbf{x})\frac{p(\mathbf{x})}{q(\mathbf{x})}\right] = \frac{1}{m}\int\limits_{\mathbb{R}^n}\frac{(f(\mathbf{x})p(\mathbf{x}) - \mu_fq(\mathbf{x}))^2}{q(\mathbf{x})}\dd[n]{\mathbf{x}}\,.
    \end{split}
\end{equation*}
Chcemy oczywiście, aby wariancja była jak najmniejsza, gdyż wówczas mała liczba próbek da dobre
przybliżenie wartości oczekiwanej. Rozkład proponujący kandydatów powinien być zatem proporcjonalny
do \(f(\mathbf{x})p(\mathbf{x})\), co może być trudne do praktycznego zrealizowania.

\subsubsection{Algorytm Metropolisa--Hastingsa}

Cała klasa algorytmów próbkowania MCMC opiera się na idei wyrażenia generowania próbek jako ewolucji
pewnego łańcucha Markowa. Łańcuchem Markowa nazywamy ciąg zmiennych losowych \((X_t)\) o wartościach
w \(\mathbb{R}^n\) taki, że spełnione jest kryterium Markowa
\begin{equation*}
    \forall A \subset \mathbb{R}^n: P(X_t \in A \mid X_{t-1} = \mathbf{x}_{t-1}, \ldots, X_0 = \mathbf{x}_0) = P(X_t \in A \mid X_{t-1} = \mathbf{x}_{t-1})\,.
\end{equation*}
Elementy ciągu nazywamy stanami łańcucha Markowa. Dany łańcuch jest zadany jednoznacznie przez
podanie gęstości prawdopodobieństwa przejścia łańcucha ze stanu \(\mathbf{x} \to \mathbf{y}\), którą
będziemy oznaczać przez \(\pi(\mathbf{y} \mid \mathbf{x})\) (zakładamy, iż prawdopodobieństwo
przejścia jest niezależne od chwili \(t\) -- łańcuch taki nazywamy jednorodnym). Funkcja \(\pi\)
spełnia oczywiście warunek unormowania
\begin{equation*}
    \int\limits_{\mathbb{R}^n} \pi(\mathbf{y} \mid \mathbf{x}) \dd[n]{\mathbf{y}}\,,
\end{equation*} 
istotnie prawdopodobieństwo przejścia gdziekolwiek ze stanu \(\mathbf{x}\) jest równe 1. Będziemy
zakładać dodatkowo, iż \(\forall \mathbf{x},\mathbf{y}\in\mathbb{R}^n: \pi(\mathbf{y} \mid
\mathbf{x}) > 0\). Rozkład \(p(\mathbf{x})\) łańcucha Markowa (tj. rozkład prawdopodobieństwa z
którego losujemy stan łańcucha w danej chwili \(t\)) z daną funkcją przejścia \(\pi\) nazwiemy
rozkładem stacjonarnym tego łańcucha iff
\begin{equation*}
    p(\mathbf{y}) = \int\limits_{\mathbb{R}^n} \pi(\mathbf{y} \mid \mathbf{x})p(\mathbf{x}) \dd[n]{\mathbf{x}}\,.
\end{equation*}
Rozkład stacjonarny danego łańcucha oznaczymy przez \(p^*(\mathbf{x})\). Zauważmy, iż jeśli stan
początkowy łańcucha \(X_0\) pochodzi z rozkładu stacjonarnego \(p^*\) to każdy kolejny stan \(X_t\)
również pochodzi z rozkładu stacjonarnego. Jeśli z kolei stan początkowy pochodzi z jakiegoś innego
rozkładu \(p_0\) to rozkład łańcucha w chwili \(t\) jest dany przez relację rekurencyjną
\begin{equation*}
    p_t(\mathbf{y}) = \int\limits_{\mathbb{R}^n} \pi(\mathbf{y} \mid \mathbf{x})p_{t-1}(\mathbf{x}) \dd[n]{\mathbf{x}}\,,\quad\text{dla \(t > 1\).}
\end{equation*}
Rozkładem granicznym łańcucha Markowa nazwiemy granicę w sensie zbieżności punktowej
\begin{equation*}
    \lim_{t\to\infty} p_t(\mathbf{x})\,.
\end{equation*}
Przy podanych wyżej założeniach istnieje twierdzenie, które mówi iż taki łańcuch Markowa posiada
jednoznaczny rozkład stacjonarny tożsamy z rozkładem granicznym. Ponadto warunkiem wystarczającym,
aby dany rozkład \(p(\mathbf{x})\) był rozkładem stacjonarnym łańcucha Markowa jest
\begin{equation*}
    \forall\mathbf{x}, \mathbf{y} \in \mathbb{R}^n: \pi(\mathbf{y}\mid\mathbf{x}) p(\mathbf{x}) = \pi(\mathbf{x} \mid \mathbf{y}) p(\mathbf{y})\,,
\end{equation*}
co wynika z scałkowania powyższego równania
\begin{equation*}
    \int\limits_{\mathbb{R}^n} \pi(\mathbf{y}\mid\mathbf{x}) p(\mathbf{x}) \dd[n]{\mathbf{x}} = \int\limits_{\mathbb{R}^n} \pi(\mathbf{x} \mid \mathbf{y}) p(\mathbf{y}) \dd[n]{\mathbf{x}} = p(\mathbf{y}) \int\limits_{\mathbb{R}^n} \pi(\mathbf{x} \mid \mathbf{y}) \dd[n]{\mathbf{x}} = p(\mathbf{y})\,.
\end{equation*}
Kryterium to nazywamy kryterium lokalnego balansu (z ang. \textit{detailed balance condition}).

Podstawowa idea wykorzystania łańcuchów Markowa do generowania próbek ze skomplikowanego rozkładu
\(p\) jest więc następująca: tworzymy łańcuch Markowa opisany powyżej, dla którego \(p\) jest
rozkładem stacjonarnym, wówczas rozpoczynając w dowolnym dopuszczalnym stanie początkowym \(X_0\) po
wykonaniu dużej liczby kroków (etap ten nazywamy okresem przejściowym z ang. \textit{burn-in
period}) stan \(X_t\) (dla \(t \gg 1\)) tego łańcucha będzie w przybliżeniu pochodził z rozkładu
granicznego \(p\) (nie jest jednak prosto stwierdzić po jak długim okresie przejściowym przybliżenie
to jest wystarczająco dobre). Aby otrzymać z takiej procedury próbki prawdziwie i.i.d. każda z
próbek musiałaby pochodzić z ponownego uruchomienia takiego łańcucha. Oczywiście jest to
nieefektywne, więc w praktyce generujemy próbki z jednego łańcucha po prostu odrzucając pewne z nich
tak aby uniknąć znaczących korelacji.

Pozostaje pytanie jak skonstruować funkcję przejścia \(\pi(\mathbf{y} \mid \mathbf{x})\) dla danego
rozkładu granicznego \(p(\mathbf{x})\). Podstawową konstrukcję podaje algorytm
Metropolisa--Hastingsa:
\begin{enumerate}
    \item Jako stan początkowy przyjmij dowolną dopuszczalną wartość \(\mathbf{x} \leftarrow
    \mathbf{x}_0\).
    \item Powtarzaj:
    \begin{enumerate}
        \item Będąc w aktualnym stanie \(\mathbf{x}\) z prostego rozkładu proponującego kandydatów
        \(q(\mathbf{y} \mid \mathbf{x})\) wylosuj kandydata \(\mathbf{y}\) na wartość łańcucha w
        kolejnym stanie.
        \item Z prawdopodobieństwem
        \begin{equation*}
            r(\mathbf{y} \mid \mathbf{x}) = \min\left\{1, \frac{p(\mathbf{y})q(\mathbf{x} \mid \mathbf{y})}{p(\mathbf{x})q(\mathbf{y} \mid \mathbf{x})}\right\}
        \end{equation*}
        zaakceptuj kandydata jako nowy stan i przejdź do stanu \(\mathbf{y}\). W przeciwnym razie
        pozostać w stanie \(\mathbf{x}\)
    \end{enumerate}
\end{enumerate}
Funkcja przejścia ma zatem postać
\begin{equation*}
    \pi_\text{MH}(\mathbf{y}\mid\mathbf{x}) = q(\mathbf{y} \mid \mathbf{x}) r(\mathbf{y} \mid \mathbf{x})\,.
\end{equation*}
Pozostaje tylko wykazać, iż spełnione jest kryterium lokalnego balansu. Istotnie mamy
\begin{equation*}
    \begin{split}
        &\pi_\text{MH}(\mathbf{y}\mid\mathbf{x})p(\mathbf{x}) = \min\left\{q(\mathbf{y}\mid\mathbf{x})p(\mathbf{x}), q(\mathbf{x}\mid\mathbf{y})p(\mathbf{y})\right\}\\
        &\pi_\text{MH}(\mathbf{x}\mid\mathbf{y})p(\mathbf{y}) = \min\left\{q(\mathbf{x}\mid\mathbf{y})p(\mathbf{y}), q(\mathbf{y}\mid\mathbf{x})p(\mathbf{x})\right\}
    \end{split}\quad,
\end{equation*}
skąd \(\pi_\text{MH}(\mathbf{y}\mid\mathbf{x})p(\mathbf{x}) =
\pi_\text{MH}(\mathbf{x}\mid\mathbf{y})p(\mathbf{y})\). Zauważmy, iż nie musimy znać
\(p(\mathbf{x})\) z dokładnością do stałej normalizującej, gdyż
\begin{equation*}
    \frac{p(\mathbf{y})}{p(\mathbf{x})} = \frac{\tilde{p}(\mathbf{y})/Z_p}{\tilde{p}(\mathbf{x})/Z_p} =  \frac{\tilde{p}(\mathbf{y})}{\tilde{p}(\mathbf{x})}\,.
\end{equation*}
Poza algorytmem Metropolisa--Hastingsa jest wiele innych algorytmów z rodziny MCMC. Większość z nich
implementuje konkretny sposób generowania (zostawiając resztę struktury) tak, aby zmniejszyć
korelację po okresie przejściowym i przyspieszyć zbieżność. Standardowo wykorzystywanymi algorytmami
z tej klasy są algorytmy HMC (\textit{Hamiltonian Monte Carlo}) oraz NUTS (\textit{No U-Turn
Sampler}). 



\section{Sieci neuronowe}

Podstawowym elementem każdej sieci neuronowej jest pojedynczy neuron, który możemy traktować jako
odwzorowanie postaci \(z: \mathbb{R}^n \mapsto \mathbb{R}\) będące złożeniem pewnego odwzorowania
nieliniowego \(f:\mathbb{R} \mapsto \mathbb{R}\) z odwzorowaniem afinicznym \(a: \mathbb{R}^n
\mapsto \mathbb{R}\), \(a(\mathbf{x}) = \mathbf{w}^\top\mathbf{x} + b\) tj.
\begin{equation*}
    z(\mathbf{x}) = (f \circ a)(\mathbf{x}) = f\left(\mathbf{w}^\top\mathbf{x} + b\right)\,.
\end{equation*}
W praktyce wszystkie neurony sieci używają tej samej nieliniowej funkcji \(f\) zwanej funkcją
aktywacji (z ang. \textit{activation function}) i najczęściej są to funkcje ReLU, GELU lub funkcje
sigmoidalne:
\begin{equation*}
    \begin{split}
        &\text{ReLU}(x) := \max(0, x)\,,\\
        &\text{GELU}(x) := x\Phi(x)\,,
    \end{split}
\end{equation*}
gdzie \(\Phi(x)\) to dystrybuanta standardowego rozkładu normalnego. Pojedyncze neurony są następnie
łączone w sieci w określony sposób tworząc daną architekturę sieci neuronowej.

\subsection{Architektura MLP}

Opis sieci neuronowych zaczniemy od architektury MLP (z ang. \textit{Multilayer Perceptron}). Sieć
MLP składa się z równoległych warstw neuronów, przy czym połączenia występują tylko między neuronami
w sąsiednich warstwach i nie ma połączeń między neuronami w obrębie jednej warstwy. Pierwszą warstwę
sieci nazywamy warstwą wejściową (z ang. \textit{input layer}), ostatnią -- warstwą wyjściową (z
ang. \textit{output layer}), a pozostałe nazywamy warstwami ukrytymi (z ang. \textit{hidden
layers}).

\begin{figure}
\centering
\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

    \foreach \m/\l [count=\y] in {1,2,3,4} \node [every neuron/.try, neuron \m/.try] (input-\m) at
        (0,2.5-\y) {$x_\m$};
    
    \foreach \m [count=\y] in {1,2} \node [every neuron/.try, neuron \m/.try ] (hidden-\m) at
        (2,2-\y*1.25) {$z^{(1)}_\m$};
    
    \foreach \m [count=\y] in {1,2} \node [every neuron/.try, neuron \m/.try ] (output-\m) at
        (4,2-\y*1.25) {$\theta_\m$};
        
    \foreach \l [count=\i] in {1,n} \node [above] at (hidden-\i.north) {};
        
    \foreach \i in {1,...,4} \foreach \j in {1,...,2} \draw [->] (input-\i) -- (hidden-\j);
    
    \foreach \i in {1,...,2} \foreach \j in {1,...,2} \draw [->] (hidden-\i) -- (output-\j);
    
    \foreach \l [count=\x from 0] in {Input, Hidden, Ouput} \node [align=center, above] at (\x*2,2)
        {\l \\ layer};
    
    \end{tikzpicture}
\end{figure}

Zauważmy, iż opisane wcześniej modele regresji liniowej i wieloklasowej regresji logistycznej są
przykładamy najprostszych sieci MLP bez żadnych warstw ukrytych. Ich graficzne reprezentacje jako
sieci MLP zamieszczono na Rysunku \ref{fig:simple-mlp1} i \ref{fig:simple-mlp2}. Zauważmy, iż
wyjściem sieci są parametry docelowego rozkładu prawdopodobieństwa nad obserwacjami tj. odpowiednio
wartość oczekiwana \(\mu\) w przypadku regresji liniowej i prawdopodobieństwa \(\pi_i\) każdej z
klas rozkładu kategorialnego w przypadku regresji logistycznej. W przypadku regresji liniowej
funkcja aktywacji neuronu w warstwie wyjściowej to po prostu funkcja identycznosciowa, natomiast w
przypadku regresji logistycznej jest to funkcja soft-max.

Przejdźmy teraz do matematycznego opisu architektury MLP. Dla danej funkcji
\(f:\mathbb{R}\mapsto\mathbb{R}\) przez zapis \(\mathbf{f}(\mathbf{x})\) dla \(\mathbf{x} \in
\mathbb{R}^n\) będziemy rozumieli macierz kolumnową
\begin{equation*}
    \mathbf{f}(\mathbf{x}) = \mqty[f(x_1) \\ \vdots \\ f(x_n)]\,.
\end{equation*}
Dodatkowo zdefiniujmy dodatkowo odwzorowanie \(\mathbf{a}: \mathbb{R}^n \mapsto \mathbb{R}^m\) jako
\begin{equation*}
    \mathbf{a}(\mathbf{x}) = \mqty[\mathbf{w}_1^{\top} \\ \vdots \\ \mathbf{w}_m^{\top}]\mathbf{x} + \mathbf{b} = \oper{W}\mathbf{x} + \mathbf{b}\,,
\end{equation*}
gdzie \(\oper{W} \in \mathbb{M}_{m\times n}(\mathbb{R}), \mathbf{b} \in \mathbb{R}^m\).

\begin{figure}[ht]
    \centering
    \begin{subfigure}[b]{0.8\textwidth}
        \centering
        \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

            \foreach \m/\l [count=\y] in {1,2,3,4} \node [every neuron/.try, neuron \m/.try]
                (input-\m) at (0,2.5-\y) {$x_\m$};
            
            \foreach \m [count=\y] in {1} \node [every neuron/.try, neuron \m/.try ] (output-\m) at
                (2,2-\y*2) {$\mu$};
                        
            \foreach \i in {1,...,4} \foreach \j in {1} \draw [->] (input-\i) -- (output-\j);
                
        \end{tikzpicture}
        \caption{Graficzna reprezentacja regresji liniowej jako najprostszej sieci MLP}
        \label{fig:simple-mlp1}
    \end{subfigure}
    \hfil
    \begin{subfigure}[b]{0.8\textwidth}
        \centering
        \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

            \foreach \m/\l [count=\y] in {1,2,3,4} \node [every neuron/.try, neuron \m/.try]
                (input-\m) at (0,2.5-\y) {$x_\m$};
            
            
            \foreach \m [count=\y] in {1,2,3} \node [every neuron/.try, neuron \m/.try ] (output-\m)
                at (2,2-\y) {$\pi_\m$};
            
                        
            \foreach \i in {1,...,4} \foreach \j in {1,...,3} \draw [->] (input-\i) -- (output-\j);
                        
        \end{tikzpicture}
        \caption{Graficzna reprezentacja wieloklasowej regresji logistycznej jako najprostszej sieci MLP}
        \label{fig:simple-mlp2}
    \end{subfigure}
    
\end{figure}

Oznaczmy przez \(n_0, n_1, \ldots, n_{s-1}, n_s\) liczby neuronów w kolejnych warstwach, natomiast
przez \(g\) funkcję aktywacji warstwy wyjściowej. Wyjście sieci MLP jest zatem opisane przez
następujące złożenie funkcji
\begin{equation*}
    \boldsymbol{\theta}(\mathbf{x}; \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s) = \left(\mathbf{g}\circ\mathbf{a}_s\circ \mathbf{f}_{s-1}\circ\mathbf{a}_{s-1}\circ\ldots\circ \mathbf{f}_1\circ\mathbf{a}_1\right)(\mathbf{x})\,,
\end{equation*}
gdzie 
\begin{equation*}
    \mathbf{a}_k(\mathbf{x}) = \oper{W}_k\mathbf{x} + \mathbf{b}_k\,,
\end{equation*}
przy czym \(\oper{W}_k \in \mathbb{M}_{n_k \times n_{k-1}}(\mathbb{R})\) oraz
\(\mathbf{f}_k:\mathbb{R}^{n_k} \mapsto \mathbb{R}^{n_k}\). Chcemy zatem wnioskować o parametrach
\(\oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s\) zakładając, iż rozkład
warunkowy nad obserwacjami dla wektora zmiennych objaśniających \(\mathbf {x}\) ma postać 
\begin{equation*}
    y \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s \sim \mathcal{D}(\boldsymbol{\theta}(\mathbf{x}))\,.
\end{equation*}
dla pewnej rodziny rozkładów prawdopodobieństwa \(\mathcal{D}\). 

\subsubsection{Wsteczna propagacja błędu}

Zajmiemy się najpierw problemem znalezienia estymaty punktowej MLE dla parametrów sieci MLP.
Załóżmy, iż mamy dane obserwacje iid \(D = \{(y_1, \mathbf{x}_1), \ldots, (y_m, \mathbf{x}_m)\}\).
Wiarygodność ma postać
\begin{equation*}
p(D \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s ) = \prod_{i=1}^m p(y_i \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)
\end{equation*}
skąd funkcja kosztu (zanegowana logarytmiczna funkcja wiarygodności)
\begin{equation*}
    \ell(D \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s) = -\sum_{i=1}^m \log p(y_i \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)\,.
\end{equation*}
Zauważmy więc, iż dla dowolnego modelu statystycznego funkcja ta ma postać sumy po wszystkich
przykładach w zbiorze uczącym \(D\)
\begin{equation*}
    \ell(D \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s) = \sum_{i=1}^m \ell(y_i \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)\,.
\end{equation*}
Do znalezienia estymaty MLE parametrów sieci neuronowej musimy zminimalizować powyższą funkcję, a
zatem potrzebny nam jest algorytm efektywnego obliczania pochodnych \(\ell(y_i \mid \ldots)\) po
parametrach \(\oper{W}_k, \mathbf{b}_k\). Zauważmy, że zachodzi
\begin{equation*}
    \pdv{\ell}{\oper{W}_k} = \pdv{\ell}{\mathbf{g}}\pdv{\mathbf{g}}{\mathbf{a}_s}\pdv{\mathbf{a}_s}{\mathbf{f}_{s-1}}\pdv{\mathbf{f}_{s-1}}{\mathbf{a}_{s-1}}\ldots \pdv{\mathbf{a}_k}{\oper{W}_k}
\end{equation*}
jednakże
\begin{equation*}
    \pdv{\mathbf{f}_k}{\mathbf{a}_k} = \mqty[f'([\mathbf{a}_k]_1) & 0 & \ldots & 0 \\ 0 & f'([\mathbf{a}_k]_2) & \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \ldots & f'([\mathbf{a}_k]_{n_k})] = \diag(\mathbf{f}'_k(\mathbf{a}_k))
\end{equation*}
oraz
\begin{equation*}
    \pdv{\mathbf{a}_k}{\mathbf{f}_{k-1}} = \oper{W}_k\,,\quad \pdv{\mathbf{a}_k}{\oper{W}_k} = \mqty[\mathbf{f}_{k-1} & \mathbf{0} & \ldots & \mathbf{0} \\ \mathbf{0} & \mathbf{f}_{k-1} & \ldots & \mathbf{0} \\ \vdots & \vdots & \ddots & \vdots \\ \mathbf{0} & \mathbf{0} & \ldots & \mathbf{f}_{k-1}]
\end{equation*}
zatem
\begin{equation*}
    \pdv{\ell}{\oper{W}_k} = \mathbf{f}_{k-1} \underbrace{\left[\pdv{\ell}{\mathbf{g}}\pdv{\mathbf{g}}{\mathbf{a}_s}\cdot \oper{W}_s\cdot\diag(\mathbf{f}'_{s-1}(\mathbf{a}_{s-1}))\cdots \oper{W}_{k+1}\cdot \diag(\mathbf{f}'_{k}(\mathbf{a}_k))\right]}_{\boldsymbol{\delta}_k}\,.
\end{equation*}
Zauważmy, że możemy obliczać \(\boldsymbol{\delta}_k\) rekurencyjnie jako
\begin{equation*}
    \boldsymbol{\delta}_{k-1} = \boldsymbol{\delta}_{k}\cdot \oper{W}_k\cdot\diag(\mathbf{f}'_{k-1}(\mathbf{a}_{k-1}))\,,\quad \boldsymbol{\delta}_s = \pdv{\ell}{\mathbf{g}}\pdv{\mathbf{g}}{\mathbf{a}_s}\,.
\end{equation*}
W przypadku wyrazu wolnego (\textit{bias}) mamy natomiast analogicznie
\begin{equation*}
    \pdv{\ell}{\mathbf{b}_k} = \pdv{\ell}{\mathbf{g}}\pdv{\mathbf{g}}{\mathbf{a}_s}\pdv{\mathbf{a}_s}{\mathbf{f}_{s-1}}\pdv{\mathbf{f}_{s-1}}{\mathbf{a}_{s-1}}\ldots \pdv{\mathbf{a}_k}{\mathbf{b}_k}
\end{equation*}
ponieważ jednak
\begin{equation*}
    \pdv{\mathbf{a}_k}{\mathbf{b}_k} = \oper{I}\,,
\end{equation*}
więc
\begin{equation*}
    \pdv{\ell}{\mathbf{b}_k} = \boldsymbol{\delta}_k\,.
\end{equation*}
Możemy zatem zapisać algorytm obliczania pochodnych funkcji kosztu po parametrach sieci neuronowej
zwany algorytmem wstecznej propagacji błędu (z ang. \textit{error backpropagation})

\begin{tcolorbox}[title=Algorytm wstecznej propagacji błędu]
\begin{enumerate}
\item Dla przykładu \((y_i, \mathbf{x}_i)\) dokonaj propagacji naprzód sieci MLP i zapamiętaj
wartości funkcji \(\mathbf{a}_1, \mathbf{a}_2, \ldots, \mathbf{a}_s\) i funkcji aktywacji
\(\mathbf{f}_1,\mathbf{f}_2,\ldots,\mathbf{f}_{s-1},\mathbf{g}\).

\item Wyznacz rekurencyjnie i zapamiętaj wartości \(\boldsymbol{\delta}_k\) korzystając ze wstecznej
propagacji
\begin{equation*}
    \boldsymbol{\delta}_{k-1} = \boldsymbol{\delta}_{k}\cdot \oper{W}_k\cdot\diag(\mathbf{f}'_{k-1}(\mathbf{a}_{k-1}))\,,\quad \boldsymbol{\delta}_s = \pdv{\ell}{\mathbf{g}}\pdv{\mathbf{g}}{\mathbf{a}_s}\,.
\end{equation*}

\item Wyznacz odpowiednie pochodne korzystając z
\begin{equation*}
    \pdv{\ell}{\oper{W}_k} = \mathbf{f}_{k-1}\boldsymbol{\delta}_k\,,\quad \pdv{\ell}{\mathbf{b}_k} = \boldsymbol{\delta}_k\,.
\end{equation*}
W powyższym wzorze \(\mathbf{f}_0 = \mathbf{x}_i\).
\end{enumerate}
\end{tcolorbox}

Powyższy algorytm wyznacza pochodną funkcji kosztu dla pojedynczego przykładu. Jeśli używamy serii
przykładów \(D\) (tzw. \textit{batch}) to oczywiście zachodzi
\begin{equation*}
    \begin{split}
        &\pdv{\ell(D\mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)}{\oper{W}_k} = \sum_{i=1}^m \pdv{\ell(y_i\mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)}{\oper{W}_k}\,,\\
        &\pdv{\ell(D\mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)}{\mathbf{b}_k} = \sum_{i=1}^m \pdv{\ell(y_i\mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s)}{\mathbf{b}_k}\,,
    \end{split}
\end{equation*}
więc powyższy algorytm wykonujemy dla każdego przykładu i dodajemy wyniki. Problemy regresji
liniowej i logistycznej na sieci MLP różnią się jedynie funkcją aktywacji \(g\) warstwy wyjściowej i
używaną funkcją kosztu. W przypadku regresji liniowej mamy
\begin{equation*}
    g(x) = x\,,\quad \ell(y_i \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s ) = \frac{1}{2}(y_i - g)^2\,,
\end{equation*}
skąd
\begin{equation*}
    \delta_s = g - y_i\,.
\end{equation*}
Natomiast w przypadku regresji logistycznej mamy
\begin{equation*}
    \begin{split}
        &\mathbf{g}(\mathbf{x}) = \frac{1}{\sum_{i=1}^n \e^{x_i}}\mqty[\e^{x_1} \\ \vdots \\ \e^{x_n}]\,,\\
        &\ell(y_i \mid \oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1, \ldots, \mathbf{b}_s) = -\sum_{j=1}^c \delta(y_i, \tau_j) \log [\mathbf{g}]_j\,,
    \end{split}
\end{equation*}
skąd
\begin{equation*}
    \boldsymbol{\delta}_s = \mqty[\frac{\delta(y_i, \tau_1)}{[\mathbf{g}]_1} & \cdots & \frac{\delta(y_i, \tau_c)}{[\mathbf{g}]_c}] \mqty[[\mathbf{g}]_i[\mathbf{g}]_j - \delta_{ij}[\mathbf{g}]_j ]_{c\times c} = \mathbf{g}^\top - \mqty[\delta(y_i, \tau_1) \ldots \delta(y_i, \tau_c)]\,.
\end{equation*}
Mając algorytm efektywnego obliczania pochodnych funkcji kosztu, funkcję minimalizujemy korzystając
z algorytmu spadku wzdłuż gradientu. W przypadku sieci neuronowych funkcja kosztu nie jest funkcją
ściśle wypukłą, więc algorytm spadku wzdłuż gradientu nie znajdzie globalnego minimum; możemy liczyć
jedynie na znalezienie minimum lokalnego. Istnieją trzy podstawowe algorytmy spadku wzdłuż
gradientu: seryjny spadek wzdłuż gradientu (z ang. \textit{Batch Gradient Descent (BGD)}),
stochastyczny spadek wzdłuż gradientu (z ang. \textit{Stochastic Gradient Descent (SGD)}) oraz
mini-seryjny spadek wzdłuż gradientu (z ang. \textit{Mini-Batch Gradient Descent (mBGD)})

\begin{tcolorbox}[title=Algorytm BGD]
\begin{enumerate}
    \item Wybierz początkowe wartości parametrów \(\oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1,
    \ldots, \mathbf{b}_s\).
    
    \item Powtarzaj przez \(N\) epok:
    \begin{enumerate}
        \item Oblicz pochodne funkcji kosztu \(\ell\) zsumowane po wszystkich przykładach z batcha
        \(D\) korzystając z algorytmu wstecznej propagacji błędu.

        \item Zaktualizuj wartości parametrów zgodnie z:
        \begin{equation*}
            \begin{split}
                &\oper{W}_k = \oper{W}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\oper{W}_k}\\
                &\mathbf{b}_k = \mathbf{b}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\mathbf{b}_k}\\
            \end{split}
        \end{equation*}
    \end{enumerate}
\end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[title=Algorytm SGD]
\begin{enumerate}
    \item Wybierz początkowe wartości parametrów \(\oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1,
    \ldots, \mathbf{b}_s\).
    
    \item Powtarzaj przez \(N\) epok: \\
    Dla każdego przykładu \((y_i, \mathbf{x}_i) \in D\):
    \begin{enumerate}
        \item Oblicz pochodne funkcji kosztu \(\ell\) dla przykładu \((y_i, \mathbf{x}_i)\)
        korzystając z algorytmu wstecznej propagacji błędu.

        \item Zaktualizuj wartości parametrów zgodnie z:
        \begin{equation*}
            \begin{split}
                &\oper{W}_k = \oper{W}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\oper{W}_k}\\
                &\mathbf{b}_k = \mathbf{b}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\mathbf{b}_k}\\
            \end{split}
        \end{equation*}
    \end{enumerate}

\end{enumerate}
\end{tcolorbox}

\begin{tcolorbox}[title=Algorytm mBGD]
\begin{enumerate}
    \item Wybierz początkowe wartości parametrów \(\oper{W}_1, \ldots,\oper{W}_s, \mathbf{b}_1,
    \ldots, \mathbf{b}_s\).

    \item Podziel dane treningowe w \(D\) na \(K\) rozłącznych mini-batchy \(D_1, \ldots, D_K\)
    jednakowej wielkości.
    
    \item Powtarzaj przez \(N\) epok: \\
    Dla każdego mini-batcha \(D_i\):
    \begin{enumerate}
        \item Oblicz pochodne funkcji kosztu \(\ell\) zsumowane po wszystkich przykładach z
        mini-batcha \(D_i\) korzystając z algorytmu wstecznej propagacji błędu.

        \item Zaktualizuj wartości parametrów zgodnie z:
        \begin{equation*}
            \begin{split}
                &\oper{W}_k = \oper{W}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\oper{W}_k}\\
                &\mathbf{b}_k = \mathbf{b}_k - \frac{\epsilon}{|D|}\pdv{\ell}{\mathbf{b}_k}\\
            \end{split}
        \end{equation*}
    \end{enumerate}
\end{enumerate}
\end{tcolorbox}

\subsubsection{Regularyzacja w sieciach neuronowych}

\begin{enumerate}
    \item \textbf{Consistent Gaussian Priors}\\
    Analogicznie jak w przypadku prostych modeli liniowych jedną z możliwości regularyzacji jest
    dodanie do funkcji kosztu \(\ell\) czynnika regularyzującego zawierającego kwadraty składowych
    wektorów wag postaci \(\tr(\oper{W}_k^\top\oper{W}_k)\) przy czym w ogólności przyjmujemy iż
    mamy \(s\) różnych współczynników \(\lambda_k\) określających siły regularyzacji dla wag
    łączących poszczególne warstwy. Zregularyzowana funkcja kosztu ma więc w ogólności postać
    \begin{equation*}
        \ell^* = \ell + \frac{1}{2}\sum_{k=1}^s\lambda_k \tr(\oper{W}_k^\top\oper{W}_k)\,.
    \end{equation*}
    Dzięki takiej postaci funkcja kosztu zachowuje własność niezmienniczości względem skalowania.
    Istotnie zauważmy, iż w przypadku niezregularyzowanej funkcji kosztu jeśli wektor w warstwie
    wejściowej pomnożymy przez pewien skalar \(\alpha\) to wyjście sieci pozostanie niezmienione
    jeśli wagi w pierwszej warstwie ukrytej pomnożymy przez \(\alpha^{-1}\). Analogicznie wyjście
    nie zmieni się jeśli wektor w warstwie wyjściowej pomnożymy przez \(\beta\), a wagi łączące dwie
    ostatnie warstwy pomnożymy przez \(\beta^{-1}\). W szczególności możemy wykonać obie te operacje
    dla jednej sieci i również nie zmienimy wyjścia. Zauważmy jednak, iż gdybyśmy na sztywno
    założyli, iż współczynniki \(\lambda_1\) i \(\lambda_s\) są takie same to zregularyzowana
    funkcja nie byłaby niezmiennicza względem takiego skalowania. Dzięki różnym współczynnikom
    pozostaje niezmiennicza jeśli pomnożymy współczynniki \(\lambda_1, \lambda_s\) odpowiednio przez
    \(\sqrt{\alpha}\) i \(\sqrt{\beta}\).

    \item \textbf{Early stopping}\\
    Innym podejściem do regularyzacji sieci neuronowych jest procedura \textit{early stopping}.
    Polega ona na zatrzymaniu procesu uczenia (optymalizacji funkcji kosztu) w momencie, w którym
    wartość funkcji kosztu na wydzielonym ze zbioru treningowego zbiorze walidacyjnym zaczyna
    rosnąć. Unikamy w ten sposób przeuczenia modelu.

    \item \textbf{Niezmienniki}\\
    W wielu zastosowaniach uczenia maszynowego wiemy, że predykcje modelu powinny być niezmienione
    jeśli dane wejściowe poddamy pewnej transformacji np. w problemie rozpoznawania ręcznie pisanych
    cyfr odpowiedź nie powinna zależeć od miejsca na obrazku, w którym znajduje się cyfra
    (niezmienniczość translacyjna) oraz od skali, w której została napisana (niezmienniczość
    skalowania). Istnieje kilka możliwych rozwiązań pozwalających uwzględnić te cechy
    \begin{enumerate}
        \item Jeśli znamy przekształcenia względem których predykcje powinny pozostawać niezmienione
        możemy rozszerzyć nasz zbiór treningowy o przykłady z początkowego zbioru poddane tym
        przekształceniom.

        \item Możemy dokonać preprocessingu danych w taki sposób aby wyekstrahować te cechy, które
        są niezmiennicze względem danych przekształceń (\textit{feature extraction}).

        \item Możemy w końcu wbudować tę niezmienniczość w strukturę samej sieci neuronowej.
        Przykładem takim są omawiane dalej Konwolucyjne Sieci Neuronowe, których struktura jest
        skonstruowana w taki sposób, aby wyciągać pewne cechy przestrzenne z obrazów.
    \end{enumerate}
\end{enumerate}

\subsection{Bayesowskie Sieci Neuronowe (BNN)}

\subsection{Sieci konwolucyjne (CNN)}

\subsection{Sieci rekurencyjne (RNN)}

\subsection{Transformery}

\subsection{Normalizing flow}


%TODO: Important
\section{Reinforcement learning i teoria optymalnego sterowania}

\end{document}